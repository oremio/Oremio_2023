# 961复习提纲

使用教辅：王道四件套、天勤四件套、961真题

注：难题、综合题要及时加入改错本，并做足注释！！

## <a name="index">**目录**</a>

&emsp;<a href="#1">2023年硕士研究生入学考试专业课961考研大纲</a>  
&emsp;<a href="#2">复习提纲</a>  
&emsp;<a href="#3">计算机组成原理（60分）</a>  
&emsp;&emsp;<a href="#4">（一）计算机系统概述</a>  
&emsp;&emsp;<a href="#5">（二）数据的表示和运算</a>  
&emsp;&emsp;<a href="#6">（三）存储器层次结构</a>  
&emsp;&emsp;<a href="#7">（四）MIPS指令系统及汇编语言</a>  
&emsp;&emsp;<a href="#8">（五）MIPS处理器</a>  
&emsp;&emsp;<a href="#9">（六）总线与输入输出(I/O)系统</a>  
&emsp;<a href="#10">操作系统（50分）</a>  
&emsp;&emsp;<a href="#11">（一）操作系统概述</a>  
&emsp;&emsp;<a href="#12">（二）进程管理</a>  
&emsp;&emsp;<a href="#13">（三）内存管理</a>  
&emsp;&emsp;<a href="#14">（四）设备管理</a>  
&emsp;&emsp;<a href="#15">（五）文件系统</a>  
&emsp;<a href="#16">计算机网络（40分）</a>  
&emsp;&emsp;<a href="#17">（一）计算机网络概述</a>  
&emsp;&emsp;<a href="#18">（二）物理层</a>  
&emsp;&emsp;<a href="#19">（三）数据链路层</a>  
&emsp;&emsp;<a href="#20">（四）网络层</a>  
&emsp;&emsp;<a href="#21">（五）传输层</a>  
&emsp;&emsp;<a href="#22">（六）应用层</a>  
&emsp;<a href="#23">附录：各种名词缩写及含义</a>  

## <a name="1">2023年硕士研究生入学考试专业课961考研大纲</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>
一、考试组成

961计算机基础综合共包括三门课程的内容：计算机组成原理、操作系统、计算机网络技术，分别占60分，50分、40分。所有课程均不指定参考书。

二、计算机组成原理部分的考试大纲（60分）

<一>、整体要求

（一）理解单处理器计算机系统中各部件的内部工作原理、组成结构以及相互连接方式，具有完整的计算机系统的整机概念；

（二）理解计算机系统层次化结构概念，掌握以MIPS为代表的RISC指令集体系结构的基本知识，能对MIPS汇编程序设计语言的相关问题进行分析；

（三）理解计算机存储系统的层次化结构，掌握层次化存储系统的设计、分析和性能计算；

（四）能根据指令语义进行单周期、多周期或流水线MIPS处理器的数据通路及其控制器的分析和简单设计；

（五）理解并掌握输入输出系统的基本知识。

<二>、知识要点

（一）计算机系统概述

（1）计算机系统的基本组成与层次结构

（2）计算机系统的性能指标：吞吐量、响应时间、带宽、延迟；CPU时钟周期、主频、CPI、CPU执行时间；MIPS、MFLOPS、GFLOPS、TFLOPS、PFLOPS。

（二）数据的表示和运算

（1）数制与编码

（2）定点数和浮点数的表示和运算

（3）算术逻辑单元ALU

1）串行加法器和并行加法器

2）算术逻辑单元ALU的功能和结构

（三）存储器层次结构

（1）存储器的层次化结构

（2）主存储器与CPU的连接

（3）高速缓冲存储器(Cache)

1）Cache的基本工作原理

2）Cach和主存之间的映射方式

3）Cache中主存块的替换算法与写策略

4）多层次Cache性能计算

（4）虚拟存储器

1）虚拟存储器的基本概念

2）页式虚拟存储器

3）TLB(快表)

（四）MIPS指令系统及汇编语言

（1）指令系统的基本知识（指令格式、寻址方式）

（2）MIPS汇编语言

（五）MIPS处理器

（1）CPU的功能和基本结构

（2）单周期、多周期MIPS处理器数据通路的功能和基本结构

（3）硬布线控制器的功能和工作原理

1）单周期处理器控制器

2）多周期处理器控制器

（4）指令流水线

1）指令流水线的基本概念

2）流水线冒险及处理策略

3）指令流水线的基本实现

（六）总线与输入输出(I/O)系统

（1）总线的基本概念

（2）磁盘存储器

（3）I/O控制器

1）I/O控制器的功能和基本结构

2）存储映射I/O编址

（4）基本I/O方式

1）程序查询方式

2）程序中断方式：中断的基本概念，中断响应过程，中断处理过程，多重中断和中断屏蔽的概念；

3）DMA方式，DMA控制器组成，DMA传送过程，设备传输性能计算。

三、操作系统部分的考试大纲（50分）

（一） 可参考书目

1.操作系统实用教程（第三版），任爱华，清华大学出版社。

2.现代操作系统(Modern Operating System) (The 3rd Edition),陈向群,马洪兵等译,Andrew S. Tanenbaum著,机械工业出版社。

（二） 复习内容

1.操作系统概述

a)操作系统的基本概念；内核态与用户态、中断、异常和系统调用。

2.进程管理

a)进程、线程的基本概念以及两者的区别；

b)进程控制块、进程的状态与转换；

c)进程同步的基本概念；实现临界区互斥的基本方法；信号量机制及P、V操作；了解经典同步问题，并通过信号量机制解决进程同步问题。

d)进程间通信，包括共享存储系统、消息传递系统、管道。

e)进程调度的基本准则；典型调度算法：先来先服务调度算法、短作业(短进程、短线程)优先调度算法、时间片轮转调度算法、优先级调度算法。

f)死锁的形成原因与必要条件；死锁预防、死锁避免、死锁检测和解除。

3.内存管理

a)程序装入与链接；逻辑地址与物理地址空间；重定位；内存保护。

b)分区管理；交换与覆盖技术。

c)分页管理方式；分段管理方式；段页式管理方式。

d)虚拟内存基本概念和局部性原理；缺页中断；地址变换过程。

e)页面置换算法：最佳置换算法(OPT)、先进先出置换算法(FIFO)、最近最少使用置换算法(LRU)、时钟置换算法(CLOCK)；工作集模型。

4.设备管理

a) I/O控制方式：程序控制、中断、DMA、通道；缓冲技术；假脱机技术(SPOOLing)。

5.文件系统

a)文件与文件系统的基本概念；组织方式；文件控制块；目录结构；文件存取控制；文件系统层次结构。

b）磁盘的结构；磁盘调度算法；廉价冗余磁盘阵列。

四、计算机网络部分的考试大纲（40分）

（一）可参考书目《计算机网络》(第8版)，谢希仁编著，电子工业出版社，2021

（二）复习内容

1、计算机网络概述

(1)计算机网络定义与分类

(2)计算机网络体系结构

2、物理层

(1)物理层的基本概念

(2)数据通信的基础知识

(3)传输介质及其特性

(4)信道复用技术

(5)数字传输系统

(6)宽带接入技术

3、数据链路层

(1)数据链路层功能和设计要点

(2)错误检测和纠正

(3)基本数据链路协议，包括：停止-等待协议、后退N帧协议和选择重传协议；

(4)滑动窗口协议

(5)点对点协议PPP

(6)介质访问控制协议，包括介质访问控制基本概念、协议分类、CSMA/CD协议；

(7)以太网，包括MAC地址、IEEE局域网标准、以太网、高速以太网技术；

(8)局域网互连技术，包括物理层及数据链路层互连技术、网桥概念和工作原理、局域网交换机工作原理；

(9)无线局域网(IEEE802.11)基本知识，包括CSMA/CA协议原理等。

4、网络层

(1)网络层提供的数据报和虚电路服务

(2)IP协议及ARP协议

(3)划分子网和构造超网

(4)ICMP协议

(5)路由算法及协议，包括路由表及路由转发、路由算法分类、距离向量路由算法及RIP协议、链路状态路由算法及OSPF协议、BGP基本原理；

(6)IP组播基本原理、特点及用途

(7)网络地址转换NAT原理

(8)IPv6基本知识，包括：IPv6特点、地址、包结构等

5、传输层

(1)传输层功能及提供的服务

(2)UDP协议

(3)TCP协议，包括：报文段格式、可靠传输、流量控制、拥塞控制和连接管理。

6、应用层

(1)套接字编程接口及端口概念

(2)域名系统DNS

(3)文件传送协议

(4)万维网WWW原理及HTTP协议

(5)电子邮件系统构成与协议

## <a name="2">复习提纲</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

## <a name="3">计算机组成原理</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

### <a name="4">（一）计算机系统概述</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）计算机系统的基本组成与层次结构

**计算机系统的基本组成：**

硬件系统：看得见的物理实体，电子线路和电子元件等

软件系统：解决问题的思想、方法，包括程序和数据

固件：固化的软件，firmware，本质是软件

**计算机硬件的基本组成：**

冯·诺依曼结构：
- 输入设备：将信息输入到计算机的外部设备，如键盘、鼠标等
- 输出设备：输出计算机处理结果的外部设备，如显示器、打印机等
- 存储器：存放程序和数据，按地址访问
- 运算器：执行算术运算和逻辑运算，必备寄存器：累加器（ACC）、乘商寄存器（MQ）、操作数寄存器（X）、程序状态寄存器/标志寄存器（PSW）
- 控制器：由程序计数器（PC）、指令寄存器（IR）、控制单元（CU）组成，根据指令的操作码、指令执行过程中的条件状态、时序系统等三方面的因素来产生指令执行过程中所需要的控制信号，控制指令的执行

*重要概念——存储字长：存储单元中的二进制代码位数，“等于数据线的数量，等于MDR的位数”（这条划掉。详见知乎：https://www.zhihu.com/question/293885327）（顺便：MAR的位数是log2存储单元个数，与PC长度相等），一般小于等于机器字长，是1字节的偶数倍。*

*重要概念——CPU：图示见王道p4。CPU包含{ALU、通用寄存器组GPRs、标志寄存器}、{CU、IR、PC}、MAR、MDR。*

冯·诺依曼计算机特点：（真题2019）

组成：运算器、控制器、存储器、输入和输出设备

存储程序：
- 指令和数据以**二进制**形式存放在存储器中
- 指令顺序存放，存储器按地址访问

程序控制：
- 程序运行时，控制器逐条从主存中取出指令，控制全机相关部件执行相应操作，完成指令的功能直至完成程序的功能
- 由指令控制计算机的运行
- 由控制器来控制数据的存取及程序的执行
- 程序顺序执行，遇到分支指令可能改变顺序

**计算机软件系统分类:**

应用软件:解决应用问题的程序集合，如各种科学计算类程序、工程设计类程序、数据统计与处理程序、情报检索程序等

系统软件：管理和调度计算机，方便用户使用计算机并提高使用效率的程序的集合
- 操作系统（OS）、数据库管理系统（DBMS)
- 分布式软件系统、网络软件系统、标准库程序
- 语言处理程序：
    - 编译器：将高级语言转换成汇编语言
    - 汇编器：将汇编语言转换成机器指令
    - 解释器：将高级语言直接翻译成机器指令，如JAVA

软硬件功能逻辑等效：
- 同一功能即可软件实现，也可以硬件实现
- 软件灵活性高，性能差，成本低
- 硬件效率高，成本高
- 功能划分要折中考虑

**计算机系统的层次结构：**

软件层（虚拟计算机）：
- 高级语言层 
- 汇编语言层    
- 操作系统层（由操作系统程序实现，由机器指令和广义指令组成，因此也被称为混合层）

硬件层：
- 指令集架构层（传统机器语言层）（组原讨论对象）
- 微代码层（可选）（微程序解释机器指令）（组原讨论对象）
- 逻辑门层（实体硬件）

![](https://api2.mubu.com/v3/document_image/e582b4cf-04cd-44ed-a905-f5cac0e939be-329792.jpg)

**计算机系统的工作过程：（真题2015、2016）**

- 1.“存储程序”工作方式
- 2.从源程序到可执行文件：hello.c->(预处理器cpp)->hello.i->(编译器ccl)->hello.s->(汇编器as)->hello.o+prinf.o->(链接器ld)->hello
- 3.程序的执行过程：数据在CPU、主存储器和I/O设备之间流动，通过总线、I/O接口进行
- 4.指令的执行过程：略

**王道习题：**

一轮标记题：2 7 9 14 19 20 22 23

二轮重做：2 5 9 14 19 23 24

大题：

1.
- 解：略
- 答：存储程序是指将指令以代码的形式事先输入计算机主存，然后按其在存储器中的首地址执行程序的第一条指令，以后就按该程序的规定顺序执行其他指令，直至程序执行结束。计算机按照此原理应该具有5大功能：数据传送功能、数据存储功能、数据处理功能、操作控制功能、操作判断功能


错题总结：
- 冯·诺依曼机的基本工作方式是控制流驱动方式
- 编译程序（编译器）既能输出汇编语言，也能输出机器语言，**现代编译器主要采用生成汇编代码（assembly code）的策略，而不直接生成二进制的目标代码（binary object code）**
- 硬件描述语言（英文：Hardware Description Language，简称：HDL）是电子系统硬件行为描述、结构描述、数据流描述的语言。利用这种语言，数字电路系统的设计可以从顶层到底层（从抽象到具体）逐层描述自己的设计思想，用一系列分层次的模块来表示极其复杂的数字系统。然后，利用电子设计自动化（EDA）工具，逐层进行仿真验证，再把其中需要变为实际电路的模块组合，经过自动综合工具转换到门级电路网表。接下去，再用专用集成电路 ASIC 或现场可编程门阵列 FPGA 自动布局布线工具，把网表转换为要实现的具体电路布线结构。**这是一个很容易望文生义的专业词汇**

#### （2）计算机系统的性能指标：吞吐量、响应时间、带宽、延迟；CPU时钟周期、主频、CPI、CPU执行时间；MIPS、MFLOPS、GFLOPS、TFLOPS、PFLOPS

**静态性能指标：**
- 机器字长：CPU一次处理的数据位数；与寄存器、运算器、数据总线的位宽相等；决定数据表示范围和精度
- 带宽：数据总线一次所能并行传送信息的位数，这里指外部总线的宽度。
- 主存容量：主存储器所能存储信息的最大容量。

**时间相关性能指标：（背30）**
- 吞吐量：指系统单位时间内处理请求的数量，主要取决于主存的存取周期。
- 响应时间：用户向计算机发送一个请求，到系统对该请求做出相应并获得结果所用的时间。响应时间越短，吞吐率越大。程序执行时间 = CPU时间 + 等待时间（磁盘、存储器访问、I/O操作、OS开销）
- 延迟：内存延迟是从开始请求内存中的字节或字，到处理器检索到它之间的时间。如果数据不在处理器的缓存中，则获取它们需要更长的时间，因为处理器必须与外部存储单元通信。因此，延迟是衡量内存速度的基本指标：延迟越少，读取操作就越快。延迟不应与衡量内存吞吐量的内存带宽混淆。延迟可以用时钟周期或以纳秒为单位测量的时间来表示
- CPU时钟周期：时钟频率的倒数，是处理操作最基本的时间单位
- 主频：时钟周期的倒数，同等条件下，频率越高，性能越好。但频率不可能无限提升，存在散热问题，串扰问题等，单位赫兹Hz
- CPI：执行每条指令所需的平均时钟周期数，Clock cycle Per Instruction
- CPU执行时间：程序执行期间真正消耗CPU的时间，**取决于①主频、②CPI、③指令条数（指令集）三要素**
- MIPS：每秒执行多少百万条指令数量，Million Instructions Per Second
- MFLOPS:
    - **每秒执行多少百万次浮点操作，Mega Floating-Point Operations Per Second，用于衡量科学计算性能**
    - 更小单位：kFLOPS，k小写
    - 更大单位：**GFLOPS、TFLOPS、PFLOPS**、EFLOPS、ZFLOPS，**Giga、Tera、Peta**、Exa、Zetta，每个单位相差1000倍
    - 还有一些常用的英文前缀：kilo(3)、hecto、deca、deci、centi、milli(-3)、micro(-6)、nano(-6)、pico(-9)
- 基准程序：专门用来进行性能评价的一组程序，但也存在缺陷（比如硬件设计人员根据benchmark代码进行特别优化）

**王道习题：**

一轮标记题：10 13 14

二轮重做：13 22 

大题：1 3

1.
- 解：MDR：32位，MAR：16位，IR：32位，PC：16位，X = ACC = MQ = 32位；信息通路：嗯……
- 答：信息通路：PC->MAR, Ad(IR)->MAR, MDR->IR, MDR->ACC（取数）, ACC->MDR（存数）, MDR->X

2.
- 解：CPI = 0.6 * 1 + 0.18 * 2 + 0.12 * 4 + 0.1 * 8 = 2.24; CPU时间 = I * CPI / f = 5.6 * 10 ^ -8; MIPS = f / (CPI * 10 ^ 6) = 17.86
- 答：解答正确，注意CPU执行时间的单位是秒

3.
- 解：
    1. T = 1 / f = 1.25 * 10 ^ -7秒
    2. T = 1 / 0.4MIPS =  2.5 * 10 ^ -6秒
    3. 0.4MIPS = f / CPI * 10 ^ -6, 解得CPI = 20; 平均指令执行速度 = 1 / (CPI * T) = 12 * 10 ^ 6 / 20 = 6 * 10 ^ 5
- 答：解答正确。所谓“平均指令执行速度”，其实就是在说MIPS，最后的写法也建议写成MIPS的形式

4.
- 解：老CPI：1.57；新指令总数：0.79M + 0.21M * 0.75 = 0.9475M, CPI = ...
- 答：新指令总数算错了。算术逻辑和Load指令都是减去0.43 * 0.25M，新增的新算术逻辑指令也是0.43 * 0.25M

错题总结：
- 兼容指计算机软件**或**硬件的通用性
- 单片机（Single-Chip Microcomputer）是一种集成电路芯片，是采用超大规模集成电路技术把具有数据处理能力的中央处理器CPU、随机存储器RAM、只读存储器ROM、多种I/O口和中断系统、定时器/计数器等功能（可能还包括显示驱动电路、脉宽调制电路、模拟多路转换器、A/D转换器等电路）集成到一块硅片上构成的一个小而完善的微型计算机系统，在工业控制领域广泛应用

#### 本章小结

- 机器语言和汇编语言与机器指令对应，而高级语言不与指令直接对应，具有较好的可移植性。其中机器语言可以被硬件直接执行
- 翻译程序分为编译程序和解释程序，汇编程序则是特指从汇编语言翻译到机器语言的程序
- *字长 = 机器字长，指令字长 = 一个指令字中包含的二进制代码的位数，存储字长：一个存储单元存储的二进制代码的位数，若指令字长是存储字长的2倍，则需要两个访存周期来取出一条指令（这条划掉。详见知乎：https://www.zhihu.com/question/293885327）*
- 两台机器指令系统相同时，只能认为它们具有相同的结构，至于这两台机器**如何实现其指令**，完全可以不同，即可以认为它们的组成方式是不同的。例如，一台机器是否具备乘法指令是一个**结构**的问题，但实现乘法指令采用什么方式则是一个**组成**的问题。许多计算机厂商提供一系列体系结构相同的计算机，而它们的组成却有相当大的差别，即使是同一系列的不同型号机器，其性能和价格差异也很大

### <a name="5">（二）数据的表示和运算</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）数制与编码

进位制数及其相互转换:
- 二进制编码：两种状态，容易与物理状态对应；位数有限时不能表示循环小数；运算规则简单，适合用布尔代数设计电路，制造成本低
- 数制转换
    - 二进制转十进制：加权展开
    - 十进制到二进制：整数除2取余，先余为低；小数乘2取整，先整为高
    - 二进制转8进制或16进制：从小数点向左右3/4位一分组

BCD码：
- 8421码：1010到1111是无效码，要加6修正
- 余3码：8421码的基础上每种编码加3
- 2421码：也是一种有权码，权值由高到低分别为2,4,2,1，特点是大于等于5的4位二进制数中最高位为1，小于5的最高位为0

机器码：**在现代计算机中，通常用定点补码整数表示整数，用定点原码小数表示浮点数的尾数部分，用移码表示浮点数的阶码部分。补码是重点，会结合代码，指令格式（立即数，相对寻址）进行考察！**
- 原码：存在正零和负零两个零
- 反码：当真值为正数时，反码和原码相同；当真值为负数时，数值部分要逐位取反。也存在正零和负零两个零。主要用于求补
- 💎补码：*数据表示建立在“模”的概念基础上，模的值即为符号位进位的权值*
    - 模2的补码：定点小数模值为2，定点整数模值为2 ^ ( n + 1 )
    - 模4的补码：变形补码，定点小数模值为4，定点整数模值为2 ^ ( n + 2 )，其中**n为数值位位数**
    - 当真值为负数时，补码等于真值加上模
    - 在数轴上的表示区间不对称：机器零唯一，最左侧比原码、反码多表示一个最小负数
    - 补码符号位可以直接参与加减运算，运算电路实现方便，因此计算机中整数采用补码进行存储、表示和运算
    - 补码和真值之间的转换：正数与原码一致，**负数都遵循“数值位逐位取反、末尾加一”的规则**
- 移码：
    - 只用于表示整数，也称偏移码，真值 + 常量
    - 方便比较大小，数字越大，真值越大
    - **移码和补码的符号位相反，数值位相同**
    - 用于表示浮点数的阶码
- 机器码表示范围（只需记住补码公式，加模数）：
![](https://api2.mubu.com/v3/document_image/8274186f-11f0-4065-8723-aafe9a0220e4-329792.jpg)
- 机器码在数轴上的表示（对比理解）：
![](https://api2.mubu.com/v3/document_image/d971313c-94f7-483b-ad4f-a9f500063e43-329792.jpg)

**王道习题：**

一轮标记题：1 3 4 7 13 14 17 25 26 28 29 30

二轮重做：17

错题总结：
- 使用补码表示时，若符号位相同，则数值位越大码值越大

#### （2）定点数和浮点数的表示和运算

定点数的表示：
- 定点数概念：小数点位置固定的数
- 定点数分类
    - 有符号数、无符号数：机器码到底有无符号取决于输出形式。C语言中printf中%d输出，%u表示无符号
    - 定点整数和定点小数：
        - 定点小数：小数点隐含在符号位之后，有效数值部分最高位之前
        - 定点整数：小数点在有效数值部分最低位之后
    - 溢出问题：
        - 定点整数存在上溢问题（超出表示范围）
        - 定点小数存在精度溢出问题（超出表示精度）

**定点数的移位运算：**
- 算术移位：**符号位保持不变**

符号|码制|添补代码
:-:|:-:|:-:
正数|原码、补码、反码|0
负数|原码|0
负数|补码左移|0
负数|补码右移|1
负数|反码|1

- 逻辑移位：将操作数视为无符号数，不管左移还是右移，都补0
- 循环移位：
    - 带进位标志位CF（大循环）：CF参与循环
    - 不带CF（小循环）：CF存储最新移出的数字的副本

原码定点数的加减运算（没考过）：
- 符号位不能直接参与运算
- 加法运算需要“同号求和，异号求差”
- 减法运算需要“异号求和，同号求差”
- 求差时还需要先比较大小，然后用大数减去小数
- 结果的符号选择也相对复杂，运算复杂

**补码定点数的加减运算：**
- 运算公式：设机器字长为n + 1：
    - [A + B]补 = [A]补 + [B]补 (mod 2 ^ (n + 1))
    - [A - B]补 = [A]补 + [-B]补 (mod 2 ^ (n + 1))
- 运算规则：
    - 操作数采用补码表示，符号位参加运算
    - 运算的结果为补码，符号位的进位位（模）直接丢弃

定点数的乘法运算（几乎没考）：
- 原码乘法运算：
    - 运算过程见改错本p1
    - 符号位单独运算
    - 被乘数取双符号位，右移n次，加n次
- 补码乘法运算（Booth算法）：
    - 运算过程见改错本p1
    - 符号位参与运算
    - 被乘数取双符号位，乘数取单符号位，末尾增加一附加位，右移n次，加n + 1次
- 原码除法运算（恢复余数法）：
    - 循环次数不固定，不利于机器控制
- 原码除法运算（不恢复余数法）：
    - 运算过程见改错本p2
    - 符号位单独运算
    - 被除数（余数）和商均为单符号位，左移n次，加n + 1次
    - 第n + 1步的余数为负时，需要加上|Y|得到正确的余数
- 补码除法运算（加减交替法）：
    - 运算过程见改错本p3
    - 符号位参与运算
    - 被乘数取双符号位，乘数取单符号位，左移n次，加n + 1次
    - 若对商的精度没有特殊要求，则一般采用“末位恒置1”法

💎**溢出的概念和判别法**：*仅当两个符号相同的数相加或两个符号相异的数相减才可能产生溢出（可用来快速判断）*
- 采用一位符号位：由于减法运算是用加法器实现的，因此只需遵循加法的溢出规则“正正得负，负负得正”即可：
![](https://api2.mubu.com/v3/document_image/eb154771-892b-493a-af75-e7b4c4a8cfaa-329792.jpg)
- 采用双符号位：00正数，01正溢出，10负溢出，11负数。主要用于手工计算，方便肉眼识别，计算机因为成本问题不采用
- 采用一位符号位根据数据位的进位情况判断溢出：若符号位的进位Cn和最高数位的进位Cn-1相同，则说明没有溢出，否则表示发生溢出，即：OF = Cn ⊕ Cn-1

**王道习题：**

一轮标记题：4 10 11 14 15 19 22 25 26 27 31 33 35 38 43

二轮重做：14 26 27 38 41 43(溢出、进位/借位的快速判断?)

大题：1 2 8

1.（加入改错本）
- 解：全部算错！32位数是-2147483648 ~ 2147483647！
- 答：
    1. 2 ^ 31 + 2 ^ 2; 2 ^ 30 + 2; 4000 0002H; **2 ^ 32 + 2 ^ 3, 发生溢出**; 0000 0008H
    2. -(2 ^ 31 - 2 ^ 2); -(2 ^ 30 - 2); C000 0004H; **(2 ^ 32 - 2 ^ 3), 发生溢出**; 0000 0008H

2.
- 解：
    1. 86H; 90H; 7CH;
    2. -122; -112
    4. 最后一条语句执行时会发生溢出，理由略
- 答：
    3. 能。n位加法器实现的是模2^n无符号整数加法运算。对于无符号整数a和b，a + b可以直接用加法器实现，而a-b可用a加b的补数实现，所以n位无符号整数加减运算都可在n位加法器中实现；由于有符号整数用补码表示，补码加减运算公式为[a + b]补 = [a]补 + [b]补 (mod 2 ^ n)，[a - b]补 = [a]补 + [-b]补 (mod 2 ^ n)，所以n位有符号整数加减运算都可在n位加法器中实现

3.
- 解：0.1001; 0.1101

4.（加入改错本）
- 证明：采用定点小数表示，条件为|X<1|，|Y<1|，|X+Y<1|，所以要分4种情况证明
- 解析：**本题考查定点小数补码的定义，需牢记！**

5.
- 解：0010

6.
- 解：0.1110

7.
- 解：
    1. BCH, B0H;
    2. 6CH, OF = 1, SF = 0
    3. 0CH, OF = 0, SF = 0

8.（不加入改错本，但要复习！）
- 解：
    1. 乘法指令可以通过Booth算法利用加减和位移等指令实现
    4. 带符号和无符号均为: FF FF FF FEH; umul()没有溢出，mul()溢出
- 答：
    1. 乘法运算可以通过加法和移位来实现。编译器可以将乘法运算转换为一个循环代码段，在循环代码段中通过比较、加法和移位等指令实现乘法运算
    2. 控制逻辑的作用是控制循环次数，控制加法和移位操作
    3. **a)最长，c)最短。对于a)，需要用循环代码段（即软件）实现乘法操作，因而需要反复执行很多条指令，而每条指令都需要取指令、译码、取数、执行并保存结果，所以执行时间很长；对于b)和c)，都只需用一条乘法指令实现乘法操作，不过b)中的乘法指令需要多个时钟周期才能完成，而c)中的乘法指令可在一个时钟周期内完成，所以c)的执行时间最短**
    4. 应该是00 00 00 00 FF FF FF FEH。umul()没有溢出，mul()溢出。对于无符号整数乘法运算，高n位全为0就足以说明运算结果没有溢出，否则溢出，理由略

错题总结：
- 三种溢出判别方法，均须有溢出判别电路，可用“异或”门来实现
- 存储模4补码仅需一个符号位，因为任何一个正确的数值，模4补码的两个符号位总是相同的。只在把两个模4补码的数送往ALU完成加减运算时，才把每个数的符号位的值冏时送到ALU的双符号位中，即只在ALU中采用双符号位
- 来自26题的B选项，非常复杂，三轮可以直接跳过，只记结论：**对于补码的不恢复余数除法，同号相除时**，那就和符号位不参与运算的原码不恢复余数法没有区别，也就是说，**够减（余数为正）商1，不够减（余数为负）商0；异号相除时**，则相反，**够减商0，不够减商1**。好奇推理过程，可参考：https://blog.csdn.net/H_define/article/details/125877290
- 补码表示时，正数的符号位为0，左移最高位为0时，数据不会丢失；负数的符号位为1，左移最高位为1时，数据也不会丢失。也就是说，左移移走的最高位要与符号位相同（才不会溢出）
- 大题第1题：网友-Jjonak：王道写的真误导人啊，讲课也没讲明白，直接就是一句符号位不动，数值位移动，做题目发现不对劲，查了查发现是**符号位也移动，只是没溢出的情况下符号位就好像没移动的意思**

**浮点数的表示：**
- 表示方法：N = ((-1) ^ S) × (R ^ E) × M
    - 数符 S：取值0或1，用来决定浮点数的符号
    - 阶码/指数 E：一个二进制定点整数，一般用移码表示
    - 尾数 M：一个二进制定点小数，一般用定点原码小数表示
    - 基数（隐含） R：可以约定为2、4、16等
    - 阶码的值反映浮点数的小数点的实际位置，阶码的位数反映浮点数的表示范围，尾数的位数反映浮点数的精度
    - **浮点数的表示法也不止上面这一种，比如阶码也可以用原码表示，但比较统一的一点是，阶码往往在尾数的前面**
- 溢出问题：
    - 存在正上溢和负上溢（统称为上溢）问题（此时计算机必须进行中断处理）
    - 存在正下溢和负下溢（统称为下溢）问题（此时浮点数值趋于零，计算机仅将其当作机器零处理）
    - 也存在精度溢出问题（无法精确表示，只能舍入处理）
- 尾数规格化：调整尾数和阶码，保证尾数最高位是有效值1，这样可以提高运算精度，充分利用尾数有效位
    - 左规：尾数左边无效位太多，往左移，左规可多位。阶码减少，尾数增大
    - 右规：尾数运算溢出时要进行右规，右规最多一位。阶码增加，尾数减小
    - 原码规格化数（绝对值大于等于0.5）
        - 正数：0.1xxx
        - 负数：1.1xxx
        - 尾数最高位为1
    - 补码规格化数
        - 正数：0.1xxx
        - 负数：1.0xxx（注意：补码的-0.5不是规格化数，且补码下限可以为-1）
        - 符号位和尾数最高位相反
        - **大多数题目在规格化时都是IEEE754浮点数，但某些题目可能会指定尾数或阶码采用补码表示。通常采用双符号位，当尾数求和结果溢出（如尾数为10.××···×或01.××···×）时，需右规一次；当结果出现00.0××···×或11.1××···×时，需要左规，直到尾数变成00.1××···×或11.0××···×**
    - *基数不同，浮点数的规格化形式也不同。浮点数尾数的基数为2时，原码规格化数的尾数最高位一定是1。基数为4时，原码规格化形式的尾数最高两位不全为0*
- 浮点数在数轴上的分布：
    - 刻度并不均匀，越往右，浮点数越稀疏
![](https://api2.mubu.com/v3/document_image/95e59a35-5996-4253-b34e-dba717048f00-329792.jpg)
- 浮点运算不满足结合律：
    - 小数a + 大数b = 大数b（有可能）
    - 编程时浮点数比较要小心

**💎IEEE754标准：**
- 二进制浮点数
    - 数符S、阶码E和尾数M
    - 阶码采用移码表示
    - 尾数采用原码数据表示：隐藏高位1，运算时还原成1.M形式
    - 二进制浮点数无法精确表示一些十进制小数（0.1 0.2 0.4等转换成二进制都是循环小数）
    - 对32位单精度格式而言：S为1位，E为8位，采用偏移值为127的移码，M为23位
![](https://api2.mubu.com/v3/document_image/91eaba8b-3da0-4775-8fb7-ef9e3d1b9949-329792.jpg)
- 十进制浮点数
    - 可精确表示十进制浮点数，保证运算精度
    - 解决二进制浮点运算引起的误差问题
    - IEEE-754 2008标准中有定义
- IEEE754表示范围
    - **阶码为全1时，表示无穷大或非数，即：浮点数除零不会异常**
    - **阶码和尾码全零时表示机器零**
    - *阶码为零，尾数不为零时表示非规格化数*
    - *其他表示区间为规格化数*
    - 各类区间及浮点数的最大值、最小值问题：注意，0.111···1 = 1 - 2 ^ 23（常考）；注意，单精度非规格化是-126
![](https://api2.mubu.com/v3/document_image/d5bcad7b-9e5e-4969-921e-a55562f4106f-329792.jpg)
![](https://api2.mubu.com/v3/document_image/b0ed425c-8d6f-4e13-bbad-3b76df3ed2db-329792.jpg)

**💎浮点数加减运算（难）：**
- 对阶
    - 小阶向大阶看齐
    - 阶码增加，尾数右移
- 尾数运算
- 规格化
    - 尾数运算上溢：右归最多一位
    - 尾数规格化下溢：左归处理，可以多位
- 舍入处理
    - 0舍1入：舍去位最高位为1，尾数最低位加1，否则舍去。这样可能会使尾数溢出，此时需要再做一次右规
    - 恒置1法：舍去中有一位是1，尾数最低位置1
    - 截断法：直接截取所需位数，丢弃后面的所有位
- 溢出判断
    - 浮点数的溢出并不是以尾数溢出来判断的，尾数溢出可以通过右规操作得到纠正。运算结果是否溢出主要看结果的指数是否发生了上溢，因此是由阶码上溢来判断
    - 上溢：进入异常处理
    - 下溢：按机器零处理
- 注意IEEE754浮点数与采用补码表示阶码和尾数的浮点运算法则的相同和不同之处，考研有真题考到过！

**程序中的数据表示与运算（常考）：**
- 汇编语言中的数据类型
    - 寄存器、存储器操作数本没有数据类型
    - 对该数进行何种数据类型的操作完全取决于指令功能
    - 有符号运算、无符号运算、定点运算、浮点运算指令
- 💎C语言中数据类型
    - 整型
        - 有符号整型包括char、short、int、long
        - 分别采用8、16、32、64位补码进行表示
        - 通过unsigned声明为无符号类型
    - 整型运算溢出问题
        - 有符号整数和无符号整数、浮点数都存在运算溢出的问题
        - C语言不做溢出判断，需要程序员特别注意
    - 浮点型
        - C语言中常见的浮点数为float、double
        - 分别对应IEEE 754中的单精度和双精度浮点数
        - 不同数据类型的运算会在编译器的翻译下变成不同类型的汇编指令
    - 💎强制类型转换（难）
        - 相同位宽的整型数据进行强制转换时机器码保持不变
        - 小字长转大字长时，无符号整型进行零扩展，有符号整型进行符号扩展
        - 大字长转小字长时直接将机器码截短
        - float → double：由于double型数据的尾数、阶码宽度都比float型大，因此其表示范围更大、精度更高，转换后的 double 型数据与原 float 型数据完全相等
        - double → float：大数转换时可能发生溢出，高精度数转换时会发生舍入
        - float/double → int：小数部分会截断，大数转换时可能会溢出
        - int → float：两种类型都是 32 位，所表示的状态数是一样的，在数轴上表示的数据并不完全重叠，float 型用其中一部分状态表示了更大的整数和小数；- int 型中一些比较大的整数无法用float型精确表示。浮点数尾数连隐藏位在内一共24位，当int型数据的24～31位数据非0时，无法精确转换成 24 位浮点数的尾数，此时会发生精度溢出，需要进行舍入处理
        - int → double：浮点数尾数字段为 53 位，可以精确表示所有 32 位整数
        - 一些很有用的例子，回去慢慢看：
![](https://api2.mubu.com/v3/document_image/27750e8a-60b9-4faa-a47c-60a6d749286e-329792.jpg)

**王道习题：**

一轮标记题：5 7 10 12 13 14 17 20 21 22 23 24 25 27 28 29 30

二轮重做：5 7 17 21

大题：4 5 7 8

1.
- 答：
    - 阶码上溢出。一个正指数超过了最大允许值时，浮点数发生上溢出（即向 ∞ 方向溢出)。若结果是正数，则发生正上溢出（有的机器把值置为 +∞ ）；若结果是负数，则发生负上溢出（有的机器把值置为 -∞ ）。这种情况为软件故障，通常要引入溢出故障处理程序来处理
    - 阶码下溢出。一个负指数比最小允许值还小时，浮点数发生下溢出。一般机器把下溢出时的值置为 0（+0或-0）。不发生溢出故障
    - 尾数溢出。当尾数最高有效位有进位时，发生尾数溢出。此时，进行“右规”操作：尾数右移一位，阶码加 1，直到尾数不溢出为止。此时，只要阶码不发生上溢出，浮点数就不会溢出
    - 非规格化尾数。当数值部分高位不是一个有效值时（如原码时为 0 或补码时与符号位相同），尾数为非规格化形式。此时，进行“左规”操作：尾数左移一位，阶码减1，直到尾数为规格化形式为止

2.
- 解：略

3.
- 解：1)ture; 2)不一定true; 3)true; 4)不一定true

4.
- 解：1)好困，三刷的时候再算吧

5.
- 解：1)同上

6.
- 答：两个n位数的加减运算，其和/差最多为n+1位，因此有可能需要右规，但右规最多一次。由于异号数相加或同号数相减，其和/差的最少位数无法确定，因此左规的次数也无法确定，但最多不会超过尾数的字长n位次

7.
- 解：
    - 1)机器零，+0
    - 2)48
    - 3)非规格化数，-2 ^ -127
    - 4)负无穷大

8.
- 解：
    1. 会，原因略；不会，原因略；
    2. 相等；f1(23)返回值的机器数为00 FF FF FFH, f2(23)返回值的机器数为4B 7F FF FFH
    3. 浮点数的精度不够
    4. 超出int范围，溢出了；30
    5. 正无穷；126；23


错题总结：
- **对阶操作，是将较小的阶码调整到与较大的阶码一致，因此不存在阶码减小、尾数左移的情况**
- 与非规格化浮点数相比，采用规格化浮点数的目的主要是为了增加数据的表示精度
- 舍入是浮点数的概念，定点数没有舍入的概念。浮点数舍入的情况有两种：对阶、右规格化（注意，**右规可能引起阶码上溢，但对阶没这个可能**）。舍入不一定产生误差，如向下舍入11.00到11.0时是没有误差的
- 各类区间及浮点数的最大值、最小值问题：注意，0.111···1 = 1 - 2 ^ 23（常考）；注意，单精度非规格化，阶码是-126，没有隐含的高位1

#### （3）算术逻辑单元ALU

一位全加器：全加器（FA）是最基本的加法单元，逻辑表达式和逻辑电路如下：
![](https://api2.mubu.com/v3/document_image/d4b7af6f-4584-4804-b25b-82dbe4691705-329792.jpg)
![](https://api2.mubu.com/v3/document_image/e7354005-28dc-4b31-aad7-09d1c2c20423-329792.jpg)

**1）串行加法器和并行加法器**
串行加法器：
串行进位加法器：把n个加法器相连。串行进位又称行波进位，因为每级进位直接依赖于前一级的进位，即信号是逐级形成的。因此，**该加法器的运算速度和位数是线性关系**，位数越多，延迟时间就越长，而全加器本身的求和延迟只是次要因素。逻辑电路如下，注意其中的异或电路需要3T：
![](https://api2.mubu.com/v3/document_image/3eacad7e-b067-4be0-bb28-e2cbb58616f2-329792.jpg)
可控加减法电路：减法变加法，输入增加异或门，控制位送进位输入，逐位取反，末位加1。有符号无符号运算均适用，区别是溢出检测逻辑。逻辑电路如下：
![](https://api2.mubu.com/v3/document_image/4ab15384-9327-424e-ac65-4785220b98f7-329792.jpg)

并行加法器：
- 主要原理：采用先行进位电路提前得到所有进位位。因此，各位的求和运算可以并发运算。注意：先行进位电路也有开销和时间延迟
- 进位生成函数：
![](https://api2.mubu.com/v3/document_image/c28f2020-0709-4abd-8f1b-2032abfb35f8-329792.jpg)
- 进位传递函数：
![](https://api2.mubu.com/v3/document_image/7716ed85-94d2-4f8c-b49a-92ca21c371bc-329792.jpg)
- 进位信号仅仅与G，P，C0有关：
![](https://api2.mubu.com/v3/document_image/7dc167b8-b1ca-43a8-bc56-53a8c603f331-329792.jpg)
- 先行进位电路：
![](https://api2.mubu.com/v3/document_image/a96cee4e-04af-4fd9-8da2-4d699e861e40-329792.jpg)
- 四位快速加法器：
![](https://api2.mubu.com/v3/document_image/4d2ac825-0803-40cf-9ac5-45657dd1977c-329792.jpg)
- 先行进位电路级联：
![](https://api2.mubu.com/v3/document_image/4d959d83-ab59-4a96-9c0e-b602a6faa840-329792.jpg)
- 两级或多级先行进位方式：组内**并行**，组间**并行**

带标志加法器：增加生成相应的标志信息的逻辑电路：
- 溢出标志的逻辑表达式为OF = Cn ⊕ Cn-1，OF= 1表示带符号整数运算时发生溢出。对于无符号数运算，OF没有意义
- 符号标志就是和的符号，即SF = Fn-1，表示结果的符号，即F的最高位。对于无符号数运算，SF没有意义
- 零标志ZF = 1当且仅当F = 0，不管对于无符号数还是带符号整数运算，ZF都有意义
- 进位 / 借位标志CF =Cout ⊕ Cin（或者是记作Sub），即当Cin = 0（加法）时，CF为进位Cout，当Cin = 1（减法）时，CF为进位Cout取反。对于带符号数运算，CF没有意义

**2）算术逻辑单元ALU的功能和结构**
- 定点运算器
    - 算术逻辑运算单元ALU：算术逻辑运算单元是运算器的核心，由它实现算术逻辑运算
    - 通用寄存器组：通用寄存器组的作用是暂存参加运算的数据、运算的中间结果或最后结果
    - 输入选择电路：输入选择电路的作用是对若干个数据的输入进行选择或控制
    - 输出控制电路：输出控制电路对加法器的输出进行控制
- 💎运算器结构
    单总线结构：2个缓冲器，3个时钟完成运算
    双总线结构：1个缓冲器，2个时钟完成运算
    三总线结构：0个缓冲器，1个时钟完成运算
- 运算流水线
    - 浮点流水线，将浮点运算的步骤进行细分
    - 不提升单个运算的性能，优化密集型浮点运算性能
![](https://api2.mubu.com/v3/document_image/dba9a987-352f-4265-b9fa-abe403fc12f8-329792.jpg)

#### （4）其他

**字符与字符串：**

- ASCII码：国际通用的字符码，7位表示 128 个字符。实际占用 1 个字节，最高有效位 MSB = 0。有 33 个控制字符，其余为可打印字符：
    - 20H 开始是空格等可打印字符
    - 0 ～ 9 这 10 个数字是从 30H 开始的一个连续区域
    - 大写英文字母是从 41H 开始的一个连续区域
    - 小写英文字母是从 61H 开始的一个连续区域
- 汉字编码：
    - 输入码：汉字的输入。拼音，五笔等
    - 机内码：汉字的存储。GB2312、GBK、GB18030、Unicode、BIG5等标准
    - 字形码：汉字的输出
    - GB2312：
        - 区位码：矩阵形式，由4位十进制数构成，前2位区码，后2位位码
        - 汉字机内码：区位码（16进制）+ A0A0H（为区分ASCII码，MSB = 1），即：GB2312汉字占用两个字节，有效位14位
- 字符串：以"\0"结束的字符序列

#### 本章小结

- 用移码表示浮点数的阶码有什么好处？
    - 浮点数进行加减运算时要比较阶码的大小，移码比较大小更方便
    - 检验移码的特殊值（0和max）时比较容易。阶码以移码编码时的特殊值如下。0：表示指数为负无穷大，相当于分数分母无穷大，整个数无穷接近0，在尾数也为0时可用米表示0；尾数不为零表示未正规化的数。max：表示指数正无穷大，若尾数为0，则表示浮点数超出表示范围（正负无穷大）；尾数不为0，则表示浮点数运算错误
- 计算机内部的数值数据并非都是二进制数。在计算机内部，数值数据的表示方法有以下两大类：
    - 直接用二进制数表示。分为有符号数和无符号数，有符号数又分为定点数表示和浮点数表示。无符号数用来表示无符号整数（如地址等信息)
    - 二进制编码的十进制数，一般采用BCD码表示，用来表示整数
- 什么称为无符号整数的“溢出”？实际上，对于无符号定点整数来说，若寄存器位数不够，则计算机运算过程中一般保留低n位，舍弃高位。这样，会产生以下两种结果：
    - 保留的低n位数不能正确表示运算结果。在这种情况下，意味着运算的结果超出了计算机所能表达的范围，有效数值进到了第n+1位，称此时发生了“溢出”现象
    - 保留的低n位数能正确表达计算结果，即高位的舍去并不影响其运算结果
- 现代计算机中是否需要考虑原码加减运算？如果要，如何实现？
    - 因为现代计算机中浮点数采用IEEE 754标准，所以在进行两个浮点数的加减运算时，必须考虑原码的加减运算，因为IEEE 754规定浮点数的尾数都用原码表示。原码的加减运算可以有以下两种实现方式：
        - 1）转换为补码后，用补码加减法实现，结果再转换为原码
        - 2）直接用原码进行加减运算，符号和数值部分分开进行

### <a name="6">（三）存储器层次结构</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）存储器的层次化结构

存储器分类：
- 按介质分
    - 磁存储器：机械装置，速度较慢，单位成本较低
    - 半导体存储：电子设备，速度快，单位成本高
    - 光存储器：便于携带，成本低廉，适合电子出版
- 按存取方式分
    - 顺序（串行访问）存储器：访问时间与存储单元位置有关，如磁带
    - 随机存储器：访问时间与存储单元位置无关，如半导体
    - 直接存储器：顺序、随机的折中，如磁盘、光盘
- 按信息的**可改写性**分
    - 读写存储器RAM
    - 只读存储器ROM
- 按信息的**可保存性**分
    - 易失性：掉电数据丢失，如SRAM，DRAM等
    - 非易失性：掉电数据不丢失，如磁盘，闪存等
- 按存储功能和速度分：寄存器、cache、主存、外存等

**主要技术指标：**
- 存储容量：存储器可以存储的二进制信息总量
- 存取时间：启动一次存储器的操作到该操作完成所经历的时间
- **存取周期：**
    - 又称**读写周期**或**访问周期**或**存储周期**
    - 连续启动两次访问操作之间的最短时间间隔
    - 存储周期大于存取时间，用户读写操作后复原
- 存储器带宽：单位时间内存储器所能传输的信息量

**存储器的层次化结构：**

- 存储器的层次结构
  - 理想存储器
    - 速度快、容量大、成本低（做梦）
  - 基本原理
    - 💎利用程序局部性的原理，从系统级将速度、容量、成本各异的存储器有机组合在一起，从而全方位优化存储系统的各项性能指标，构建理想存储器
    - 上层给下层做缓冲，提升命中率，让数据尽量在上层访问，详见cache机制
    - 现代计算机系统几乎都采用这种三级存储系统。需要注意的是，主存和Cache之间的数据调动是由硬件自动完成的，对所有程序员均是透明的；而主存和辅存之间的数据调动则是由硬件和操作系统共同完成的，对应用程序员是透明的
  - 层次结构![img](https://api2.mubu.com/v3/document_image/24bf5abb-4196-49c2-854e-2396a4af972e-329792.jpg)

**王道习题：**

一轮标记题：7 12

二轮重做：12

大题：2

1.
- 解：90% × 5ns + 10% × x = 12ns，解得x = 75ns

2.
- 解：牢记：*Cache/主存系统效率 = 访问Cache时间 / 平均访问时间*，这里平均时间为60ns，所以效率为83.3%

错题总结：
- 若采用**同时**访问Cache和主存的方式，则不命中的访问时间就是访问主存的时间，但若题设中没有说明(通常会说明)，则默认Cache不命中的时间为访问Cache和主存的时间之和

#### （2）主存储器与CPU的连接

主存的基本结构：
- 原理图![img](https://api2.mubu.com/v3/document_image/9bb46d83-e010-43fe-8e37-316b79e1ab1e-329792.jpg)
- 💎地址与容量关系
    - 地址译码器
        - 最小项生成器
        - 给出一个地址，只有唯一一根输出有效，选中一个存储体单元      
    - n位地址经过译码器产生2 ^ n个译码线   
    - 已知容量为C，地址线根数为log2C
    - C语言中的指针实际就是内存单元地址，所有指针变量是**无符号类型**
- 存储器芯片的组成
    - 存储体+IO/读写电路+地址译码器+片选控制信号+读写控制信号
    - 读RD/写WR控制线：决定芯片是进行读还是写操作
    - 片选线CS：确定哪个存储芯片被选中。可用于容量扩充
    - 引脚最低数目 = 片选线（至少1）+ 控制线（1或2, 读RD写WR）+ 数据线 + 地址线

💎主存中数据的存放：
  - 存储单元
    - **存储单元的大小和机器字长相关**
    - **一个存储周期可以访问一个机器字长的存储单元（关于存储字长，这个词大概率是个已经被淘汰或者说根本不存在的词语！详见知乎：https://www.zhihu.com/question/293885327）**
    - 64位计算机一次可以访问64位的数据
  - 💎地址访问模式
    - **存储单元可按不同的大小访问**（**都是一个存储周期**）
    - 百度百科：**存放一个机器字的存储单元，通常称为字存储单元，相应的单元地址叫字地址。而存放一个字节的单元，称为字节存储单元，相应的地址称为字节地址。如果计算机中可以编址的最小单元是字存储单元，则该计算机称为按字寻址的计算机**。如果计算机中可编址的最小单位是字节，则该计算机称为按字节寻址的计算机。如果机器字长等于存储器单元的位数，一个机器字可以包含数个字节，所以一个存储单元也可以包含数个能够单独编址的字节地址。例如一个16位二进制的字存储单元可存放两个字节，可以按字地址寻址，也可以按字节地址寻址。当用字节地址寻址时，16位的存储单元占两个字节地址
    - 王道：**地址码相同**的多个存储元（存放一个二进制位的物理器）构成一个存储单元
      - 字节访问、半字访问、字访问（机器指令支持）
      - 字节地址、半字地址、字地址
        - 实际计算机中只有字节地址
        - 半字地址 = 字节地址 << 1（相对字节地址少1根）
        - 字地址 = 字节地址 << 2（相对字节地址少2根）    
    - 不同地址访问模式![img](https://api2.mubu.com/v3/document_image/d86e9af0-38f8-4879-9fde-d559dbc27f89-329792.jpg)
  - 💎大端小端方式
    - 小端方式：存储器的低字节地址单元中存放的是数据的最低字节
    - 大端方式：存储器的低字节地址单元中存放的是数据的最高字节
  - 💎数据的边界对齐
    - 有利于减少访问时间，但会造成主存空间浪费
    - short按双字节对齐
    - float类型按4字节对齐
    - double按8字节对齐
    - 复杂数据结构也会考虑对齐问题

**主存储器与 CPU 的连接：**
- 💎存储扩展
  - 位扩展：（数据总线扩展）
    - 数据总线宽度不匹配：字位扩展 = 字长扩展 = 数据总线扩展
      - 多芯片并发：提供更多的数据位
      - 📈字长扩展原理图
        - ![img](https://api2.mubu.com/v3/document_image/add319f8-9fbd-411f-b719-8a7c8a54be8d-329792.jpg)
  - 字扩展：（地址总线控制）
    - 地址总线宽度不匹配：字数扩展 = 容量扩展 = 地址总线扩展
      - 高位用译码器进行芯片片选
        - 如果低位片选就变成了交叉编制模式
        - 译码器的功能就是最小项生成器
      - 多芯片串行：同一时刻只有一个芯片工作
      - **需明确每个存储芯片在全局范围内的地址空间**
      - 字数扩展原理图
        - ![img](https://api2.mubu.com/v3/document_image/dfb29104-4172-4b74-a1ab-c5ddaf83b2d9-329792.jpg)
  - 字位同时扩展
    - 二者都不匹配：综合扩展
      - 📈![img](https://api2.mubu.com/v3/document_image/c016dbb5-adfd-4215-ab20-c11dbfa90494-329792.jpg)
- 存储芯片的地址分配和片选
    - 先片选，再字选
    - 片选又分为线选法和译码片选法，注意前者是低电平有效
- 存储器与 CPU 的链接
    1. 合理选择存储芯片：ROM存放系统程序、标准子程序和各类常数，RAM为用户编程设置
    2. 地址线的连接：CPU地址线低位与存储芯片的地址线相连，高位连接译码器用于片选
    3. 数据线的连接
    4. 读/写命令线的连接：有些CPU的读/写命令线是分开的（读为RD，写为WE，均为低电平有效），此时CPU的读命令线应与存储芯片的允许读控制端相连，而CPU的写命令线则应与存储芯片的允许写控制端相连
    5. 片选线的连接：片选有效信号与CPU的访存控制信号MREQ（低电平有效）有关，因为只有当CPU要求访存时，才要求选中存储芯片。若CPU访问IO，则MREQ为高，表示不要求存储器工作

双口RAM和多模块存储器：
  - 双端口存储器
    - 一个存储器，两套独立读写逻辑，带宽提升一倍
    - 两端口存在访问冲突
      - 同一单元同时写
      - 同一单元一读一写
    - 图解
      - ![img](https://api2.mubu.com/v3/document_image/22e50af8-7a90-452c-89c5-d04dd5524d3e-329792.jpg)
  - 单体多字存储器
    - 一个地址，多个存储字，多个存储单元并发
    - 扩大了数据总线宽度
    - 双通道内存
      - 📈联动模式和非联动模式双通道内存![img](https://api2.mubu.com/v3/document_image/9ef46be6-5dc6-4909-8764-38fd6fb9af56-329792.jpg)
  - 多体交叉存储器
    - 顺序编址：高位片选，用于扩充容量，存在单点故障
    - 交叉编址：低位片选，用于提升速度（提高带宽），流水方式访问
        - 计算：**设模块字长等于数据总线宽度**，模块存取一个字的存取周期为T，总线传送周期为r，为实现流水线方式存取，存储器交叉模块数应大于等于**m=T/r**，式中，**m称为交叉存取度**。每经过r时间延迟后启动下一个模块，交叉存储器要求其模块数必须大于等于m，以保证启动某模块后经过 m × r 的时间后再次启动该模块时，其上次的存取操作已经完成（即流水线不间断）。这样，连续存取m个字所需的时间为**T+(m-1)r**
        - 对比：顺序方式连续读取m个字所需的时间为mT。可见低位交叉存储器的带宽大大提高
    - 📈图解
      - ![img](https://api2.mubu.com/v3/document_image/444f9292-c04c-41f3-820e-98ebdecbedc7-329792.jpg)

**王道习题：**

一轮标记题：10 13 14 17

二轮重做：14(看不懂题目:X) 16 17

大题：3 5

1.
- 解：
    - 在主存储器中，地址寄存器MAR用来存放当前CPU访问的内存单元地址，或存放CPU写入内存的内存单元地址。数据寄存器MDR用来存放由内存中读出的信息或写入内存的信息
    1. 按字节编址，1MB = 2^20×8位，地址寄存器为20位，数据寄存器为8位，编址范围为00000H ~ FFFFFH (FFFFFH - 00000H + 1 = 100000H = 2^20)
    2. 按字编址，1MB = 2^18x32位，地址寄存器为18位，数据寄存器为32位，编址范围为00000H～3FFFFH (3FFFFH - 00000H + 1 = 40000H = 2^18)

2.
- 解：
    1. 32, 22
    2. 32
    3. 在CPU的22根地址线中(A0 ~ A21)，地址线的作用分配如下：首先，此时不需要指定A0、A1来标识每组中的4片存储器，**因为此时是按字寻址的，所以4片每次都是一起取的**，而不是按字节编址时需要取4片中的某一片。A0 ~ A18：每片都是512K，所以需要19位来表示。A19、A20、A21：因为在扩展中4片一组，一共有8组，所以需要用3位地址线来决定取哪一组（通过3/8译码器形成片选信号）

3.
- 解：
    1. 64
    2. 采用异步刷新方式，在2ms时间内分散地把芯片64行刷新一遍，因此刷新信号的时间间隔为2ms/64=31.25μs，即可取刷新信号周期为31μs。注意：刷新周期也可取30μs，只要小于31.25μs 即可，但**通常取刷新间隔的整数部分**

4.
- 解：
    1. 256K × 32容量的存储器
    2. 18
    3. 略

5.(加入改错本，无需画图，主要**练习地址范围**)
- 解：略

错题总结：
- 实际的主存容量不能代表MAR的位数，考虑到存储器扩展的需要，MAR应保证能访问到整个主存地址空间，反过来，MAR的位数决定了主存地址空间的大小

#### （3）高速缓冲存储器(Cache)

1）Cache的基本工作原理
-  主要思路
    - 💎CPU 与主存之间增加一个隐藏的小容量的快速的SRAM 存储器，将 DRAM 主存中经常访问或即将访问的数据的副本调度到 SRAM中，使得大部分数据访问都可以在快速的 SRAM 中进行，从而提升系统读性能，写性能可以通过写回策略提升。![img](https://api2.mubu.com/v3/document_image/4668a5e0-ca8e-4237-90c8-741c553ca788-329792.jpg)
- 程序局部性原理
    - 时间局部性
        - 当程序访问一个存储位置时，该位置在未来可能会被多次访
        - 常用变量、程序的循环结构和过程调用
    - 空间局部性
        - 一旦程序访问了某个存储单元，则其附近的存储单元也即将被访问。
        - 数组、结构体、顺序指令
- 常用术语
    - 数据块：主存，cache均划分位大小相同的块
        - 块具有预读的作用
        - 块过大时间局部性利用不佳
        - 块过小空间局部性利用不
    - cache行，槽：包括数据副本和描述数据副本的元数据
        - 标记、标志、置换标志
    - 命中hit、缺失miss
    - 命中率、缺失率![img](https://api2.mubu.com/v3/document_image/b00d884f-85d9-4029-9f8c-92e5a8faeddb-329792.jpg)
    - 平均访问时间![img](https://api2.mubu.com/v3/document_image/e4f3293b-4747-4512-995d-4865464a86bf-329792.jpg)
    - cache访问效率![img](https://api2.mubu.com/v3/document_image/22a9c850-bf81-4ebc-9124-45e02812439c-329792.jpg)

2）Cach和主存之间的映射方式
💎查找机制：
- 硬件查找：相联存储器
    - 不按地址进行访问，按内容进行访问
    - 所有存储单元与关键字并发比较
    - 成本高：需要多路比较器
    - 📈图解![img](https://api2.mubu.com/v3/document_image/67ac43d8-48d4-41e3-b317-a5bcb5de114d-329792.jpg)

💎映射机制：
- 全相联
    - 基本特征
      - 主存块可以映射到任何一个cache行
      - 查找时**n路并发比较，硬件成本高**
      - 命中率高，cache利用率高
      - **cache满时需要淘汰算法**
    - 全相联cache容量计算
      - cache行内容
        - valid位（区分是否有数据）
        - 主存块地址tag
        - 数据块副本
        - *脏数据位*
        - *置换标记位*
        - **cache容量 = 行数 × cache行容量**
    - 全相联图解
      - 只是成本高，其访问速度比直接相联更快
      - 📈![img](https://api2.mubu.com/v3/document_image/bdc6007c-25a3-4b4d-90b9-469641d482cf-329792.jpg)
    - 全相联工程实现
      - **CPU与cache之间交换的单位是字**
      - **cache与主存交换单位是块**
      - 📈![img](https://api2.mubu.com/v3/document_image/7dc07942-b078-4923-9e08-df77d634d3e3-329792.jpg)
- 直接相联（映射）
    - 基本特征
      - 主存块只能映射到唯一的cache行
      - 查找时只需一个比较器，**硬件成本低**
      - 命中率低，cache利用率低
      - **无淘汰算法，有冲突，直接置换**
      - 直接相联cache容量计算：
        - cache行内容
          - valid位（区分是否有数据）
          - 区地址（标记）
          - 数据块副本
          - *脏数据位*
          - *置换标记位*
        - **cache容量 = 行数 × cache行容量**
    - 直接相联图解
      - 📈![img](https://api2.mubu.com/v3/document_image/68157b76-9fbe-42cf-82d4-9ff55dceb1d2-329792.jpg)
    - 直接相联工程实现
      - 📈增加了行索引译码器，所以其访问延迟比全相联慢![img](https://api2.mubu.com/v3/document_image/24c685a3-d04b-4256-80f6-96fe810a02d8-329792.jpg)
- 组相连
    - 折中实现，是直接相联和全相联的通用模型
    - **查找成本，命中率，利用率折中**
    - 地址划分对比
      - r=0 全相联  d=r 直接相联
      - 📈搞懂组相联，其他两个都ok，注意地址划分![img](https://api2.mubu.com/v3/document_image/1f097604-0d3a-4ee1-b006-d430bcefebc3-329792.jpg)
    - 📈组相联有两种方式，考研第一次出现的时候出现歧义![img](https://api2.mubu.com/v3/document_image/31f9fbc6-bf2e-4bb0-ab99-fb788820c5a8-329792.jpg)
      - 这里只关注最容易理解的一种
    - 工程实现
      - 📈成本低，多路比较器数目变少![img](https://api2.mubu.com/v3/document_image/d5ee1d0c-d214-4fc3-a53e-6fba5778e7aa-329792.jpg)

3）Cache中主存块的替换算法与写策略
替换策略：
- FIFO  先进先出
    - 每个数据块一个计数器（硬件成本）
    - 每次访问所有计数器+1
    - 替换计数值最大的行（时间最久）
    - 容易出现**颠簸现象**
- LFU 最不经常使用
    - 每个数据块一个计数器（硬件成本）
    - 访问命中的块计数器+1
    - 替换计数值最小的行（访问次数最少）
    - 历史访问计数并不能反映当前热度
- LRU 近期最少使用
    - 每个数据块一个计数器（硬件成本）
    - **访问命中的计数器清零**
    - 替换计数值**最大**的行（近期最少使用）
    - 近期最少使用，能反映当前数据热度，命中率高
- RAND 随机替换
    - 无计数器，成本最低，命中率低
    - **随机不一定效率低**，在虚存TLB中采用

写策略：
- 写入策略：
    - 写回（write-back）
        - 产生不一致性，有脏数据，写响应快
        - 提升写速度，减少访存次数
    - 写穿（write-through）
        - 不一致性，无脏数据，写响应慢
- 写分配策略：写入缺失时是否分配cache块（write-allocate和not-write-allocate）

💎cache读写基本流程：
- cache读流程
    - 命中直接访问cache，确实访问主存，并将数据块载入cache![img](https://api2.mubu.com/v3/document_image/aec85843-7046-42ea-a1cc-4a3ad191fe1b-329792.jpg)
- cache写流程
    - 命中根据写入策略写入，不命中根据写分配策略写入![img](https://api2.mubu.com/v3/document_image/14b6d7f2-bffc-4bb3-8047-6b94d66f0408-329792.jpg)

4）多层次Cache性能计算

见大题解答

**王道习题：**

一轮标记题：1 2 5 7 8 10 11 12 13 14 15 16 20

二轮重做：5 11 12 14 15(结合14) 19 20

大题：

1.
- 解：显然，1)应该写回，2)应该写穿

2.
- 解：略

3 ~ 9.
- 不做了


错题总结：
- 什么是Cache地址？什么又是Cache的内容？实际上，**Cache地址应该是：块号 + 块内地址**。Cache行的内容是分为：标记阵列容量（替换算法控制位、脏位、标记项、有效位）+ 每行存储的数据。
- **主存容量 / Cache容量 = 标记项位数**
- 主存单元号（**字块号**） / 组相联路数 = 组号
- 采用指令Cache与数据Cache分离的主要目的是减少指令流水线资源冲突，因为把指令Cache与数据Cache分离后，取指和取数分别到不同的Cache中寻找，则**指令流水线中取指部分和取数部分就可以很好地避免冲突**，即减少了指令流水线的冲突
- 形如a[i] = a[i] + 1这种形式的时空局部性代码时，一定要注意的是，它包含了**一次读**与**一次写**

#### （4）虚拟存储器

1）虚拟存储器的基本概念
基本概念：在硬件和OS联合管理下，将磁盘空间、内存空间构成一个更大的虚拟地址空间，让更多的更大的程序在有限的内存空间运行，主要作用是扩大主存地址空间，进行存储保护
- 采用了类似cache的技术
    - 相同之处
        - 将经常访问的数据放到快速存储器中
        - 提升性能
        - 数据分块或分页
    - 不同之处
        - **cache解决性能问题，VM解决容量问题**
        - cache硬件实现，VM软硬协同
        - cache透明，**VM对应用程序员透明，对系统程序员不透明**
        - VM确实性能损失过大
- 实例
    - Windows页面文件，交换分区
    - 实模式：物理地址模式，嵌入式系统，OS引导之前
    - 保护模式：虚拟地址模式，OS引导之后
- 分类
    - 页式虚拟存储器（**考研重点，多次和cache一起考，结合OS一起复习**）
        - 以固定大小页为单位，常见4KB，也有更大的页
        - 无碎片，存储共享保护不方便
    - 段式虚拟存储器（OS课程复习，组成未考过）
        - 以段为单位，存储共享保护容易、易产生碎片
    - 段页式（OS课程复习，组成未考过）
- 具体见OS

2）页式虚拟存储器

- 见OS

3）TLB(快表)

- 💎CPU访存过程：可以无视右上角的“页表块cache命中”部分，我们默认直接访问主存页表
    - 📈流程图![img](https://api2.mubu.com/v3/document_image/7fda6601-0fb7-40c8-b34b-8c738fe710e5-329792.jpg)
    - 命中组合：
        - 访存零次（1）、访存一次（2、3）、访存两次（4）、访存两次 + 外存（5）
        - **注意三种不可能的情况**，为什么它们不可能？→ 关键看**页有没有缺失**
        - 📈![img](https://api2.mubu.com/v3/document_image/4ddfab15-9f4a-44fd-b0e4-3aae26d3f6a9-329792.jpg)
- 具体的地址翻译计算见本文OS部分，以及王道OS的p221（加入改错本√）

**王道习题：**

一轮标记题：2 3 5 11 12

二轮重做：11

大题：只做真题即可，其中第5题与OS重复

1.
- 解：读一遍题目：虚拟地址24位，物理地址20位，页内偏移12位，Cache直接映射（行索引3位），块内偏移5位
    1. 24；12；20；8
    2. 12 + 3 + 5
    3. 在主存中；对应物理地址04C60H, 对应标记为04C, 不命中
    4. TLB组索引为1位，标记为11位，则024BACH的标记为012H，在主存中


6.
- 解：读题：物理地址24位，虚拟地址30位，页偏移12位，TLB组索引3位
    1. 前18位，后12位
    2. 前15位，中3位
    3. 4号
    4. 页号增加2位，页框号不变，因此TLB表项增加2位

错题总结：
- 见OS

####  （5）其他

半导体存储器：CPU - SRAM - DRAM - ROM
- SRAM存储器
  - SRAM读写原理
    - 读出：行列同时选通，位线数据差分放大检出
    - 写入：行列同时选通，数据从位线写入
    - SRAM读写原理详解
      - 📈SRAM读原理![img](https://api2.mubu.com/v3/document_image/2e4c5365-ac5c-4b36-a4dc-232c76464eb6-329792.jpg)
        - 同时给出行选和列选信号，打开T5，T6，T7，T8门控管
        - 将I/O以及~I/O信号经I/O电路放大得到数据
      - 📈SRAM写原理![img](https://api2.mubu.com/v3/document_image/e2b09ac8-d011-47e7-8364-a1cee43a7302-329792.jpg)
        - 同时给出行选和列选信号，打开T5，T6，T7，T8门控管
        - 将写入数据加载在I/O以及~I/O端
  - SRAM特征
    - 性能好，读写对称，性能一样
    - **功耗大，存储密度低，单位容量成本高**
  - SRAM芯片
    - 数据总线双向
- DRAM存储器
  - 访问过程
    - 预充、访问、信号检测、数据恢复、数据读/写
  - DRAM特性
    - **行列分时选通，相比SRAM速度慢，电容会泄露丢失数据，需要定时刷新**
    - **功耗低，存储密度高，价格便宜，速度慢**
  - **DRAM刷新**
    - **按行刷新**：刷新行地址由刷新控制器提供
    - *最大刷新周期：信息存储到数据丢失之前的这段时间*
    - 集中刷新：集中安排时间刷新，**存在死区**，CPU长时间得不到响应
    - 分散刷新：**一个存储周期细分为CPU访内和刷新两部分，存储周期变慢（缺点极大）**
    - 异步刷新
      - 在最大刷新周期内每隔一段时间t（**将刷新周期除以行数**）刷新一行
      - 效率最高
    - 刷新时不需要选片，即整个存储器中的所有芯片同时被刷新
  - DRAM芯片
    - **行列地址复用，地址线减半，数据输入，输出分开，数据线倍增**
  - DDR存储带宽(了解)
    - 以 DDR4-3200 为例
      - 3200 为等效传输频率 f，单位为 MHz
      - 数据位宽 w = 8 字节
    - 则内存带宽 B = f × w = 3200 × 8 = 25.6GB/s
    - 由于时钟上跳沿和下跳沿各完成一次数据传输，因此数据总线频率为 3200/2 = 1600MHz，
    - DRAM 的工作频率为 1600MHz/8 = 200MHz （DDR2/3/4  频率倍数分别是2,4,8）
    - 有兴趣可以了解下DRAM存储带宽计算![img](https://api2.mubu.com/v3/document_image/755032f5-1628-422f-816a-36087261caa9-329792.jpg)
- 只读存储器
  - ROM  
    - 只读存储器
    - 利用开关电路存储数据
  - PROM  
    - 可编程一次
    - 利用熔丝或反向二极管存储数据
  - EPROM  
    - 可擦除可编程
    - 利用浮置栅存储数据
    - 紫外线擦除，高压写入
  - EEPROM  
    - 电可擦除
    - 在EPROM基础上增加控制栅极
- Flash存储器
  - 闪存，和EEPROM类似
  - U盘，SSD固态盘使用该技术
  - 固态硬盘由控制单元和存储单元（Flash芯片）组成。**保留了Flash存储器长期保存信息、快速擦除与重写的特性。对比传统硬盘也具有读写速度快、低功耗的特性**，缺点是价格较高

**王道习题：（961不知道考不考，大题先不做）**

一轮标记题：1 6 7 9 12 14 15 16 17 18 19 22 25

二轮重做：7 9 14 17 18(题出得不是很好) 19 25

错题总结：
- RAM属于易失性半导体，SRAM和DRAM的区别在于是否需要动态刷新
- 地址复用的DRAM需要**行选通和列选通**的引脚，而片选线可由行选线替代
- DRAM的读并不是把信息读入CPU，也不是从CPU向主存存入信息，它只是把信息读出，通过一个刷新放大器后又重新存回存储单元，而刷新放大器是集成在DRAM上的。因此，这里只进行了一次访存，也就是**占用一个存取周期**
- 闪存的存储元由MOS管组成，是一种半导体存储器
- 25题：这题也很有迷惑性，我们探讨交叉编址的前提一般是：**模块字长等于数据总线宽度**，而这里是32位的总线可以同时读4个模块。但读取x依旧需要三个周期，因为double型变量应该按字对齐，也就是最后两位应该为00，但这里的804 001AH，最后两位为10，没有按字对齐的后果就是要多读一个周期

#### 本章小结

- 计算机如何管理存储器的层次？
    - **主存与Cache之间的信息调度功能全部由硬件自动完成**。**而主存与辅存层次的调度**目前广泛采用虚拟存储技术实现，即将主存与辅存的一部分**通过软/硬结合**的技术组成虚拟存储器，程序员可用这个比主存实际空间（物理地址空间）大得多的虚拟地址空间（逻辑地址空间）编程，当程序运行时，再由软/硬件自动配合完成虚拟地址空间与主存实际物理空间的转换。因此，**这两个层次上的调度或转换操作对于程序员来说都是透明的**
- Cache行的大小和命中率之间有什么关系？
    - 行的长度较大，可以充分利用程序访问的空间局部性，使一个较大的局部空间被一起调到Cache中，因而可以增加命中机会
    - 但是，行长也不能太大，主要原因有两个，一是会使失效损失变大。也就是说，若未命中，则需花更多时间从主存读块。二是行长太大，Cache项数变少，因而命中的可能性变小

### <a name="7">（四）MIPS指令系统及汇编语言</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）指令系统的基本知识（指令格式、寻址方式）

指令系统基本概念：
  - 指令是计算机执行某种操作的命令，一台计算机中所有机器指令的集合称为指令系统。
  - 机器语言指令是计算机硬件与软件的界面，也是用户操作和使用计算机硬件的接口。软件层次的指令需要经过“翻译”成机器语言指令后才能被计算机硬件识别并执行。
    - 一条高级语言指令被“翻译”(编译或解释)成多条机器语言指令
    - 一条汇编语言指令（不包含伪指令）对应一条机器指令
    - 一条机器指令功能的实现依赖于多条微指令的执行
  - 完善的指令系统特征
    - 完备性、规整性、有效性、和兼容性

**指令格式：**
  - 指令基本格式
    - 指令格式![img](https://api2.mubu.com/v3/document_image/3157ba53-e8d5-46e8-8f13-cafed2f32aaa-329792.jpg)
    - 指令长度
      - 一条指令所包含的二进位数
      - 按与机器字长的关系分
        - 半字长指令
        - 单字长指令
        - 多字长指令：多字长影响取指令速度，需要多个主存周期
      - 按指令长度是否统一
        - 定长指令：便于处理(包括计算地址、取指令、指令译码)
        - 变长指令：指令结构紧凑，程序占用空间少，但不便于处理
    - 操作码：指明指令的具体操作性质
      - 定长操作码
        - 操作码长度n与指令规模m的关系
        - n ≥ log2m
        - 有利于指令译码，简化控制器设计
      - 变长操作码
        - 💎扩展操作码: 将指令的操作码字段向不用的地址码字段扩展
        - 充分利用字长，增加指令数，指令译码麻烦，控制器设计复杂
        - 图解![img](https://api2.mubu.com/v3/document_image/dbaa037d-4dec-4667-86a6-061a7d4e79ea-329792.jpg)
        - 3种指令操作码部分不得重叠，否则无法区分，译码
          - 短码不能是长码的前缀
        - 设双操作数指令数为k, 显然k < 2^8
        - 2^8 - k为多余状态，可用于表示其他类型指令
        - 2^8 - k可用于单操作数指令的条数 = (2^8 - k) * 2^12，2^12是多余12位组合
    - 地址码：地址码用于描述操作数
      - 三地址、二地址、单地址、零地址
        - 零地址的运算类指令仅用在堆栈计算机中。通常参与运算的两个操作数隐含地从栈顶和次栈顶弹出，送到运算器进行运算，运算结果再隐含地压入堆栈
        - 隐含约定目的地址的双操作数指令，按指令地址A可读取源操作数，指令可隐含约定另一个操作数由ACC（累加器）提供，运算结果也将存放在ACC中
      - 地址码可能分为寻址特征位和形式地址两部分

**指令的寻址方式：**
  - 指令寻址
    - 顺序寻址方式：
      - 💎PC =PC+ ”1” ,这里的“1”表示一条指令所占用的主存单元数(按字节编址)
      - MIPS32中 PC=PC+4  
    - 跳跃方式寻址
      - PC = 转移地址值
      - 转移地址值可能直接来自指令中的形式地址字段,也可能通过计算后得到
  - 💎操作数寻址
    - 概念：指明操作数的有效物理地址
    - 构成：把操作数部分分为【寻址特征I】+【形式地址D】![img](https://api2.mubu.com/v3/document_image/7ad7ae93-7db1-4669-a008-7960c615be7e-329792.jpg)
    - 立即数寻址
      - 指令的形式地址字段给出的就是操作数,不需要计算有效地址
      - 无需访存，指令执行速度快，但立即数大小受字段长度限制
    - 直接寻址：E = D
      - 指令的形式地址字段给出的就是操作数的地址；
      - 寻址范围受字段长度限制
    - 寄存器寻址：S = R[D]
      - 操作数在寄存器中，D为寄存器编号![img](https://api2.mubu.com/v3/document_image/7db6ed11-3d14-4b82-bba7-d0e852608877-329792.jpg)
      - 无需访存，执行速度快
    - 间接寻址：E = (D)
      - 形式地址字段给出的是操作数存储单元的地址
      - 需要访问两次主存才能取出操作数，慢，已淘汰
      - 可有效扩大寻址空间至整个主存范围![img](https://api2.mubu.com/v3/document_image/896b3943-ab51-4b67-9c6f-5d66057d331f-329792.jpg)
    - 寄存器间接寻址：E = R[D]
      - 指令的形式地址字段所指寄存器的值是操作数的地址；
      - 相对间接寻址速度更快，也可扩大寻址范围![img](https://api2.mubu.com/v3/document_image/dfd882a5-a8a5-4556-ad70-1c3d9aa4b7e4-329792.jpg)
    - 相对寻址：E = (PC) + D 
      - 由指令的形式地址字段给出的偏移量与PC的值相加得到数据的有效地址。
      - 形式地址决定了指令前后跳转的范围![img](https://api2.mubu.com/v3/document_image/299cff96-da66-42a1-8755-31805681d096-329792.jpg)
      - 注意很多指令系统相对寻址都是相对下一条指令的PC值
    - 基址寻址：E = (BX) + D
      - 基址寄存器(设为BX)的值与指令的形式地址字段给出的偏移量相加得到操作数的有效地址
    - 变址寻址：E = R[X] + D
      - 变址寄存器(设为X)的值与指令的形式地址字段给出的偏移量相加得到操作数的有效地址
      - 变址寄存器为通用寄存器![img](https://api2.mubu.com/v3/document_image/e79ed8ab-7e5d-4ed4-bee8-0ff31ede55fa-329792.jpg)
    - 堆栈寻址
      - 硬件堆栈，成本高，容量小
        - 栈顶不动，数据移动
      - 内存堆栈，成本低，容量大
        - 数据不动，栈顶移动
        - 📈图示![img](https://api2.mubu.com/v3/document_image/2565fece-dac5-44e3-8db3-d0052f41e3cc-329792.jpg)

指令格式设计：
  - 定长/变长/混合编码指令格式?
  - 操作码的设计
    - 根据指令完备性要求选择操作码字段位数
    - 是否采用扩展操作码
  - 地址码的设计
    - 既要为指令提供操作数，又要满足指令系统的有效性和规整性要求
    - 地址码的设计往往还与寻址方式有关
      - 用间接寻址方式缩短地址码长度
      - 用变址寻址方式缩短地址码长度
  - 寻址方式字段的设计
    - 把寻址方式与操作码一起编码
    - 设置专门的寻址方式字段

**王道习题：**

一轮标记题：5 10 12 13 

二轮重做：4

错题总结：
- 堆栈指令的访存次数，取决于采用的是软堆栈还是硬堆栈。若是软堆栈（堆栈区由内存实现），则对于双目运算需要访问4次内存：取指、取源数1、取源数2、存结果。若是硬堆栈〔堆栈区由寄存器实现），则只需在取指令时访问一次内存


#### （2）MIPS汇编语言

💎MIPS指令特点(32位MIPS为例)：
- Load/Store架构
- 指令格式规整，寻址方式简单，指令功能简单
- 只有R型、I型和J型三类指令
  - 指令格式图解
    - ![img](https://api2.mubu.com/v3/document_image/c26efe46-535d-4a74-be3c-f1f0470429d0-329792.jpg)
  - op：操作码，所有R型指令中都全为0
  - rs/rt/rd：寄存器编号
  - shamt：常数，在移位指令中使用
  - funct：功能码，指定指令的具体功能
- 32个32位的通用寄存器
- **32位定长指令结构**
- **操作码字段长度固定为6位**
- 没有寻址方式字段，5种寻址方式
  - 寄存器寻址、立即数寻址、基址寻址、相对寻址、伪直接寻址

CISC和RISC的基本概念（拓展）：
  - 复杂指令系统计算机CISC（Intel、AMD、IBM）
    - 变长指令字结构
    - 指令系统复杂庞大且指令数目多
    - 指令格式种类多
    - 指令寻址方式种类多
    - 指令译码复杂
    - 大多数采用微程序设计
    - 指令执行速度慢
  - 精简指令系统计算机RISC（MIPS、ARM）
    - 等长指令
    - 寻址方式少且简单
    - Load/Store架构: **只有取数和存数指令访问存储器**
    - 指令数量和指令格式少、指令功能简单
    - CPU内部设置了大量的寄存器
    - 控制器多采用硬布线方式
    - 大多数指令可在一个时钟周期内完成、支持指令流水并强调指令流水的优化使用
    - 设计方便，可靠性高，设计周期短
  - CISC和RISC近年来在技术上互相融合

汇编语言：
- 相关寄存器：

十六bit|三十二bit|说明
:-:|:-:|-
AX|EAX|累加器(Accumulator)
BX|EBX|基地址寄存器(Base Register)
CX|ECX|计数寄存器(Count Register)
DX|EDX|数据寄存器(Data Register)
~|ESI / EDI|变址寄存器(lndex Register)
~|EBP|堆栈基指针(Base Pointer)
~|ESP|堆栈顶指针(Stack Pointer)

- 汇编指令格式：一般有两种不同的汇编格式：AT&T格式和Intel格式。它们的区别主要体现如下：
    - AT&T格式的指令**只能用小写字母**，而Intel格式的指令对大小写不敏感
    - 在AT&T格式中，**第一个为源操作数，第二个为目的操作数**，方向从左到右，合乎自然；而在Intel格式中，第一个为目的操作数，第二个为源操作数，方向从右向左
    - 在AT&T格式中，**寄存器需要加前缀“ % ”，立即数需要加前缀“ $ ”**；在Intel格式中，寄存器和立即数都不需要加前缀
    - 在内存寻址方面，**AT&T格式使用“ ( ”和“ ) ”，而Intel格式使用“ [ ”和“ ] ”**
    - 在处理复杂寻址方式时，例如 AT&T格式的内存操作数“disp(base, index, scale)”分别表示偏移量、基址寄存器、变址寄存器和比例因子
    - 在指定数据长度方面，AT&T格式指令操作码的后面紧跟一个字符，表明操作数大小，**“b”表示byte(字节)、“w”表示word(字）或“l”表示long(双字)**。Intel格式也有类似的语法，它在操作码后面显式地注明byte ptr、word ptr 或 dword ptr（注意：由于32或64位体系结构都是由16位扩展而来的，因此用word(字)表示16位）
    - 一组实例：

AT&T格式|Intel格式|含义
-|-|-
mov $100, %eax|mov eax, 100|100 -> R[ eax ]
mov %eax, %ebx|mov ebx, eax|R[ eax ] -> R[ ebx ]
mov %eax, ( %ebx )|mov [ ebx ], eax|R[ eax] -> M[ R[ ebx ] ]
lea 8( %edx, %eax, 2), %eax|lea eax, [ edx + eax * 2 + 8]|R[ edx ] + R[ eax ] * 2 + 8 -> R[ eax ]
movl %eax, %ebx|mov dword ptr ebx, eax|长度为4字节的R[ eax ] -> R[ ebx ]

- 常见指令
    - 数据传送指令：mov；push；pop
    - 算术和逻辑运算指令：add；sub；inc；dec；imul；idiv（被除数为edx:eax，商送eax，余数送edx）；and；or；xor；not；neg；shl；shr；sal；sar
    - 控制流指令：jmp；je / jne / jz / jg / jge / jl / jle；cmp；test；call；ret；

- 💎MIPS32汇编语言（写法和上面提到的两种都不太一样，方向不自然，寄存器用$，立即数无需前缀）
    - r型指令
        - 3寄存器r型指令：add；sub；and；or；xor
        - 2寄存器r型指令：sll（shift left logical）；srl；sra（没有rs）
        - 1寄存器r型指令：jr（跳转寄存器）（只有rs）
    - i型指令
        - 面向运算的i型指令：addi；andi；ori；xori
            - **第一条指令是进行符号扩展，其余是0扩展**
        - 面向访存的i型指令：lw（load word）；sw（save word）
        - 面向数位设置的i型指令：lui（设置寄存器的高16位）
            - **汇编语言**：lui rt, imm # $rt ← imm << 16 (空位补0)
        - 面向分支的i型指令：beq（相等则跳）；bne（不等则跳）
            - **汇编语言**(beq)：beq rs, rt, imm # if($rs == $rt) $PC ← $PC + E(imm) << 2
            - 因为mips的指令长度为4个字节，所以指令地址一定为4的倍数，因而地址后两位一定为0，**因此offset左移两位使偏移量变为4的倍数**，保持地址最后两位为0
    - j型指令
        - j：无条件跳转
            - **汇编语言**：j address # PC ← ($PC + 4)取高4位 ∪ (address << 2)
        - jal：调用与联结（jump and link？）

#### 本章小结

- 对于一个指令系统来说，寻址方式多和少有什么影响?
    - 寻址方式的多样化能让用户编程更为方便，但多重寻址方式会造成CPU结构的复杂化，也不利于指令流水线的运行。而寻址方式太少虽然能够提高CPU的效率，但对于用户而言，少数几种寻址方式会使编程变得复杂，很难满足用户的需求
- 简述各常见指令寻址方式的特点和适用情况。
    - 立即寻址操作数获取便捷，通常用于给寄存器赋初值
    - 直接寻址相对于立即寻址，缩短了指令长度
    - 间接寻址扩大了寻址范围，便于编制程序，易于完成子程序返回。寄存器寻址的指令字较短，指令执行速度较快
    - 寄存器间接寻址扩大了寻址范围
    - 基址寻址扩大了操作数寻址范围，适用于多道程序设计，常用于为程序或数据分配存储空间
    - 变址寻址主要用于处理数组问题，适合编制循环程序。相对寻址用于控制程序的执行顺序、转移等
    - 基址寻址和变址寻址的区别：两种方式有效地址的形成都是寄存器内容＋偏移地址，但是**在基址寻址中**，程序员操作的是偏移地址，**基址寄存器的内容由操作系统控制**，在执行过程中是动态调整的；而在**变址寻址中，程序员操作的是变址寄存器**，偏移地址是固定不变的
- 装入/存储（Load/Store）型指令有什么特点?
    - 装入/存储型指令在RISC中较为常见。为了规整指令格式，使指令具有相同的长度，**规定只有Load/Store指令才能访问内存**。而运算指令不能直接访问内存，只能从寄存器取数进行运算，运算的结果也只能送到寄存器
    - 因为寄存器编号较短，而主存地址位数较长，通过某种方式可使**运算指令和访存指令的长度一致**
    - 这种装入/存储型风格的指令系统的最大特点是，指令格式规整，指令长度一致，一般为32位。由于只有Load/Store指令才能访问内存，程序中可能会包含许多装入指令和存储指令，与一般通用寄存器型指令风格相比，其程序长度会更长

### <a name="8">（五）MIPS处理器</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）CPU的功能和基本结构

CPU的功能和组成：
  - CPU功能
    - 程序控制
      - 控制程序中的指令按事先规定的顺序自动地执行
    - 操作控制
      - 产生指令执行过程中所需要的操作控制信号
    - 时间控制
      - 对每个操作控制信号进行定时
    - 数据加工
      - 对数据进行算术或逻辑运算
    - 中断处理
      - 处理随机产生的内部异常和外部中断请求
  - 💎CPU中的主要寄存器
    -  程序计数器(PC)
      - PC保存将要执行的指令地址
    -  存储器地址寄存器(AR)【可选】
      - AR通常用来保存访存地址，无论CPU取指令还是存储数据，都必须先将要访问的主存单元地址送AR。
    -  存储器数据寄存器(DR)【可选】
      - DR作为CPU和主存之间的数据缓冲寄存器用于存放操作数、运算结果或中间结果，以减少访问主存的次数；
      - 也可存放从主存中读出的数据，或准备写入主存的数据。
    -  指令寄存器(IR)【可选】
      - IR用于保存指令字，从主存取出的指令存放在IR中
    -  通用寄存器组(GR)【程序员可见】
      - 可作为ALU的累加器、变址寄存器、地址指针、指令计数器、数据缓冲器，用于存放操作数（包括源操作数、目的操作数及中间结果)和各种地址信息等。
    -  程序状态字寄存器(PSW)【可选】【程序员可见】
      - PSW用于保存由算术运算指令、逻辑运算指令、测试指令等建立的各种条件标志。
      - 常见的状态信息包括进位标志(C)、溢出标志(V)、结果为负数标志(S)及结果为零标志(Z)等
    - 程序员不可见的寄存器包括PC、AR、DR、IR等，称为透明寄存器
  - CPU的组成
    - 运算器
      - 运算器是执行部件，由算术逻辑单元和各种寄存器组成。运算器接受控制器的命令执行算术运算、逻辑运算及逻辑测试等功能
      - 通用寄存器GR，程序状态寄存器PSW
    - 控制器
      - 取指令、计算下一条指令的地址、对指令译码、产生相应的操作控制信号序列，形成完成指令所需要的数据通路，控制指令执行的步骤和数据流动的方向
      - AR、DR、PC、IR

**王道习题：**

二轮重做：8 11 12 18 21 23；2 11 16

大题：

1.
- 答：通常完成一条指令可分为取指阶段和执行阶段。在取指阶段通过访问存储器可将指令取出；在执行阶段通过访问存储器可以将操作数取出。因此，虽然指令和数据都以二进制代码形式存放在存储器中，但 CPU 可根据**指令周期的不同阶段**判断从存储器取出的二进制代码是指令还是数据

2.
- 答：中断周期之前是执行周期，之后是下一条指令的取指周期

错题总结：
- 程序计数器PC属于控制器，控制器还有IR、CU
- 指令译码是指对指令的操作码字段进行译码
- 间址周期的任务是取操作数有效地址（我们往往忽略这个周期）

#### （2）单周期、多周期MIPS处理器数据通路的功能和基本结构

**指令执行过程：**
  - 指令执行的一般流程
    - 📈图解![img](https://api2.mubu.com/v3/document_image/50029e8b-b45f-4abd-8a5f-83a16b879dde-329792.jpg)
  -  💎指令周期
    - 定义：将一条指令从取出到执行完成所需要的时间称为指令周期
        - 简单划分
          - 取指周期
            - 负责取指令
          - 执行周期
            - 负责指令执行
            - 还可以进一步细分，如间址周期
          - 中断周期
            - 指令执行完毕后处理中断
        - 指令周期的划分不尽相同
    - 💎传统三级时序
      - **指令周期可划分成若干个机器周期**(也称为CPU周期)
        - 机器周期：取指令所需要的**最短时间**，指令cache命中时最短
          - **一个机器周期又包括若干时钟周期**，可以进行一系列复杂的操作
          - **一个时钟周期只能进行简单的微操作**，如寄存器写入
        - *一个机器周期*又分成*若干个节拍电位时间段*
          - 通常以CPU完成一次微操作所需要的时间为基础来定义节拍电位的时间
          - *一个节拍电位中又包含1个*或多个*节拍脉冲*
    - 现代时序系统
      - 已经不再使用*机器周期、节拍电位和节拍脉冲三级时序*体制，**指令执行过程中的定时信号就是时钟信号，一个时钟周期就是一个节拍，不再设置节拍脉冲**
    - 一言以蔽之
      - 单周期 = 定长指令周期 + 单时钟周期
        - 所有指令均在一个时钟周期内完成，CPI=1
        - 性能取决于最慢的指令，时钟周期过长
      - 三级时序 = 定长指令周期 + 多时钟周期
        - 缩短时钟周期，复用器件或数据通路
        - 可支持流水操作，提升性能
      - 现代时序 = 变长指令周期 + 多时钟周期

数据通路：
- 数据通路的基本概念：
  - 数据在功能部件之间传送的路径称为数据通路
  - 运算器与各寄存器之间的传送路径就是中央处理器内部的数据通路
  - 指令功能不同，指令执行过程中所用到的功能部件不同，其数据通路也不同
- 2种数据通路结构
  - 数据通路构成
    - 数据处理单元（组合逻辑）（组合逻辑元件）
    - 状态存储单元（时序逻辑）（**状态**元件）
    - 📈图解![img](https://api2.mubu.com/v3/document_image/1a4635b4-ff95-4071-a099-6fa8ca5be453-329792.jpg)
    - **数据通路的时钟频率取决于数据处理单元的关键延迟**
  - 数据通路分类
    - 总线结构：实现简单，总线复用，效率低下
    - 专用通路：硬件复杂，指令执行效率高

**MIPS数据通路：**
  - 基本特征
    - 各功能部件之间均基于**专用的数据传输通路**连接
    - 各通路中的数据可**并行传输**，控制较总线结构要简单
  - 💎单周期MIPS
    - 单周期不能设置AR，DR，IR寄存器
    - **所有指令一个时钟周期完成**，CPI = 1，但时钟频率取决于最慢的LW指令
    - **数据、指令分开存放**，保证取指令和取操作数并行——哈佛结构
        - 指令存储器 → 指令cache（现代）
        - 数据存储器 → 数据cache（现代）
    - **运算PC、运算分支地址、运算数据所需的ALU分别设置**，成本较高
    - 控制器为**组合逻辑**（只有一个周期，所以无需时序），不同指令产生不同的控制信号组合，形成对应的数据通路
    - 凡是有多个输入来源的，增加MUX，引入控点
  - 多周期MIPS
    - **不再区分指令存储器和数据存储器**，指令和数据保存在同一存储器中
    - 部分功能单元，如ALU可在一条指令执行过程的不同时钟周期中多次使用，**不需要额外设置ALU或加法器**
    - 时钟周期变小，传输通路变短
    - 主要功能单元输出端都增加了一些**附加寄存器**，暂存（**锁存**）当前时钟周期加工处理的数据，给后续时钟周期使用
      - DR、IR
      - A、B：缓存寄存器操作数
      - C：缓存分支地址或ALU运算结果
    - 增加和扩展了部分多路选择器
    - 增加了ALU控制器
      - 专门负责产生 ALU 的运算选择控制信号 AluOP
    - 方便合并R型运算指令以及I型指令的状态机
    - 📈指令周期图解![img](https://api2.mubu.com/v3/document_image/b5c00733-af77-4711-9c26-dc5f7f220ed0-329792.jpg)
      - 注意S2，S5状态可以合并，R型运算指令共享S8 ~ S9路径，I型运算共享S10 ~ S11路径
      - 控制器是时序逻辑，需要实现上述状态机，每一个圆圈一个时钟周期
      - 不同指令时钟周期数不一样

**王道习题：**

错题总结：
- 脑筋急转弯：指令为一个时钟周期时，指令执行过程中控制信号并不会变化（因为一个时钟周期的控制信号无法变化）
- 指令执行过程中数据所经过的路径，包括路径上的部件，称为数据通路。ALU、通用寄存器、状态寄存器、Cache、MMU、浮点运算逻辑、异常和中断处理逻辑等，都是指令执行过程中数据流经的部件，**都属于数据通路的一部分**

#### （3）硬布线控制器的功能和工作原理

控制器的设计方法：
  - 硬布线：硬布线控制器采用数字逻辑电路的方法设计
  - 微程序：而微程序控制器是利用软件方法设计，存储逻辑，软时序
  - 微程序控制器具有规整性、灵活性、可维护性等一系列优点，在计算机设计中得到了广泛应用，并取代了早期的硬布线控制器设计技术，但随着VLSI技术的发展和对机器速度不断提高的要求，硬布线设计思想又重新得到了重视。

1）单周期处理器控制器 / 传统三级时序硬布线控制器：
  - 设计原理
    - 硬布线控制器是组合逻辑
      - 输入：指令译码（Opcode，Func）、状态周期电位、节拍电位、反馈信号
      - 输出Cn：微操作控制器信号序列（多路选择器选择信号、寄存器写使能信号、内存访问控制信号、运算器控制信号、指令译码信号）
      - 逻辑函数![img](https://api2.mubu.com/v3/document_image/ebded0fa-35ac-4d6c-a252-ae2c43a47c31-329792.jpg)
      - 例子![img](https://api2.mubu.com/v3/document_image/dd7dd982-93ff-4bf9-9e4b-cdb4c451e462-329792.jpg)
    - 📈图解：![img](https://api2.mubu.com/v3/document_image/7f324698-97c6-4832-8ad7-4c929cbd40f2-329792.jpg)
  - 设计流程
    1. **分析指令执行的数据通路**，列出每条指令在所有寻址方式下的执行操作流程和每一步所需要的控制信号
    2. 对指令的操作流程进行细化，将每条指令的每个微操作**分配到具体的机器周期的各个时间节拍信号上**，即对操作控制信号进行同步控制
    3. 根据控制信号同步控制方式构造合适的时序发生器
    4. 对每一个控制信号进行逻辑综合，得到每个控制信号的逻辑表达式
    5. 最后采用逻辑门或 PLA 或 ROM 实现逻辑表达式的功能

2）多周期处理器控制器 / 现代时序硬布线控制器:
  - 设计原理
    - 功能：输入*时钟脉冲信号（clk），指令译码信号、反馈信号*，持续不断地产生*状态周期电位和节拍电位*，操作控制器利用这些周期、节拍电位信号对操作控制信号进行时序的调制，生成控制信号序列
    - 核心是有限状态机
    - 控制信号是现态的函数
    - 📈图解：![img](https://api2.mubu.com/v3/document_image/0daf4262-d213-490b-b1b0-231b30a6dcab-329792.jpg)
  - 设计流程
    1. 分析指令执行的数据通路，列出每条指令在所有寻址方式下的执行操作流程和每一步所需要的控制信号
    2. 对指令的操作流程进行细化，将每条指令的每个微操作分配到具体时钟节拍上
    3. **以时钟周期为单位构建指令执行状态图**，生成状态转换表，实现有限状态机电路
    4. 收集每一个控制信号产生的所有状态条件，得到每个控制信号的逻辑表达式
    5. 最后采用逻辑门或 PLA 或 ROM 实现硬布线控制器逻辑

**王道习题：**

二轮重做：2 8 11 12 13

- 控制存储器用ROM
- 硬布线控制器需要结合各微操作的节拍安排，综合分析，写出逻辑表达式，再设计成逻辑电路图，因此时序系统比较复杂；而微程序只需按照节拍的安排，顺序执行微指令，因此比较简单
- **汇编程序员可见的寄存器有基址寄存器（用于实现多道程序设计或者编制浮动程序）和状态/标志寄存器、程序计数器PC及通用寄存器组**

#### （4）指令流水线

1）指令流水线的基本概念
  - 将一条指令的执行阶段划分成几个阶段，各阶段在不同的功能部件上并行执行，使得在同一个时钟周期内能同时解释多条机器指令，提高程序的执行速度，这就指令流水线。
  - 分类
    - 按流水级别
      - 部件功能级流水线：运算流水线
      - 处理机级流水线：指令流水线
      - 处理机间流水线
    - 按功能分
      - 单功能：单一功能
      - 多功能：各流水段之间可以通过组合实现多种功能
    - 按连接方式分
      - 静态流水线
      - 动态流水线
    - 按是否存在反馈分
      - 线性流水线：不存在反馈
      - 非线性流水线：存在反馈
  - 性能指标
    - 吞吐率：*单位时间内流水线完成的任务数量*（单位：指令/秒）
    - 加速比：*不使用流水线的耗时 / 使用流水线的耗时*

2）指令流水线的基本实现 / 流水线冲突 / 相关 / 冒险（hazard）及处理策略

💎💎流水线的控制信号：
控制信号|位置|来源|功能说明
-|-|-|-
**BranchTaken**|**IF**|**EX**|分支跳转信号
RegDst|ID|ID|1为rd，0为rt
**RegWrite**|**ID**|**WB**|控制寄存器堆写
AluCtrl|EX|EX|控制ALU进行不同运算
MemWrite|MEM|MEM|控制数据存储器写
MemToReg|WB|WB|为1时**从数据存储器读出**数据写回寄存器，否则将ALU结果写回

💎结构冲突 / 资源冲突：
  - 定义：是由于**多条指令在同一时钟周期使用同一操作部件**而引起的冲突
  - 解决方案
    - 增加资源
      - 可以通过**增加加法器**解决运算资源冲突
      - 使用**分离的指令存储器和数据存储器**（哈佛结构）
    - 延迟运行
      - **插入气泡**延迟访存的方式解决访存引起存储器资源冲突

💎控制冲突 / 分支冲突：
  - 定义：当流水线遇到分支指令或其他会改变PC值的指令时，**在分支指令之后载入流水线的相邻指令可能因为分支跳转不能进入执行阶段**，这种冲突称为控制冲突，也称为分支冲突。
  - 解决方案：
    - **清空误取指令**。在实际分支跳转时，将分支指令后续所有已经进入流水线的误取指令清空，但这种方法会带来流水线性能损失
    - **分支延迟槽**，MIPS处理器
    - 动态分支预测技术使用，RISC-V处理器

💎数据冲突 / 段间互锁：
  - 定义：**后续指令要用到前面指令的操作结果**，而这个结果尚未产生或尚未送到指定的位置，从而造成后续指令无法继续执行的状况
  - 解决方案
    - 插入气泡：硬件阻塞，或软件插入nop指令，带来性能损失
    - 重定向 / 数据旁路：将产生后续指令需要的操作数的部件直接和后续指令的输入端连接，无性能损失，但Load-Use相关不能重定向，还是需要插入气泡
    - 编译优化：改变指令执行顺序

超标量和动态流水线的基本概念：
  - 超流水技术
    - 增加流水线功能段数目，尽可能减少各段关键延迟时间，从而提高流水线主频的方式来提升流水线性能，如 Pentium pro 的流水线就多达 14 段。
  - 多发射
    - 静态多发射
      - 超长指令字：编译程序挖掘出指令潜在的并行性
    - 动态多发射
      - 超标量技术：每个时钟周期内可以并发运行多条指令

**王道习题：**

二轮重做：6 8 14

大题：

1.
- 解：
  1. 100ns
  2. 推迟200ns
  3. 若在硬件上加以改进，可以只延迟一个时钟周期(100ns)。因为在ADD指令中，运算周期已得到结果。可以通过数据旁路技术在运算结果一得到时，就将结果快速地送入寄存器Rl，而不需要等到写回周期完成

2.
- 解：
  4. 7700000条/s

3.
- 解：
  1. 第一组指令中，I1指令运算结果应先写入R1，然后在I2指令中读出R1的内容。由于2指令进入流水线，变成I2指令在I1指令写入R1前就读出R1的内容，发生RAW相关
  2. 第二组指令中，I3指令应先读出R3的内容并存入存储单元M(x)，然后在I4指令中将运算结果写入R3。但由于I4指令进入流水线，变成I4指令在I3指令读出R3的内容前就写入R3，发生WAR相关
  3. 第三组指令中，若I6指令的加法运算完成时间早于I5指令的乘法运算时间，变成指令I6在指令I5写入R3前就写入R3，导致R3的内容错误，发生WAW相关

4.
- 不做了

错题总结：
- 注意！注意！注意！RAW是真相关，它虽然叫做“**写后读**”，犯的错误却是先**读后写**！

#### （5）其他

💎基于单总线结构的数据通路：
  - 基本特征
    - CPU 中的运算器、控制器、寄存器堆等核心部件均通过一条内部的公共总线连接起来
    - 同一时刻只有一个部件向总线输出数据
    - 数据传输只能分时使用总线
  - 数据通路图解
    - ![img](https://api2.mubu.com/v3/document_image/6964b651-0db1-4351-bb7d-86b444ea6e18-329792.jpg)
    - 📈指令周期图解
      - ![img](https://api2.mubu.com/v3/document_image/b9bd7783-05d1-4682-a29b-818f725bc7fe-329792.jpg)

中央处理器的定时：
  -  控制方式
    -  同步控制方式
      - 选取部件中最长操作时间作为统一的时间间隔进行时序同步。
      - **教材中例子都是同步**
    -  异步控制方式
      - 系统不设立统一的时间间隔标准，各部件设置各自的时序系统，分别实现各自的时序控制，主要采用异步应答通信机制实现
    -  联合控制方式
      - 将同步控制与异步控制相结合，对大多数需要节拍数相近的指令，采用同步控制；而对少数需要节拍数多的指令或节拍数不固定的指令，采用异步控制
  - 💎传统三级时序
    - 机器周期电位、节拍电位、节拍脉冲
    - 📈时序图
      - **一条指令包括x个机器周期，一个机器周期包括y个节拍，一个节拍包括z个脉冲**![img](https://api2.mubu.com/v3/document_image/a33be99e-bc66-4436-998e-bca2a2fb81f4-329792.jpg)
      - x，y，z的值与指令寻址方式，CPU设计等有关，可固定，也可以变化
      - **节拍电位变化的时刻决定了控制信号产生的时刻**
      - **节拍电位的长度决定控制信号的持续时间**
      - **脉冲跳变时刻决定寄存器，存储器锁存时刻**
      - 为满足寄存器的定时机制，正确写入数据，节拍电位变化时刻应该和脉冲跳变时刻错开
  - 现代时序
    - 只有时钟周期，指令执行过程是时钟驱动的状态机
  - 时序发生器
    - 功能
      - **输入***时钟脉冲信号，指令译码信号、反馈信号*，持续不断地产生*状态周期电位和节拍电位*，操作控制器利用这些周期、节拍电位信号对操作控制信号进行时序的调制，生成控制信号序列
    - 输入：clk，指令译码、反馈信号
    - 输出：状态周期电位，节拍电位
    - 📈图解
      - ![img](https://api2.mubu.com/v3/document_image/1abe4764-4514-435f-b534-2407d3e520fb-329792.jpg)![img](https://api2.mubu.com/v3/document_image/f512c9fb-8f50-4b21-a49e-7814f5249688-329792.jpg)
    - 设计思路
      - 利用数字逻辑同步时序电路设计方法进行构造，根据状态机进行实现
      - 定长指令周期状态机
        - 状态切换只与时钟信号有关![img](https://api2.mubu.com/v3/document_image/7cfd71a3-b48c-4735-a505-4e6460e37ea0-329792.jpg)
      - 变长指令周期状态机
        - 状态切换还与指令译码有关![img](https://api2.mubu.com/v3/document_image/47faac3c-6d3b-44df-bf74-13495098dc50-329792.jpg)

💎微程序控制器：
  - 基本概念
    -  微命令：控制部件向执行部件发出的各种**控制命令**
    -  微操作：执行部件收到微命令后所进行的**操作**
      - 相容性微操作：能在同一个时钟周期内并行执行的微操作
      - 互斥性微操作：不能在同一个时钟周期并行执行的微操作
    - 微指令与微程序
      - 微指令：一个CPU周期或时钟周期中，一组实现一定操作功能的**微命令的组合**
        - 微指令格式
          - 操作控制字段：**存储微操作控制信号**
            - 每一位对应一个控制信号，也称微命令，可同时给出多个操作信号
          - 顺序控制字段：**控制微程序执行顺序**
            - 判别测试位：如果为1，要约定条件生成下一条微指令地址
            - 下址字段：判别测试条件为0时下一条微指令的地址
        - 图解![img](https://api2.mubu.com/v3/document_image/6e825efb-3223-4ea2-8bdf-43f4cf234cb7-329792.jpg)
      - 微程序
        - 实现一条指令功能的若干条**微指令的集合**（即：1条指令 = 微程序 → 微指令 → 微命令 / 微操作）
        - 微指令的执行意味着**其定义的所有控制信号被激活**
        - 微程序的执行意味着控制**一条指令执行所需要的控制信号按照一定的顺序依次被激活**，是一种*软时序*
  - 💎微程序控制器组成
    -   微程序控制器组成原理
      - 初始化，微地址寄存器为0，控存0号单元为取指令微程序入口
      - 📈下址字段法![img](https://api2.mubu.com/v3/document_image/5ce99f63-5b98-48ce-a0a3-e3ec53b02d3a-329792.jpg)
      - 📈计数器法
        - 判别测试位增加一个P_end，表示最后一条微指令，下一条微指令应该返回取指微程序![img](https://api2.mubu.com/v3/document_image/2b6dd194-5a6b-406e-8a9f-5846ae257b5f-329792.jpg)
  - 微程序制器的工作原理
    - 💎仿照程序设计的方法，把完成每条指令所需要的操作控制信号编写成微指令，存放到一个只读存储器(控存)中。每条机器指令对应一段微程序，当机器执行程序时依次读出每条指令所对应的微指令，执行每条微指令中规定的微操作，从而完成指令的功能，重复这一过程，直到该程序的所有指令完成
    - 存储逻辑：**控制信号序列不由硬件产生，而是像程序一样存储起来**
      - 控制信号序列分解为若干时钟节拍
      - 一个节拍的控制信号编成一条微指令
      - 一条指令有多少节拍就对应多少条微指令，形成一段微程序
      - 取指令过程是公操作，取指令过程对应取指微程序，**取指微程序为所有指令共享**
      - 📈控存中的微程序图解![img](https://api2.mubu.com/v3/document_image/98eb7b3b-ac19-4da5-9c90-fdefe3009d46-329792.jpg)
    - 软时序：依序执行微指令即可生成控制信号序列
      - 执行一条微指令，给出对应的控制信号
      - 微指令周期就是一个时钟周期，控制器信号的时间长度就是一个节拍
      - 软时序：按顺序执行微指令，就是按顺序给出控制信号
      - 指令取指执行→微程序执行→ 微指令执行→生成控制信号序列
  - 微程序控制器的设计流程
    1. 分析指令执行的数据通路，列出每条指令在所有寻址方式下的执行操作流程和每一步所需要的控制信号
    2. 对指令的操作流程进行细化，将每条指令的每个微操作分配到具体的机器周期的各个时间节拍信号上
    3. 以时钟周期为单位构建指令执行状态图
    4. 设计微指令格式、微命令编码方法
    5. 根据指令执行状态图编制每条指令的微程序，按照状态机组织微程序存放到控存中
    6. 根据微程序组织方式构建微程序控制器中的地址转移逻辑，构建微程序地址转移逻辑、微地址寄存器μAR、控存之间的通路，实现微程序控制器
  - 微指令及其编码方法
    - 微指令编码方法
      - 直接表示法
        - 将微指令的操作控制字段的每个二进制位定义为一个微命令，用该位的“1”或“0”表示相应的微命令的“有”或“无”
        - 简单，并行，速度快，微指令字长
      - 编码表示法
        - 将微指令格式中的操作控制字段分成若干组，每组中包含若干个互斥性微命令，将相容性的微命令安排在不同组
        - 应该预留空状态，表示任何一个互斥信号都不给出
        - 微指令字短、增加译码器延迟
      - 混合表示法
        - 将直接表示法与编码表示法混合使用。
    - 微指令格式
      - 水平微指令
        - 编程难，微程序短，并行性高，速度快，控存开销大
      - 垂直微指令
        - 编程易，微程序长，并行性差，速度慢，控存开销小，已淘汰

多处理器的基本概念：
- 待补充

**王道习题：**

一轮标记题：2 8 11 12 13 23 25；6

二轮重做：25；6 7

大题：

错题总结：
- 一条水平型微指令能定义并执行几种并行的基本操作；一条垂直型微指令只能定义并执行一种基本操作

#### 专题——MIPS处理器

梅开二度——MIPS汇编语言：
- MIPS CPU寄存器包括32个通用寄存器、3个特殊功能寄存器和MIPS FPU寄存器。
- MIPS指令可以分成以下各类:
  - 空操作no-op；
  - 寄存器 / 寄存器传输：用得很广，包括条件传输在内；
  - 常数加载：作为数值和地址的整型立即数；
  - 算术/逻辑指令；
  - 整数乘法、除法和求余数；
  - 整数乘加；
  - 加载和存储；
  - 跳转、子程序调用和分支；
  - 断点和自陷；
  - CPO功能：CPU控制指令；
  - 浮点;
  - 用户态的受限访问：rdhwr和 synci
  - 注：**64位版本开头以“d”表示，无符号数以“u”结尾，立即数通常以“i”结尾，字节操作以“b”结尾，双字操作以“d”结尾，字操作以“w”结尾**
- 💎常见指令
    - r型指令
        - 3寄存器r型指令：add；sub；and；or；xor
        - 2寄存器r型指令：sll（shift left logical）；srl；sra（没有rs）
        - 1寄存器r型指令：jr（跳转寄存器）（只有rs）
    - 💎i型指令
        - 面向运算的i型指令：addi；andi；ori；xori
            - **第一条指令是进行符号扩展，其余是0扩展**
        - 面向访存的i型指令：lw（load word）；sw（save word）
      - **汇编语言**：sw rt, imm(rs) # mem[ $rs + E(imm) ] ← rt # E(imm) 表示带符号扩展
        - 面向数位设置的i型指令：lui（设置寄存器的高16位）（load upper immediate）
            - **汇编语言**：lui rt, imm # $rt ← imm << 16 (空位补0)
        - 面向分支的i型指令：beq（branch if equal）；bne（branch if not equal）
            - **汇编语言**(beq)：beq rs, rt, imm # if($rs == $rt) $PC ← $PC + E(imm) << 2
            - 因为mips的指令长度为4个字节，所以指令地址一定为4的倍数，因而地址后两位一定为0，**因此offset左移两位使偏移量变为4的倍数**，保持地址最后两位为0
    - j型指令
        - j：无条件跳转
            - **汇编语言**：j address # $PC ← ($PC + 4)取高4位 ∪ (address << 2)
        - jal：调用与联结（jump and link？）
- MIPS寻址方式
  - 在MIPS32指令集中，不单设寻址方式说明字段
  - R型指令：由op和funct字段共同隐含说明当前的寻址方式
  - I型和J型指令：由op字段隐含说明当前指令使用的寻址方式
  - 立即数寻址
  - 寄存器寻址
  - 基址寻址：lw, sw, lh, sh, lb, lbu等
  - 相对寻址：beq, bne
  - 伪直接寻址（页面寻址）：j, jal

MIPS处理器：
- 控制信号功能说明 （8条核心指令集）

控制信号|信号说明|产生条件
-|-|-
PCWrite|PC写使能控制|取指令周期，分支指令执行
IorD|指令还是数据|0表示指令，1表示数据
IRwrite|指令寄存器写使能|高电平有效
**MemWrite**|写内存控制信号|sw指令
MemRead|读内存控制信号|lw指令 取指令
Beq|Beq指令译码信号|Beq指令
Bne|Bne指令译码信号|Bne指令
PcSrc|PC输入来源|顺序寻址还是跳跃寻址
**AluOP / AluCtrl**|运算器操作控制符 4位|ALU_Control控制，00加，01减，10由Funct定
AluSrcA|运算器第一输入选择|
AluSrcB|运算器第二输入选择|Lw指令，sw指令，addi
**RegWrite**|*寄存器写使能*控制信号|寄存器写回信号
**RegDst**|*写入寄存器选择*控制信号|R型指令
**MemToReg**|写入寄存器的数据来自存储器|lw指令

- MIPS单周期数据通路举例：略
- MIPS多周期数据通路举例：
  - 📈数据通路图解![img](https://files.catbox.moe/fzcu38.png)
    - **不再区分指令存储器和数据存储器**，指令和数据保存在同一存储器中
    - 部分功能单元，如ALU可在一条指令执行过程的不同时钟周期中多次使用，**不需要额外设置ALU或加法器**
    - 时钟周期变小，传输通路变短
    - 主要功能单元输出端都增加了一些**附加寄存器**，暂存（**锁存**）当前时钟周期加工处理的数据，给后续时钟周期使用
      - DR、IR
      - A、B：缓存寄存器操作数
      - C：缓存分支地址或ALU运算结果
    - 增加和扩展了部分多路选择器
    - 增加了ALU控制器
      - 专门负责产生 ALU 的运算选择控制信号 AluOP
    - 方便合并R型运算指令以及I型指令的状态机
    - 📈指令周期图解![img](https://api2.mubu.com/v3/document_image/b5c00733-af77-4711-9c26-dc5f7f220ed0-329792.jpg)
      - 注意S2，S5状态可以合并，R型运算指令共享S8 ~ S9路径，I型运算共享S10 ~ S11路径
      - 控制器是时序逻辑，需要实现上述状态机，每一个圆圈一个时钟周期
      - 不同指令时钟周期数不一样
- MIPS流水线分支处理
  - 📈流水线图解![img](https://files.catbox.moe/ui0o96.png)
  - 控制冲突 / 分支冲突：
    - EX.Branch分支PC,并给出IF/ID.ID/EX清零信号
      - 拒绝异步清零
    - 延迟槽：nop → 一条有用的指令
      - PC = PC + 8
  - 数据冲突 / 段间互锁（空操作）：
    - ID段与WB段数据相关消除：先写后读，寄存器文件**下跳沿写入**，流水接口**上跳沿有效**
    - ID段与MEM段数据相关：IF段，ID段暂停等待数据写回（stall），EX段插入气泡（然后又会有ID段与WB段数据相关消除）
    - ID段与EX段数据相关：IF段，ID段暂停等待数据写回，EX段插入气泡（然后又会有ID段与MEM段数据相关）（然后又会有ID段与WB段数据相关消除）
    - 相关检测逻辑
      - （ID.ReadReg# == EX.WriteReg#） && （EX.RegWrite==1）
      - （ID.ReadReg# == MEM.WriteReg#） && （MEM.RegWrite==1）
      - 0号寄存器不考虑相关性
  - 数据冲突 / 段间互锁（数据重定向）（数据旁路）（bypass）（MIPS方案）：
    - 构建重定向通路
      - 在第一次使用寄存器的位置增加多路选择器
      - 连接可能的重定向通路
    - 构建重定向逻辑——生成多路选择器选择控制信号
      - 在ID段根据数据相关情况产生对应的重定向控制信号
      - **除Load-Use相关仍需插入一个气泡外，其他重定向情况都无需暂停流水线**
    - 图例![img](https://files.catbox.moe/632bcu.png)
    - Load-Use相关：EX段时延 = MEM时延 + ALU时延，成为关键路径，流水线性能下降
      - 特殊处理：ID译码阶段处理，同上（ID段与EX段数据相关）

💎💎流水线的控制信号：
控制信号|位置|来源|功能说明
-|-|-|-
**BranchTaken**|**IF**|**EX**|分支跳转信号
RegDst|ID|ID|1为rd，0为rt
**RegWrite**|**ID**|**WB**|控制寄存器堆写
AluCtrl|EX|EX|控制ALU进行不同运算
MemWrite|MEM|MEM|控制数据存储器写
MemToReg|WB|WB|为1时**从数据存储器读出**数据写回寄存器，否则将ALU结果写回

#### 本章小结

- 指令和数据均存放在内存中，计算机如何从时间和空间上区分它们是指令还是数据？
    - 从时间上讲，取指令事件发生在“取指周期”，取数据事件发生在“执行周期”。从空间上讲，从内存读出的指令流流向控制器（指令寄存器），从内存读出的数据流流向运算器（通用寄存器）
- 流水线越多，并行度就越高。是否流水段越多，指令执行越快？
    - 错误，原因如下:
        1. 流水段**缓冲**之间的**额外开销**增大。每个流水段有一些额外开销用于缓冲间传送数据、进行各种准备和发送等功能，这些开销加长了一条指令的整个执行时间，当指令间逻辑上相互依赖时，开销更大
        2. 流水**段间控制逻辑**变多、变复杂。用于流水线优化和存储器（或寄存器）冲突处理的控制逻辑将随流水段的增加而大增，这可能导致用于流水段之间控制的逻辑比段本身的控制逻辑更复杂
- 有关指令相关、数据相关的几个概念
    1. 两条连续的指令读取相同的寄存器时，会产生读后读（Read After Read, RAR）相关，这种相关不会影响流水线
    2. 某条指令要读取上一条指令所写入的寄存器时，会产生写后读（Read After Write, RAW）相关，**它称数据相关或真相关**，影响流水线。按序流动的流水线只可能出现RAW相关
    3. 某条指令的上条指令要读/写该指令的输出寄存器时，会产生读后写(Write After Read, WAR）和写后写（Write After Write, WAW）相关。在非按序流动的流水线中，既可能发生RAW相关，又可能发生WAR相关和WAW相关
    4. **对流水线影响最严重的指令相关是数据相关**

### <a name="9">（六）总线与输入输出(I/O)系统</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）总线的基本概念

总线基本概念：
  - 总线定义
    - 早期总线是指连接多个计算机硬件功能部件的一组公共的并行传输信号线缆，用于在各功能部件之间进行信息传输
    - 现代总线是指连接多个计算机内部功能部件或多个计算机的**通信系统**，总线既包括相关的硬件（总线控制器、总线接口）、软件，**也包括相关的通信协议**
  - 总线复用
    - 减少引脚数目
    - 一组传输线具有不同功能
  - 总线设备
    - 主设备
    - 从设备
  - 总线标准
    - 对总线及总线接口的物理特性、电气特性、功能特性和时间特性的详细规范和协议，总线标准有利于不同厂家分工协作，也方便设备互换
  - 总线与三态门
    - 三态门具有高、低电平和高阻三种状态，可以用于总线的输出控制，避免数据冲突，也可以作为设备与总线之间的缓冲器，增强驱动能力，另外还可以用于实现有向总线。

总线分类：
  - 按传输方向分
    - 单向传输总线
    - 双向传输总线
  - 按传输模式分
    - 并行传输总线
    - 串行传输总线
  - 按时序方式分
    - 同步总线
    - 异步总线
  - 按信号功能分
    - 数据总线：**双向传输，传输数据，位宽与机器字长相关**
    - 地址总线：**单向传输，传输地址，位宽与主存空间有关**
    - 控制总线：**双向传输，传输控制命令或反馈信号**
  - 按所处位置分
    - 片内总线: 芯片内部
    - 系统总线：连接各功能部件的总线
    - I/O总线: 连接中低速I/O设备
    - 外部总线：连接计算机与外设

总线标准：
  - 片内总线
    - AMBA、Wishbone；
  - 系统总线
    - **ISA、EISA**、MCA、**VESA、PCI**、FSB、BSB、IHA、HT、QPI、DMI；
  - I/O总线
    - AGP、**PCIe**、LPC、SPI、I2C、SMBUS、ATA、**SATA**、SCSI、SAS、FiberChannel；
  - 外部总线
    - RS-232-C、RS-485、IEEE-488、**USB**、IEEE1394、Thunderbolt、InfiniBand等总线。

总线结构：
  - 单总线结构
    - 所有功能部件都连接在同一总线上
    - 总线被不同设备分时使用
    - 单总线结构简单，使用灵活，扩充新设备容易
    - 但无法发挥高速设备的性能，系统总线负载重，计算机系统性能低下
  - 💎双总线结构
    - **CPU、主存和I/O设备分别通过不同总线连接**
      - 增设单独存储总线结构的双总线结构
      - 采用桥接芯片分离CPU总线和I/O总线的双总线结构
        - 传统教材中DMA总线并不常见，PC中没有这种结构
    - 双总线结构一定程度上将高速设备和慢速设备进行了隔离，提升了系统总线性能
  - 三总线结构
    - 三总线结构主机总线、PCI总线、ISA总线通过桥接芯片连接在一起
    - 进一步将不同速率的传输活动进行细分
      - 最快的CPU、DRAM放在系统总线上
      - 将中速的显卡、磁盘、网卡等高速设备连接在PCI总线上
      - 而传统的慢速设备连接在ISA总线上，计算机系统性能进一步提升
  - 高性能总线
    - 现代计算机普遍采用分离的多层次总线结构
      - 不同总线之间采用桥芯片进行连接和缓冲
      - 高速设备靠近CPU，慢速设备远离CPU，形成了经典的南北桥结构
    - 早期北桥芯片集成了内存控制器、显卡接口，通过前端总线与CPU连接，通过Hub-Link总线连接南桥芯片，南桥芯片连接慢速设备接口
    - 后来内存控制器集成进CPU中，前端总线演变成了更高速的QPI总线，连接南北桥的芯片的总线也变成了DMI总线
    - 最新的CPU甚至集成了GPU，北桥芯片消失，CPU直接通过DMI总线连接南桥芯片

总线组成与性能指标：
  - 总线的组成
    - 总线系统通常包括一组连接线缆和总线控制器
    - 总线控制器主要负责总线控制权的仲裁以及总线资源的分配和管理，所有设备都必须通过总线接口与总线连接。可以通过总线复用技术减少总线线缆的数目，节省布线空间降低成本，但这种方式会带来性能损失
    - 可以获得总线控制权的设备称为总线主设备，而被主设备寻址访问的设备称为从设备，正在使用总线的主设备称为活动主设备，传统计算机只有CPU、DMA控制器可以作为主设备，**总线主控技术使得I/O设备也可以作为主设备与主存直接进行数据交互**
  - 总线性能指标
    - 总线宽度
      - 指数据总线的数量，如8位、16位、32位等。
    - 总线时钟频率
      - 同步传输总线中利用总线时钟进行同步，时钟频率越快，传输速度越快
    - 总线传输周期
      - 指一次总线操作所需要的时间，简称总线周期
      - 包括总线申请阶段、寻址阶段、传输阶段和结束阶段等4个阶段
    - 单时钟传输次数
      - 指一个总线时钟周期内传输数据的次数
      - 采用DDR、QDR技术该值分别为2和4
      - 总线的实际工作频率 = 总线时钟频率 × 单时钟传输次数
    - 💎总线带宽
      - 即在总线的最大数据传输率，单位是MB/s或GB/s。
      - 通常不考虑总线传输周期中总线申请和寻址阶段的开销
      - 总线带宽计算的是峰值性能
      - 💎同步总线带宽 = 总线宽度 × 总线时钟频率 × 单时钟传输次数
      - 串行总线带宽 = 总线时钟频率 × 编码效率 × 并发通路数

💎总线传输过程：
  - 标准传输模式
    - 申请阶段
      - 主设备提出总线申请
    - 寻址阶段
      - 获的总线的主设备发出要访问设备的地址和命令，启动从设备
    - 传输阶段
      - 主从设备传输数据
    - 结束阶段
      - 主设备让出总线使用权
  - 突发（Burst）传送模式
    - 支持**一个寻址阶段和多个数据阶段**
    - 用于块传输的，适合**成组传送事务**
  - 总线事务
    - 是指总线上的一对设备之间的一次信息交换过程
    - 典型的总线事务类型有存储器读、存储器写、I/O读、I/O写、中断响应、DMA响应等
    - 总线事务一般包括一次寻址阶段和一次数据阶段

总线的信息传送：
  - 串行传送
    - 信息按从低位到高位的顺序逐位以脉冲方式传送，只有一条数据传输线，一次只能传送一位。根据数据传送方向的不同可分为单工、全双工和半双工3种
  - 并行传送
    - 并行传送是指一个信息的每位同时传送，每位都有各自的传输线，互不干扰，一次传送整个信息
  - 并串行传送
    - 是对传送速度与传输线数进行折中的一种传送方式。如将16位数据分成两个8位组传送
  - 分时传送
    - 分时传送有两种含义，一是采用总线复用，二是指共享总线的部件分时使用总线
  - 数据传送方式
    - 读写操作、块传送操作、写后读与读修改写操作、广播与广集操作4种

**王道习题：**

二轮重做：8 9 15 16 18 22 27 28 29

大题：2

2.
- 解：
    1. 读操作的时钟周期数: 1+2+4=7；对应的频率: 100MHz/7；总线宽度: 6×4B=24B；所以数据传输率=总线宽度/读时间=24×(100MHz/7) = 343MB/s
    2. 写操作的时钟周期数: 1+1+4=6；对应的频率: 100MHz/6；总线宽度: 6×4B=24B；所以数据传输率=总线宽度/写时间=24×(100MHz/6) = 400MB/s
    3. 
        - 设传送数据量为X字节，又已知在全部的传输中，70%用于读，30%用于写，读的数据量0.7X，读所用时间为0.7X/343
        - 写的数据量为0.3X，写所用时间为0.3X/400，传输X字节的数据需要花去0.7X/343 + 0.3X/400
        - 故平均传输速率=X/(0.7X/343+0.3X/400) = 1/(0.7/343 + 0.3/400)= 358MB/s

错题总结：
- 串行传输是指数据的传输在一条线路上按位进行，并行传输是指每个数据位有一条单独的传输线，所有的数据位同时进行。不同信号在同一条信号线上分时传输的方式，称为总线复用方式
- 猝发（突发）传输是在一个总线周期中，可以传输多个存储地址连续的数据，**即一次传输一个地址和一批地址连续的数据**，并行传输是在传输中**有多个数据位**同时在设备之间进行的传输，串行传输是指数据的二进制代码在一条物理信道上以位为单位按时间顺序**逐位传输**的方式，同步传输是指传输过程**由统一的时钟控制**
- 27题：初看可能会觉得A正确，并行总线传输通常比串行总线传输速率快，但这不是绝对的。在实际时钟频率较低的情况下，并行总线因为可以同时传输若干比特，速率确实比串行总线快。但是，随着技术的发展，时钟频率越来越高，并行总线之间的相互干扰越来越严重，当时钟频率提高到一定程度时，传输的数据已无法恢复。而串行总线因为导线少，线间干扰容易控制，反而可通过不断提高时钟频率来提高传输速率，A错误。总线复用是指一种信号线在不同的时间传输不同的信息，它可使用较少的线路传输更多的信息，从而节省空间和成本，因此B正确。突发（猝发）传输是指在一个总线周期中，可以传输多个存储地址连续的数据，即一次传输一个地址和一批地址连续的数据，C正确。分离事务通信是总线复用的一种，相比单一的传输线路可以提高总线的利用率，D正确
- 总线周期 = 多个时钟周期

#### （2）磁盘存储器

- 见OS

#### （3）I/O控制器

I/O系统基本概念：
  - I/O系统构成
    - I/O硬件
      - 外部设备、控制器，I/O接口，I/O控制总线
    - I/O软件
      - 与操作系统无关的I/O库
      - 与设备无关的OS调用库
      - 设备驱动程序
  - I/O控制方式
    - 程序查询（CPU占用比较高）
    - 中断控制（适合处理随机事件）
    - DMA（批量传输）
    - 通道（进一步解放CPU）

1）I/O控制器的功能和基本结构：
- I/O接口的功能
  - 设备寻址
  - 数据交互
  - 设备控制
  - 状态检测
  - 数据缓冲
  - 格式转换
- I/O接口的结构
  - 数据缓冲寄存器(DBR)
  - 设备状态寄存器(DSR)
  - 设备命令寄存器(DCR)
  - 地址译码逻辑
  - 数据格式转换逻辑
  - 📈图解
    - ![img](https://api2.mubu.com/v3/document_image/82bc06d5-54bc-468e-a2df-06692effa7cb-329792.jpg)

I/O接口的分类：
  - 并行/串行接口
  - 可编程接口和不可编程接口
  - 通用接口与专用接口
  - 同步/异步接口
  - 直接传送/程序查询/程序中断/DMA等接口

2）💎I/O设备的编址方式
  - 独立编址
    - 外设使用独立的地址空间
    - 需要特殊的I/O指令访问设备
  - 统一编址（存储映射I/O编址）
    - 外设与主存统一编址
    - **主存空间地址划分一部分出来供外设使用**
    - 访存指令访问设备，**无需I/O指令**

**王道习题：**

二轮重做：12

错题总结：
- 12题：I/O接口即I/O控制器，其功能是接收主机发送的I/O控制信号，并实现主机和外部设备之间的信息交换。磁盘驱动器是由磁头、磁盘和读写电路等组成的，也就是我们平常所说的磁盘本身，A错误。B、C和D（打印机适配器、网络控制器、可编程中断控制器）均为I/O控制器


#### （4）基本I/O方式

1）程序查询方式
  - 💎程序查询方式的输入输出相当于**条件传送方式**。该方式下，CPU查询接口中的状态字，并根据查询的结果决定下一步的动作。如果设备准备就绪则开始CPU与外设之间的数据传送；若未准备就绪，则开始独占或定时查询
    - 图例：![img](https://api2.mubu.com/v3/document_image/236e30b8-fc4c-4847-a49e-f0c6561d20f0-329792.jpg)
    - 独占查询中CPU不是在进行输入输出操作就是在查询设备状态
    - 定时查询可以让CPU执行其他任务，本质上是基于中断技术实现的
    - 实现简单，但CPU利用率不高
    - 程序查询方式不一定是最差的，现代OS中快速设备也可以采用程序查询方式

2）程序中断方式：中断的基本概念，中断响应过程，中断处理过程，多重中断和中断屏蔽的概念；
  - 💎中断的基本概念
    - （1）中断的定义
      - 图例：![img](https://api2.mubu.com/v3/document_image/4cadc98e-28a1-40a8-99da-5d1fad8dbda1-329792.jpg)
      - CPU暂时停现行程序，转向为某随机事件服务，待事件处理完毕，再恢复执行原来被中止的程序继续运行，这个过程称为中断
    - 中断的作用
      - 实现CPU和外设的并行工作
      - 方便程序调试、故障处理
      - 实时处理和人机交互
      - 多任务以及多处理器交互
      - 可实现操作系统CPU调度（定时中断）
    - 中断的分类
      - 外部中断
        - 由CPU外部事件引起的中断
        - **这类中断大部分由外设发出**
        - 可屏蔽中断
      - 内部异常
        - 是发生在CPU内部的中断
        - 故障（Fault）、自陷（Trap）和终止（Abort）
        - 不可屏蔽中断        
    - 中断优先级
      - 指响应和处理中断请求的先后次序
      - 当几个设备同时有中断请求时，优先级高的先响应，优先级低的后响应
      - 响应优先级
        - 是指CPU对各设备中断请求进行响应的先后次序
        - 在硬件上是固定的
      - 处理优先级
        - 指中断嵌套的实际优先级处理次序
        - 通常可以利用中断屏蔽技术动态调整
  - 中断的响应条件
    - 对应的中断请求未被屏蔽
    - 当前没有更高优先级的其它中断请求
    - 如果CPU正在执行中断服务，则中断请求符合嵌套条件。
    - **中断使能位**处于处于**使能状态**，也就是开中断状态
    - CPU己执行完一条指令的最后一个状态周期
    - 不可屏蔽中断和内部异常响应中断的条件和时机和可屏蔽的外部中断源略有差异
  - 中断响应过程
    - 1、硬件**关中断**
    - 2、**保存断点，保存PC值**
    - 3、**中断识别**，修改PC跳转至中断服务程序
      - 任务：确定中断是由哪个中断源发出的
        - 程序查询法
        - 硬件查询法
        - 独立请求
      - 具体方式与中断源与CPU的连接方式有关
      - 完成中断识别时还需要清除当前中断请求
      - 如何获得中断服务程序的入口地址
        - 向量中断法
          - 中断向量：中断服务程序入口地址和程序状态字
          - 中断向量表：中断向量的集合
          - 向量地址：中断指针，用于访问中断向量表的地址码
        - 非向量中断法
    - 中断响应的过程**可以看做**是执行中断隐指令完成的（实际不存在中断隐指令，是硬件自动处理的操作）
  - 💎中断处理过程
    - 📈流程图（中断服务程序中的开中断，关中断是指令实现的）![img](https://api2.mubu.com/v3/document_image/ff2fa8f6-93c9-49a8-9480-3cfaa024eee1-329792.jpg)
  - 💎多重中断和中断屏蔽
    - 单级中断
      - 中断服务程序在执行过程不能被中断
    - 多重中断，也称嵌套中断
      - 中断服务程序在执行过程可以被中断（类似递归、套娃）
      - 高优先级中断可以中断低优先级中断服务
      - 中断屏蔽技术动态调整处理优先级可以实现低优先级中断打断高优先级中断服务
      - 中断服务程序**保护现场后开中断即可实现中断嵌套**
      - 📈图解
        - 图![img](https://api2.mubu.com/v3/document_image/d2141d24-3cd5-45fc-8637-328f4e6f6016-329792.jpg)

3）DMA方式，DMA控制器组成，DMA传送过程，设备传输性能计算。
  - DMA基本概念
    - DMA方式**由DMAC临时接替CPU控制总线**，控制设备和内存之间进行直接的数据交换，信息传送不再经过CPU寄存器中转，大大提升了CPU利用率
    - 适合高速设备、磁盘，网卡等，硬件成本高
  - 内存争用问题
    - 外设与主存之间DMA传送数据时，CPU仍可执行主程序，存在DMAC与CPU内存争用的可能
      - 采用停止访内
      - 交替访问
      - 周期挪用
  - DMA控制器组成
    - 📈图解：![img](https://api2.mubu.com/v3/document_image/6b529527-f87d-46cd-b5ce-63d6bf6d8d94-329792.jpg)
  - 💎DMA的传输过程
    - 预处理阶段
      - 准备传输参数，CPU执行程序完成
    - 传送阶段
      - 无需CPU参与
    - 结束阶段
      - CPU执行中断服务程序完成
    - 📈图解：![img](https://api2.mubu.com/v3/document_image/e63fdca1-0266-4edf-868c-21f213aa96bd-329792.jpg)
  - DMA与中断差异
    - 中断通过程序传送数据，DMA靠硬件来实现
    - 中断时机为两指令之间，DMA响应时机为两存储周期之间
    - 中断不仅具有数据传送能力，还能处理异常事件。DMA只能进行数据传送
    - **DMA仅挪用了一个存储周期**，不改变CPU现场
    - **DMA请求的优先权比中断请求高**。CPU优先响应DMA请求，是为了避免DMA所连接的高速外设丢失数据
    - DMA利用了中断技术

**王道习题：**

二轮重做：

大题

1.
- 待做

错题总结：

#### （5）其他

总线仲裁：
  - 集中式仲裁
    - 链式查询：总线允许信号按设备串行连接的顺序依次查询，接口和控制简单，但存在单点故障，优先级改变不灵活、响应速度慢。
    - 计数器定时查询：通过计数值决定查询总线请求的顺序。不存在单点故障，优先级可通过改变计数初始值改变，响应速度慢。
    - 独立请求：每个设备使用独立的总线请求线和应答线。优先级可通过编程改变，响应速度快。
  - 分布式仲裁
    - 自举分布式仲裁：每个设备只有检测到比自己优先级高的设备没有总线请求时才能发总线使用请求信号。
    - 并行竞争仲裁方式：请求主设备直接将仲裁号通过“线或”方式发送到共享的仲裁线上，所有请求主设备都将仲裁线上的仲裁号与自己进行逐位比较，如果比自己大，则在仲裁线上撤销自己的仲裁号，最后竞争获胜的设备获得总线控制权。
    - 冲突检测分散式仲裁：每个部件独立地请求使用总线。请求总线时若检测到其他部件在使用总线，则等待；若无则置总线忙信号，并获得总线的使用权。使用过程中还要坚持监听总线以避免冲突。

总线定时：
  - 同步方式
    - 用公共时钟信号对传输过程的每一步进行控制
    - 一个总线周期进行一次完整的数据传送。一个周期结束另一个即开始
    - 优点：速度快；易实现
    - 缺点：主从设备强制性同步，速度不匹配；无法检验数据有效性
    - 适用于总线长度短；各部件存取时间接近的系统
  - 异步方式
    - 用应答信号对传输过程进行控制
    - 传输双方通过“握手”实现定时控制
    - 优点：周期长度可变，适合速度差较大的设备
    - 缺点：控制复杂，慢
    - 分类
      - 不互锁：发出信号后过一段时间自动撤消
      - 半互锁：主设备发出请求后，必须等收到应答信号再撤销
      - 全互锁：双方必须收到应答信号后再撤销
  - 半同步方式
    - 同步和异步方式的折中，在同步时钟的控制下进行采样和应答
    - 统一时钟的基础上，增加一个wait信号
    - 适合速度差异大的设备交互
  - 分离事务通信方式
    - （1）主设备向从设备发出读请求信号，给出地址和请求命令
    - （2）当从设备进行应答后，主设备立即释放总线控制权
    - （3）从设备准备数据，此时总线用于处理其他总线事务
    - （4）**从设备准备好数据后将作为主设备**重新申请使用总线并将数据放置在数据总线上
    - （5）原主设备通过总线接收数据
    - 大大提高总线利用率，控制方式更加复杂。如PCIe总线

常见的输入设备：
  - 键盘
    - 将按键动作翻译成主机能接受的键值
      - 薄膜键盘
      - 机械键盘
      - 静电电容键盘
  - 鼠标
    - 将鼠标移动信息通过传感器传送给计算机控制光标的移动
      - 机械鼠标
      - 光电鼠标
- 常见的输出设备
  - 打印机
    - 针式打印机
      - 利用打印针撞击色带和打印介质，进而打印出点阵，再由点阵组成字符或图形来完成打印任务
      - 适合多层票据打印，噪音大，速度慢，打印质量低
    - 喷墨打印机
    - 激光打印机
      - 充电→曝光→显影→转印→定影→消电→清洁
      - 高速、静音，质量高
  - 显示器
    - 分类
      - 按器件分：CRT、LCD、LED
      - 按显示信息：字符、图形、图像
    - 主要参数
      - 屏幕尺寸
        - 对角线的长度，以英寸为单位
      - 分辨率
        - 是指显示器所能表示的像素个数
      - 灰度级
        - 灰度级是指黑白显示器中像素点的亮度差别
        - 彩色显示器中则表示颜色的差别
      - 刷新
        - 像素光点只能保持很短的时间
        - 在光点消失之前将其再次显示（刷新）
      - 刷新频率
        - 单位时间刷新的次数称为刷新频率
        - 也称为帧频或帧率
      - 显存带宽 = 分辨率 × 灰度级位数 × 刷新频率
  - 磁盘（OS经常考大题）
    - 磁盘存储容量 = 盘片数 × 2 × 磁道数 × 扇区数 / 磁道 × 扇区容量
    - 道密度（TPI）是指沿磁盘半径方向单位长度上的磁道数，单位为道／英寸
    - 位密度（BPI）是指磁道单位长度上记录的二进制代码的位数，单位是位／英寸
    - 外圈与内圈的记录密度不同，位密度一般是指内圈所能达到的记录密度
    - 平均定位时间。
      - 定位时间是指从发出磁盘读写命令起，磁头从当前位置移动到指定的记录位置，并开始读写操作所需要的时间。
        - 寻道时间：将磁头定位到指定磁道上所需的时间，称为寻道时间
        - 等待时间：找到指定磁道后至指定的记录移到磁头下的时间，和转速有关
    - 数据传输速率
      - 单位时间（s）从磁盘中读出或写入信息的数量，称为数据传输速率，单位是 bit/s
      - 读写磁头定位之后，可以根据磁盘的转速与存储密度来决定信息的传输速率
      - 设某磁盘的位密度为 M bit/英寸，转速为 V 英寸 /s，则该盘的数据传输速率为 MVbit/s

#### 本章小结

- 引入总线会导致什么问题？如何解决？
    - 引入总线后，总线上的各个设备分时共享同一总线，当总线上多个设备同时要求使用总线时就会导致总线的冲突。为解决多个主设备同时竞争总线控制权的问题，应当采用总线仲裁部件，以某种方式选择一个主设备优先获得总线控制权，只有获得了总线控制权的设备才能开始数据传送
- 同一个总线不能既采用同步方式又采用异步方式通信吗
    - 半同步通信总线可以。这类总线既保留了同步通信的特点，又能采用异步应答方式连接速度相差较大的设备。通过在异步总线中引入时钟信号，其就绪和应答等信号都在时钟的上升沿或下降沿有效，而不受其他时间的信号干扰
    - 例如，某个采用半同步方式的总线总是从某个时钟开始，在每个时钟到来时，采样Wait信号，若无效，则说明数据未准备好，下个时钟到来时，再采样Wait信号，直到检测到有效，再去数据线上取数据。PCI总线也是一种半同步总线，它的所有事件都在时钟下降沿同步，总线设备在时钟开始的上升沿采样总线信号

## <a name="10">操作系统</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

### <a name="11">（一）操作系统概述</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### a)操作系统的基本概念；内核态与用户态、中断、异常和系统调用。

**操作系统的基本概念：**

操作系统：控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便接口与环境的程序集合

操作系统的特征：
- 并发（Concurrence）
- 共享（Sharing）：分为互斥共享方式和同时访问方式
- 虚拟（Virtual）：时分复用，如处理器的分时共享；空分复用，如虚拟存储器
- 异步（Asynchronism）：进程以不可预知的速度向前推进

操作系统的目标和功能：
- 四个「管理」
- 作为用户与计算机硬件系统之间的接口：分为命令接口和程序接口，前者又分为联机命令接口和脱机命令接口
- 实现对计算机资源的扩充

**王道习题：**

二轮重做：10 17

大题：

1.
- 解：略
- 答：**库函数是语言或应用程序的一部分，可以运行在用户空间中。而系统调用是操作系统的一部分，是内核为用户提供的程序接口，运行在内核空间中，而且许多库函数都会使用系统调用来实现功能。未使用系统调用的库函数，其执行效率通常要比系统调用的高，因为使用系统调用时，需要上下文的切换及状态的切换（也就是由用户态转向核心态）**

**操作系统的运行环境：**

处理器运行模式：
- 核心态 / 管态 / 内核态：操作系统的管理程序执行时处理机所处的状态。在此状态下处理机可使用全部指令（包括特权指令）；可以使用全部系统资源（包括整个存储区域）。以下内容的指令操作都工作在核心态：
    - 时钟管理：提供系统时间；通过时钟中断来实现进程的切换
    - 中断机制：只有一小部分功能属于内核，负责保护和恢复中断现场的信息，转移控制权到相关的处理程序
    - 原语：操作系统最底层；具有原子性；运行时间短且调用频率高
    - 系统控制的数据结构及处理：进程管理、存储器管理、设备管理
    - 注意：**切换到用户态的指令也是特权指令**
- 用户态 / 目态：用户程序执行时处理机所处的状态。在此状态下禁止使用特权指令，不能直接取用资源与改变机器状态，并且只允许用户程序访问自己的存储区域
    - 转到核心态的时机：用户程序访问系统资源（访管中断）、中断（I/O、时钟、通信等）、异常（故障、终止）
    - 注意：访管指令显然不可能是特权指令
    - 注意：**由用户态进入核心态，不仅状态需要切换，而且所用的堆栈也可能需要由用户堆栈切换为系统堆栈，但这个系统堆栈也是属于该进程的**

中断、异常、系统调用：
- 中断（Interruption）：也称**外中断**，指某个事件 (例如电源掉电、I/O传输结束等) 发生时，系统中止现行程序的运行、引出处理事件程序对该事件进行处理，处理完毕后返回断点继续执行的过程。**外中断可分为可屏蔽中断和不可屏蔽中断**。可屏蔽中断是指通过 INTR 线发出的中断请求，通过改变屏蔽字可以实现多重中断，从而使得中断处理更加灵活。不可屏蔽中断是指通过 NMI 线发出的中断请求，通常是紧急的硬件故障，如电源掉电等。此外，异常也是不能被屏蔽的
- 异常（Exception）：也称**内中断**，是由处理机内部事件引起的中断，**可分为故障（Fault）、自陷（Trap）、终止（Abort）**。异常可分为故障、自陷和终止。故障（Fault）通常是由指令执行引起的异常，如非法操作码、缺页故障、除数为0、运算溢出等。自陷（Trap）是一种事先安排的“异常”事件，用于在用户态下调用操作系统内核程序，如条件陷阱指令。终止（Abort）是指出现了使得CPU无法继续执行的硬件故障，如控制器出错、存储器校验错等。**故障异常和自陷异常属于软件中断（程序性异常)，终止异常和外部中断属于硬件中断**
- 系统调用：运行于核心态，功能大致可分为设备管理、文件管理、进程控制、进程通信、内存管理这五类

**王道习题：**

二轮重做：3 9 18 19 22 26 27 28

大题：

1.
- 解：略
- 答：区分执行态的主要目的是保护系统程序。用户态到核心态的转换发生在中断产生时，而核心态到用户态的转换则发生在中断返回用户程序时

2.
- 解：略
- 答：CPU操作与外设传输在时间上的重叠必须有中断和通道技术的支持，原因如下：
    - 通道是一种控制一台或多台外部设备的硬件机构，它一旦被启动就独立于CPU运行，因而做到了输入 / 输出操作与CPU并行工作
    - 中断就是在输入 / 输出结束时，或硬件发生某种故障时，由相应的硬件（即中断机构）向CPU发出信号，这时CPU立即停下工作而转向处理中断请求，待处理完中断后再继续原来的工作
    - 因此，通道技术和中断技术结合起来就可实现CPU与I/O设备并行工作，即CPU启动通道传输数据后便去执行其他程序的计算工作，而通道则进行输入/输出操作；当通道工作结束后，再通过中断机构向CPU发出中断请求，CPU则暂停正在执行的操作，对出现的中断进行处理，处理完后再继续原来的工作。这样，就真正做到了CPU与I/O设备并行工作

错题总结：
- 系统调用需要触发trap指令，如基于x86的Linux系统，该指令为int 0x80或sysenter。也就是说，用户程序设计时，使用的中断是内中断，其指令称为访管指令或trap指令
- 时钟中断的主要工作是处理和时间有关的信息及决定是否执行调度程序。和时间有关的所有信息包括系统时间、进程的时间片、延时、使用CPU的时间、各种定时器
- 计算机通过**硬件**机制完成由用户态到核心态的转换，而不是所谓“中断处理程序”，后者一般在核心态执行
- 子程序调用只需保存程序断点，即该指令的下一条指令的地址；中断处理不仅要保存断点(PC的内容)，还要保存程序状态字寄存器（PSW)的内容。**在中断处理中，最重要的两个寄存器是PC和PSWR**
- 当CPU检测到中断信号后，**由硬件自动保存被中断程序的断点(即程序计数器PC)**，之后，硬件找到该中断信号对应的中断向量，中断向量指明中断服务程序入口地址（各中断向量统一存放在中断向量表中，该表由操作系统初始化)。接下来开始执行中断服务程序，**保存PSW、保存中断屏蔽字、保存各通用寄存器的值**，并提供与中断信号对应的中断服务，中断服务程序属于操作系统内核
- 事件大总结：
    - *可能在用户态发生的事件：访管指令（只能）；**系统调用**；读时钟指令；取数指令；寄存器清零；跳转指令；设置断点指令；数据传送指令；压栈指令；从内存中取数；将运算结果装入内存；算术运算；命令解释；外部中断；各类异常（如缺页中断、trap指令）*
    - *只能在核心态发生的事件：广义指令（也就是系统调用）；置时钟指令；关中断指令；输入 / 输出；缺页处理；时钟中断处理；进程调度；进程切换；**设备管理、文件管理、进程控制、进程通信、内存管理**（也就是系统调用的细分功能）*

#### b)其他

操作系统发展历程：
- 手工操作阶段→联机批处理→脱机批处理→执行系统（左边三个均为单道批处理系统）→多道批处理系统/分时系统/实时系统→
- 单CPU计算机配置的操作系统：批量操作系统、分时操作系统、实时操作系统、个人计算机操作系统
- 具有并行结构的计算机系统配置的操作系统：网络操作系统（计算机网络，松耦合）、集群操作系统（分布存储的多计算机系统）

操作系统结构：
- 单体结构 / 模块结构：操作系统由多个模块构成，各模块可相互调用。优点：代码执行效率比较高。缺点：规模扩大时，难以维护、调试。操作系统实例：UNIX、Linux
- 层次结构：层次结构是把操作系统划分为若干层，各层之间只能是单向依赖或单向调用关系，这样不但系统结构清晰，而且不构成循环。优点：整体问题局部化，系统的正确性可通过各层正确性来保证。增加、修改或替换层次不影响其他层次，有利于系统的维护和扩充。缺点：层次结构是分层单向依赖的，必须要建立模块（进程）间的通信机制，系统花费在通信上的开销较大，系统的效率也就会降低
![](https://files.catbox.moe/5vd9ka.png)
![](https://files.catbox.moe/d4dgqg.png)
- 微内核构架：分为运行在核心态的微内核和运行在用户态并以C/S方式活动的服务进程。微内核：最基本的核心功能（进程 / 线程管理、低级存储器管理、中断和陷入处理）。优点：扩展性和灵活性、可靠性和安全性、可移植性、可以很好地支持分布式计算。缺点：系统开销大
- 宏内核构架：**主流的操作系统都是基于宏内核的构架，如Windows, Android, iOS, macOS, Linux等，但也广泛吸取了微内核构架的优点**
- 外核：不同于克隆真实机器的另一种虚拟机策略，外核所做的是保持多个虚拟机之间彼此不发生冲突

**操作系统引导（结合第四章学习）**：引导过程如下：
- 1.开机后，CPU加电，初始化(CS) = 0FFFFH，(IP) = 0，自动从FFFF:0单元开始执行程序。FFFF:0处有一条JMP指令，CPU执行该指令后，转去执行BIOS中的硬件系统检测和初始化程序。
- 2.初始化程序将建立BIOS所支持的中断向量，即将BIOS提供的中断例程的入口地址登记在中断向量表中。
- 3.硬件自检。启动BIOS程序后，先进行硬件自检，检查硬件是否出现故障。如有故障，主板会发出不同含义的蜂鸣，启动中止；如无故障，屏幕会显示CPU、内存、硬盘等信息
- 4.BIOS将控制权交给排在首位的启动设备后，CPU将该设备主引导扇区的内容（主引导记录MBR）加载到内存中，然后由MBR检查分区表，查找活动分区，并将该分区的引导扇区的内容（分区引导记录PBR）加载到内存，执行引导程序（启动管理器）
- 5.加载操作系统

虚拟机：
- 第一类虚拟机管理程序：直接运行在裸机上，是唯一一个运行在最高特权级的程序
- 第二类虚拟机管理程序：运行在宿主操作系统上，自己则是客户操作系统，实际上就像一个普通的进程

错题总结：
- 操作系统的基本类型主要有批处理操作系统、分时操作系统和实时操作系统
- 现代操作系统都是多任务的（主要特点是并发和并行），但并不一定需要运行在多CPU的硬件上，单个CPU也可满足要求
- 甘特图画法：
    - 横坐标上标出合适的时间间隔，纵坐标上的点是程序的名字
    - 过横坐标上每个标出的时间点，向上作垂直于横坐标的虚线
    - 用几种不同的线（推荐用“直线”“波浪线”“虚线”三种，较易区分）代表对不同资源的占用，按照题目给出的任务时间片，平行于横坐标把不同程序对应的线段分别画出来
    - 画图时要注意，如处理器、打印设备等资源是不能让两个程序同时使用的，有一个程序正在使用时，其他程序的请求只能排队。
- 常驻内存的只是操作系统内核，其他部分仅在需要时才调入
- 操作系统的引导程序位于磁盘活动分区的引导扇区中。引导程序分为两种：一种是位于ROM中的**自举程序**（BIOS的组成部分)，用于启动具体的设备；另一种是位于装有操作系统硬盘的活动分区的引导扇区中的**引导程序**（称为启动管理器)，用于引导操作系统
- 虚拟机既可以用软件实现，也可以用硬件实现

#### 本章小结

- 特权指令与非特权指令：
    - 所谓特权指令，是指有特殊权限的指令，由于这类指令的权限最大，使用不当将导致整个系统崩溃，如清内存、置时钟、分配系统资源、修改虚存的段表或页表、修改用户的访问权限等。若所有程序都能使用这些指令，则系统一天死机n次就不足为奇。为保证系统安全，这类指令只能用于操作系统或其他系统软件，不直接提供给用户使用
    - 在用户态下使用特权指令时，将产生中断以阻止用户使用特权指令
- 定义微内核构架OS的四个方面：①内核足够小；②基于C/S模式；③机制与策略分离；④采用面向对象技术

### <a name="12">（二）进程管理</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### a)进程、线程的基本概念以及两者的区别

*程序段 + 相关数据段 + PCB = 进程实体 / 进程映像*

- 进程：进程是进程实体的运行过程，是系统进行**资源分配和调度**的一个独立单位（强调资源）
- 线程：直接的理解就是“轻量级进程”，**它是一个基本的CPU执行单元**，也是程序执行流的最小单位，**是被系统独立调度和分派的基本单位**（强调调度/执行）
    - 线程由线程ID、程序计数器、寄存器集合和堆栈组成
    - 线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可以使用其进程拥有的全部资源
    - 线程也有就绪、阻塞、运行三种基本状态
    - 若线程的切换发生在同一个进程内部，则只需要很少的时空开销
- 进程与线程的区别：
    - 调度：拥有资源的是进程，独立调度的是线程
    - 并发性：线程的并发性更好（因为线程切换时，有可能会发生进程切换，也有可能不发生）
    - 拥有资源：线程只有必不可少、能保证独立运行的资源
    - 独立性：每个进程都拥有独立的地址空间和资源，进程中的线程对其他进程不可见
    - 系统开销：进程开销大，线程开销小，且同一进程中的不同线程之间的同步与通信非常容易实现
- 线程的组织与控制：
    - 线程控制块TCB：包括①线程标识符；②一组寄存器，包括程序计数器、状态寄存器和通用寄存器；③线程运行状态，用于描述线程正处于何种状态；④优先级；⑤线程专有存储区，线程切换时用于保存现场等；⑥堆栈指针，用于过程调用时保存局部变量及返回地址等
    - 一个线程可以读、写甚至清楚同一进程的另一个线程的堆栈
    - 线程也是具有生命期的，它由创建而产生，由调度而执行，由终止而消亡。相应地，在操作系统中就有用于创建线程和终止线程的函数（或系统调用）
    - 通常，线程被终止后并不立即释放它所占有的资源，只有当进程中的其他线程执行了分离函数后，被终止线程才与资源分离，此时的资源才能被其他线程利用。被终止但尚未释放资源的线程仍可被其他线程调用，以使被终止线程重新恢复运行
- 线程的实现方式：
    - 用户级线程（ULT）（多对一）：内核意识不到线程的存在，使用线程库设计多线程程序。该方式可以使线程切换时不转换到内核空间，节省了模式切换的开销
    - 内核级线程（KLT）（一对一）：又称内核支持的线程，该方式的线程切换比较快、开销小，但同一进程的线程切换仍需要转到核心态进行，系统开销较大
    - 组合方式（多对多）：多内核级线程对多用户级线程（通过时分多路复用实现）（**要求用户级线程的数量大于等于内核级线程的数量**）
    - 线程库的实现方法：
        - 在用户空间提供一个没有内核支持的库
        - 实现由操作系统直接支持的内核级的一个库
        - 目前使用的三种主要线程库为：POSIX Pthreads、Windows API、Java，其中POSIX Pthreads两种方式都支持，Windows支持内核级，Java依靠前两者实现
    

**王道习题：**

一轮标记题：5 7 14 15 20(1, 5) 22 33 38 40 44 47 48 56

二轮重做：1 14 16 26 28 52 56

大题：1 2 5 6

1.
- 答：执行一条命令或运行一个应用程序时，进程和程序之间形成一对一的关系。进程在执行过程中可以加载执行不同的应用程序，从而形成一对多的关系；以不同的参数或数据多次执行同一个应用程序时，形成多对一的关系；并发地执行不同的应用程序时，形成多对多的关系

2.
- 答：父进程创建子进程后，父进程与子进程同时执行（并发）。主程序调用子程序后，主程序暂停在调用点，子程序开始执行，直到子程序返回，主程序才开始执行

3.
- 答：**每个进程有自己独立的地址空间。在操作系统和硬件的地址保护机制下，进程无法访问其他进程的地址空间，所以必须借助于操作系统的系统调用函数实现进程之间的通信**。进程通信的主要方式有:
    - 共享内存区。通过系统调用创建共享内存区。多个进程可以（通过系统调用）连接同一个共享内存区，通过访问共享内存区实现进程之间的数据交换。**使用共享内存区时需要利用信号量解决同步互斥问题**
    - 消息传递。通过发送/接收**消息**，系统调用实现进程之间的通信。当进程发送消息时，系统将消息从用户缓冲区复制到内核中的消息缓冲区，然后将消息缓冲区挂入消息队列。进程发送的消息保持在消息队列中，直到被另一进程接收。当进程接收消息时，系统从消息队列中解挂消息缓冲区，将消息从内核的消息缓冲区中复制到用户缓冲区，然后释放消息缓冲区（即直接通信方式）
    - 管道系统。管道是先进先出（FIFO）的信息流，**允许多个进程向管道写入数据，允许多个进程从管道读出数据**。在读/写过程中，操作系统保证数据的写入顺序和读出顺序是一致的。进程通过读/写管道文件或管道设备实现彼此之间的通信。
    - 共享文件。利用操作系统提供的文件共享功能实现进程之间的通信。这时，**也需要信号量来解决文件共享操作中的同步和互斥问题**

4.
- 答：多线程是指在一个程序中可以定义多个线程并同时运行它们，每个线程可以执行不同的任务。多线程与多任务的区别：多任务是针对操作系统而言的，代表操作系统可以同时执行的程序个数；多线程是针对一个程序而言的，代表一个程序可以同时执行的线程个数，而每个线程可以完成不同的任务

5.
- 答：
    1. 是。若系统中未运行进程，则系统很快会选择一个就绪进程运行。只有就绪队列中无进程时，CPU才可能处于空闲状态
    2. 不一定。因为系统中的所有进程可能都处于等待态，**可能处于死锁状态**，也有可能因为等待的事件未发生而进入循环等待态
    3. 不一定。因为高优先级的进程有可能正处在等待队列中，进程调度会从就绪队列中选择一个进程占用CPU，这个被选中的进程可能优先级较低

6.
- 答：
    1. 为支持多进程的并发执行，系统为每个进程建立了一个数据结构：进程控制块（PCB），用于进程的管理和控制。PCB中记录了有关进程的一些描述信息和控制信息，包括**进程标识符、进程当前的状态、优先级、进程放弃CPU时的现场信息，以及指示组成进程的程序和数据在存储器中存放位置的信息**、资源使用信息、进程各种队列的连接指针和反映进程之间的隶属关系的信息等
    2. 创建、阻塞、唤醒、终止（总之就是没有运行原语）
    3. 略，**总之强调两点：①进程状态的转换；②进程PCB的改变**

7.
- 答：
    1. 时间片轮转法调度进程策略
    2. 
        - 1.进程被调度，获得CPU，进入运行态
        - 2.进程需要读文件，因IO操作进入阻塞态
        - 3.进程打印输出结果，因打印机未结束而阻塞
        - 4.打印机打印结束，进程重新回归就绪态，并排在尾部
        - 5.进程所需数据已从磁盘进入内存，进程回到就绪态
        - 6.运行的进程因为时间片用完而让出CPU，排到就绪队列尾部

错题总结：
- 程序代码经过多次创建可对应不同进程，而**同一个**系统进程（或线程）可以由系统调用的方法被不同的进程（或线程）多次使用
- 只要就绪队列不为空，CPU就总是可以调度进程运行，保持繁忙。这与就绪进程的数目没有关系，除非就绪队列为空，此时CPU进入等待态，导致CPU的效率下降
- 多线程系统可以做到：
    - 利用线程并行地执行矩阵乘法运算
    - Web服务器利用线程响应HTTP请求
    - 基于GUI的调试程序用不同的线程分别处理用户输入、计算和跟踪等操作
- **匿名管道只能用于具有亲缘关系的进程间通信，命名管道可用于同一主机上的任意进程间通信**。*管道自带同步与互斥，*且为半双工，数据只能向一个方向流动。需要双方通信时，需要建立起两个管道
- 我们把管道一次最多可以缓存的数据量大小叫做PIPESIZE。内核在处理管道数据的时候，底层也要调用类似read和write这样的方法进行数据拷贝，这种内核操作每次可以操作的数据量也是有限的，一般的操作长度为一个page，即默认为4k字节。我们把每次可以操作的数据量长度叫做PIPEBUF。PIPEBUF的作用是，内核在处理管道的时候，*如果每次读写操作的数据长度不大于PIPEBUF时，保证其操作是原子的。*而PIPESIZE的影响是，大于其长度的写操作会被阻塞，直到当前管道中的数据被读取为止
- **用户级线程的切换可以在用户空间完成，内核级线程的切换需要操作系统帮助进行调度，因此用户级线程的切换效率更高**
- 信箱通信是一种间接通信

#### b)进程控制块、进程的状态与转换

PCB：使参与并发执行的每个程序（含数据）能够独立运行的专门的数据结构。系统唯有通过进程的PCB才能感知到进程的存在。一个PCB实例如下：

进程描述信息|进程控制和管理信息|资源分配清单|处理机相关信息
:-:|:-:|:-:|:-:
进程标识符（PID）|进程当前状态|代码段指针|通用寄存器值
用户标识符（UID）|进程优先级|数据段指针|地址寄存器值
|代码运行入口地址|堆栈段指针|控制寄存器值
|程序的外存地址|文件描述符|标志寄存器值
|进入内存时间|键盘|状态字
|处理机占用时间|鼠标
|信号量使用

- 进程控制：进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般把进程控制用的程序段称为原语，原语的特点是执行期间不允许中断，是一个不可分割的基本单位
    - 创建原语：
        - 1）为新进程分配一个唯一的进程标识号，并申请一个空白PCB（PCB是有限的）。**若PCB申请失败，则创建失败**
        - 2）为进程分配其运行所需的资源，如内存、文件、I/O设备和CPU时间等（在PCB中体现）。这些资源或从操作系统获得，或仅从其父进程获得。**如果资源不足，则并不是创建失败，而是处于创建态，等待内存资源**
        - 3）初始化PCB，主要包括初始化标志信息、初始化处理机状态信息和初始化处理机控制信息，以及设置进程的优先级等
        - 4）若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待被调度运行
        - 允许一个进程创建另一个进程，此时的创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源归还给父进程。此外，在撤销父进程时，通常也会同时撤销其所有的子进程
    - 进程的终止：①正常结束；②异常结束；③外界干预
    - 进程的阻塞和唤醒：一个进程从运行态变成阻塞态是主动的行为，而从阻塞态变成就绪态是被动的行为，需要其他相关进程的协助。应当注意，Block原语和Wakeup原语是一对作用刚好相反的原语，必须成对使用

- 进程的状态和转换：
    - 运行态：在单处理机中，每个时刻只有一个进程
    - 就绪态：进程在该队列获得了除处理机外的一切所需资源
    - **阻塞态 / 等待态**：可以根据阻塞原因的不同，设置多个阻塞队列
    - 创建态：进程正在创建
    - 结束态：进程正在消失，可能是进程正常结束或其他原因退出运行。进程首先将进程置为结束态，再进一步处理资源释放和回收等工作
    - 转换：图略

#### c)进程同步的基本概念；实现临界区互斥的基本方法；信号量机制及P、V操作；了解经典同步问题，并通过信号量机制解决进程同步问题

进程同步的基本概念：	
- 为什么要引入同步互斥：因为并发进程是异步的，为了协调进程之间的相互制约关系，所以引入同步互斥
- 进程的异步性：由于系统的资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进
- 并发过程执行产生的两种相互制约关系：
    - 同步：进程 A 应在进程 B 之前执行
    - 互斥：进程 A 和进程 B 不能在同一时刻执行
- 临界资源：一次仅允许一个进程使用的资源；如物理设备(打印机)，共享变量，共享数据，共享缓冲区，公用队列
- 共享资源：可用被多个进程同时使用的资源；如可重入代码/纯代码，共享程序段，磁盘，非共享数据
- 临界区：访问临界资源的那段代码。如果n个进程涉及到了同一个变量A，则A的相关临界区 = 访问临界资源A的那段代码 = n个代码段
- 同步机制遵循的准则：
    - 空闲让进：临界区空闲，允许一个进程进入【运行进程访问空闲的临界资源】
    - 忙则等待：有进程进入临界区时，其他进程需等待【两个进程不能同时进入临界资源】
    - 有限等待：请求访问的进程应保证在有限时间内进入临界区【进程等待进入临界区的时间是有限的】
    - 让权等待：进程不能进入临界区时，应该立即释放处理器，防止进程忙等待【不能进入临界区的执行态进程立即放弃CPU】

实现临界区互斥的基本方法：（不是没有考过哦！）
- 软件实现法：
    - 单标志法（必须交替，违背“空闲让进”）
    - 双标志法先检查（进入区有多段代码，可能会导致错误，违背“忙则等待”）
    - 双标志法后检查（同时设置标志，可能会导致“饥饿”现象）
    - Peterson's Algorithm：先双标志法，再单标志，最后检查（不满足“让权等待”）
- 硬件实现法：低级方法 / 元方法
    - 中断屏蔽方法
    - 硬件指令方法：
        - TestAndSet指令：true表示正被占用
        - Swap指令：交换key和lock的值
- 互斥锁（mutex lock）：
    - 定义：解决临界区最简单的工具
    - 特点：通常采用硬件机制实现；常用于多处理器系统
    - 缺点：忙等待
    - 代码：acquire()获取锁，release()释放锁

管程：一个共享类
- 定义：
    - 管程定义了共享数据结构和各种进程在该数据结构上的全部操作
    - 结构类似于Class，把对共享资源的操作封装起来
    - 管程支持进程互斥；任何时候只有一个进程在管程中执行
    - 管程不仅能实现进程间的互斥，还能实现进程间的同步
- 组成：这类题目如果看到是管程外这个字眼，那就是错误的，**管程的组成都是基于管程内部的**
    1. 管程的名字
    2. 局部于管程内部的共享数据结构或者共享变量说明
    3. 对管程内的数据结构进行操作的一组过程
    4. 对局部于管程内部的共享数据设置初始值的语句
- 管程中设置的条件变量	
    - 定义：阻塞原因定义为条件变量condition
    - 有两种操作：
        - x.wait：**阻塞进程，将其插入到阻塞队列中**
        - x.signal：唤醒进程，将其插入到就绪队列中
    - 与信号量的相似点：
        - wait/signal类似于信号量的P/V操作，实现进程的阻塞/唤醒，但不能说和PV操作相同
    - 与信号量的不同点：
        - 条件变量没有值，仅实现“排队等待”功能
        - 信号量有值，这个值反映了剩余资源数

**信号量机制及P、V操作：**
- 信号量的分类：
    - 整型信号量
        - 该信号量被定义为一个用于表示资源数目的整型量S
        - 该机制不遵循“让权等待”的准则
    - 记录型信号量
        - 是一种不存在“忙等”现象的进程同步机制
        - 需要一个用于代表资源数目的整型变量Value
        - 需要一个进程链表L，用于链接所有等待该资源的进程
        - wait操作 = P操作 = 请求一个资源
        - signal操作 = V操作 = 释放一个资源
- P操作（wait）
    - 将信号量值S减1，表示「申请占用一个资源」
    - **如果 s < 0，表示已经没有可用资源，则执行 P 操作的进程被阻塞**
    - 如果 s ≥ 0，表示现有的资源足够你使用，则执行 P 操作的进程继续执行
    - 举例：当信号量的值为2时，表示有2个资源可以使用；当信号量的值为-2的时候，表示有两个进程正在等待使用这个资源
- V操作（signal）
    - 将信号量值S加1，表示「释放一个资源」，即使用完资源后归还资源
    - **如果s ≤ 0，表示有某些进程正在等待该资源。由于我们已经释放出一个资源了，因此需要唤醒阻塞进程**
    - S = 0表示没有临界资源可供使用，为什么还要唤醒进程？
        - V操作是先执行S + 1，也就是说，把信号量的值加1后才变成了0
        - 在此之前，信号量的值是-1，即有一个进程正在等待这个临界资源，我们需要唤醒它
- 利用信号量实现同步：
    - 信号量表示资源量：
        - 同步信号量初始值不确定，可以设置
        - 信号量最大值 = 最多可以请求的资源数
        - 信号量最小值 = 最大值 / 初始值 - 最大请求值
    - 步骤：
        - step1：定义一个同步信号量，并初始化为当前可用资源的数量
        - step2：**在先执行的操作的「后」面执行 V 操作，释放资源**
        - step3：**在后执行的操作的「前」面执行 P 操作，申请占用资源**
- 利用信号量实现互斥：
    - 信号量表示互斥量：
        - 互斥信号量初始值 = 1，表示临界区只运行一个进程进入，从而实现互斥
        - 互斥信号量 = 0，表示临界区已经有一个进程进入，临界区外还没有进程等待
        - 互斥信号量 < 0，表示临界区中有一个进程
        - 信号量为负数时，其绝对值表示在临界区外等待进入的进程数
    - 步骤：
        - step1：定义一个互斥信号量，并初始化为 1
        - step2：把对于临界资源的访问置于 P 操作和 V 操作之间
        - **P 操作和 V 操作必须成对出现**
        - 缺少 P 操作就不能保证对临界资源的互斥访问
        - 缺少 V 操作就会导致临界资源永远得不到释放、处于等待态的进程永远得不到唤醒

**了解经典同步问题，并通过信号量机制解决进程同步问题：**
- 生产者-消费者问题
```
semaphore mutex = 1; //互斥信号量
semaphore empty = n; //空缓冲区数量
semaphore full = 0; //满缓冲区数量

producer(){
    while(1){
        produce an item in nextp;
        P(empty);
        P(mutex);
        add nextp to buffer;
        V(mutex);
        V(full);
    }
}

consumer(){
    while(1){
        P(full);
        P(mutex);
        remove an item from buffer;
        V(mutex);
        V(empty);
        consume the item;
    }
}
```
- 复杂的生产者问题（爸爸放苹果，女儿吃苹果，妈妈放橘子，儿子吃橘子）
```
semaphore plate = 1, apple = 0, orange = 0; //有一个盘子、零个苹果、零个橘子

dad(){
    while(1){
        prepare an apple;
        P(plate); // 大同步，plate = 1时，既是同步、也是互斥
        put the apple on the plate;
        V(apple); // 小同步
    }
}

daughter(){
    while(1){
        P(apple);
        take the apple from the plate;
        V(plate);
        eat the apple;
    }
}

// mom & son类似。
```

- 读者-写者问题（①允许多个读者可以同时对文件执行读操作；②只允许一个写者往文件中写信息；③任一写者在完成写操作之前不允许其他读者或写者工作；④写者执行写操作前，应让已有的读者和写者全部退出）
```
int count = 0; //读者数量
semaphore mutex = 1; //保护count变量
semaphore rw = 1; //读写者互斥
semaphore w = 1; //用于实现写优先

writer(){
    while(1){
        P(w);
        P(rw);
        writing;
        V(rw);
        V(w);
    }
}

reader(){
    while(1){
        P(w);
        P(mutex);
        if(count == 0) //一有读者，rw就开P
            P(rw);
        conut ++;
        V(mutex);
        V(w);
        reading;
        P(mutex);
        count --;
        if(count == 0) //最后一个读者了，rw可以V
            V(rw);
        V(mutex);
    }
}

//这里的写进程优先是相对而言的，有些书上把这个算法称为读写公平法，即读写进程具有一样的优先级。当一个写进程访问文件时，若先有一些读进程要求访问文件，后有另一个写进程要求访问文件，则当前访问文件的进程结束对文件的写操作时，会是一个读进程而不是一个写进程占用文件（在信号量w的阻塞队列上，因为读进程先来，因此排在阻塞队列队首，而V操作唤醒进程时唤醒的是队首进程），所以说这里的写优先是相对的

//读者-写者问题有一个关键的特征，即有一个互斥访问的计数器count，因此遇到一个不太好解决的同步互斥问题时，要想一想用互斥访问的计数器count能否解决问题

```

- 哲学家进餐问题（五人五筷）
```
semaphore chopsticks[5] = {1, 1, 1, 1, 1};
semaphore mutex = 1; //取左右筷子的这一整个操作需要一个互斥，免得被抢筷子
Pi(){
    do{
        P(mutex);
        P(chopsticks[i]);
        P(chopsticks[(i + 1) % 5]);
        V(mutex);
        eat;
        V(chopsticks[i]);
        V(chopsticks[(i + 1) % 5]);
        think;
    } while(1);
}
```

- 吸烟者问题（供应商无限地、串行地提供材料，每个吸烟者需要不同的材料）
```
int num = 0;
semaphore offer1 = 0, offer2 = 0, offer3 = 0; //定义信号量，表示三种资源
semaphore finish = 0; //定义信号量，表示抽烟是否完成
Provider(){
    while(1){
        num++;
        num = num % 3; // 轮流抽烟，实现互斥
        if(num == 0){
            put the src;
            V(offer1);
        }
        else if (num == 1){
            put the src;
            V(offer2);
        }
        else{
            put the src;
            V(offer3);
        }
        P(finish);
    }
}

Smoker1(){
    while(1){
        P(offer1);
        make a tobacco and smoke;
        V(finish);
    }
}

// Smoker2 & Smoker3类似
```
- 总结：
    - 生产者-消费者问题：互斥+同步问题
    - 一家人吃水果问题：互斥+同步问题，爸爸+女儿这一连续过程和妈妈+儿子这一连续过程互斥
    - 读者-写者问题：互斥+写优先
    - 哲学家进餐问题：互斥
    - 吸烟者问题：互斥，注意：供应商提供资源，吸烟者制作香烟这一连续过程是彼此互斥的

**王道习题：**

一轮标记题：1 3 9 16 18 20 25 26 28 30 38

二轮重做：43 46 49

大题：9 19

1.
- 答：前两问略。管程的引入是为了解决临界区分散所带来的管理和控制问题。在没有管程之前，对临界区的访问分散在各个进程之中，不易发现和纠正分散在用户程序中的不正确使用P、V操作等问题。管程将这些分散在各进程中的临界区集中起来，并加以控制和管理，管程一次只允许一个进程进入管程内，从而既便于系统管理共享资源，又能保证互斥

2.
- 答：互斥；互斥；同步；同步

5.
- 解：解析看不懂
```
semaphore a = m - 1, b = n - 1;
semaphore mutex = 1;

processA(){
    while(1){
        ?
    }
}

```

6.
- 解：
```
int i = 0, j = 0; //号码
semaphore mutex_i = 1, mutex_j = 1; //有变量就有锁
semaphore numSeller = n; //没有用到的变量，因为销售人员不是资源，而是函数

Customer(){
    while(1){
        进入面包店；
        P(mutex_i);
        取号i;
        i++;
        V(mutex_i);
        等待叫号i;
    }
}

Seller(){
    while(1){
        P(mutex_j);
        if(j < i){
            叫号j;
            j++;
            V(mutex_j);
            销售面包；
        }
        else{
            V(mutex_j);
            休息片刻；
        }
    }
}

```

7.
- 解：
```
// 显然是一个生产者-消费者问题
semaphore emptyf1 = 10, emptyf2 = 10;
semaphore fullf1 = 0, fullf2 = 0;
semaphore mutexf1 = mutexf2 = 1;
processA(){
    while(1){
        P(emptyf1);
        P(mutexf1);
        将产品A放到F1上；
        V(mutexf1);
        V(fullf1);
    }
}
processB(){
    // 略
}
processReceiver(){
    while(1){
        P(fullf1);
        P(mutexf1);
        从F1取产品A；
        V(mutexf1);
        V(emptyf1);
        // 略
    }
}
```

8.
- 解：题目都读不懂

9.
- 解：
```
// 这是一个同步题，主要是实现P1、P2、P3的输入数据同步、计算同步
// 先输入b，再算P1
// 先算P2，再算P3
// 先算完x, y, z，再打印
```

10.
- 解：
```
// 1)
semaphore mutex = 1;
NtoS(){
    P(mutex);
    通过桥;
    V(mutex);
}
StoN(){
    // 同上
}

// 2)
// 读者-写者问题
int countSN = countNS = 0;
semaphore mutexSN = 1;
semaphore mutexNS = 1;
semaphore mutex = 1; //大开关
StoN(){
    P(mutexSN);
    if(countSN == 0)
        P(mutex);
    countSN ++;
    V(mutexSN);
    过桥;
    P(mutexSN);
    countSN --;
    if(countSN == 0)
        V(mutex);
    V(mutexSN);
}
NtoS(){
    // 同上
}
```

12 ~ 17.
- 待做

18.
- 解：
// 生产者-消费者问题，通过选择语句实现互斥
```
semaphore empty = N;
semaphore mutex = 1;
semaphore even = odd = 0;
cobegin{
    ProcessP1(){
        while(1){
            x = produce();
            P(empty);
            P(mutex);
            Put();
            V(mutex);
            if(x % 2 == 0)
                V(even);
            else
                V(odd);
        }
    }
    ProcessP2(){
        while(1){
            P(odd);
            P(mutex);
            getodd();
            V(mutex);
            V(empty);
            countodd();
        }
    }
}
    ProcessP3(){
        // 同上
    }
```

19.
- 解：
```
互斥资源：取号机 → mutex
生产者-消费者问题：顾客消费一个椅子，生产一个服务请求，营业员消费一个服务请求，生产一个椅子（隐含题设）
semaphore mutex = 1;
semaphore full = 0, empty = 10;
semaphore service = 0;
cobegin{
    process 顾客 i
    {
        P(empty);
        P(mutex);
        取号;
        V(mutex);
        V(full);
        P(service); // 等待叫号
        获取服务;
    }
    process 营业员
    {
        while(1){
            P(full);
            V(empty);
            V(service); // 叫号
            为客户服务;
        }
    }
}
coend
```

20.
- 解：
```
semaphore empty = 500;
semaphore mutex = 1;
cobegin{
    参观者进程 i{
        P(empty);
        P(mutex);
        进门;
        V(mutex);
        参观;
        P(mutex);
        出门;
        V(mutex);
        V(empty);
    }
}
coend
```

21.
- 解：
```
semaphore full = 0, empty = 1000;
semaphore mutex1 = 1;
semaphore mutex2 = 1;
cobegin{
    void Producer(){
        while(1){
            P(empty);
            P(mutex2);
            produce();
            V(mutex2);
            V(full);
        }
    }
    void Consumer(){
        while(1){
            P(mutex1);
            for(int i = 0; i < 9; i++){
                P(full);
                P(mutex2);
                fetch();
                V(mutex2);
                V(empty);
                consume();
            V(mutex1);
            }
        }
    }
}
coend
```

22.
- 解：
```
semaphore fullA = M - x, emptyA = x, fullB = N - y, emptyB = y;
semaphore mutexA = mutexB = 1;
cobegin{
    void A(){
        while(1){
            P(fullA);
            P(mutexA);
            fetch a mail();
            V(mutexA);
            V(emptyA);
            reply the mail and ask a new question();
            P(emptyB);
            P(mutexB);
            put the mail in mailbox();
            V(mutexB);
            V(fullB);
        }
    }
    void B(){
        // 同上
    }
}
coend
```

错题总结：
- 可重入代码 / 纯代码：一种允许多个进程同时访问的代码；如进程映像中的共享程序段
- PV操作实现的同步的S的初值由用户确定；如果期望的信息还没发送，则对应的初值为0，若信息已存在，则初值为非0的正数；PV操作实现的互斥的S的初值=1
- 判断代码中的语句是否要互斥执行，可以从以下几个方面考虑【见王道书P121第43题】
    - 不同范围的变量不需要互斥（如进程A和进程B都有变量x，这是两个不同范围的变量，不用互斥）
    - 对变量赋值前，都有声明语句的话，不需要互斥（如「int a; a=1; int a; a=2」，a=1和a=2不需要互斥）（说明是局部变量？）
- 在实现临界区互斥时，“让权等待”准则不一定非得实现，如皮特森算法

PV问题做题思路：
- 信号量
    - 如果出现了资源（但注意不要是进程自己），按照资源数设置它们的信号量准没错
    - P：**使用 / 申请 / 等待**
    - V：**返还 / 通知**
- 互斥
    - 多个进程使用同一个变量，要给变量上锁
- 同步
    - 在先执行的操作的「后」面执行 V 操作，释放资源
    - 在后执行的操作的「前」面执行 P 操作，申请占用资源

#### d)进程间通信，包括共享存储系统、消息传递系统、管道

- 进程间通信：进程通信是指进程之间的信息交换。**PV操作是低级通信方式**，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三类：
    - 共享存储：
        - 共享存储又分为两种：低级方式的共享是基于数据结构的共享，高级方式的共享则是基于存储区的共享
        - 对共享空间进行读/写操作时需要使用同步互斥工具
        - 让两个进程共享空间需要通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的
    - 消息传递：
        - 进程间的数据交换以**格式化的消息**（Message）实现
        - 进程通过系统提供的发送消息和接收消息两个原语进行数据交换
        - 通信过程对用户透明，简化了通信程序的设计，是当前应用最广泛的进程间通信机制
        - 微内核操作系统中，微内核与服务器之间的通信就采用了消息传递机制
        - 该机制很好地支持多处理机系统、分布式系统、计算机网络
            - **直接通信方式**：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息
            - **间接通信方式**：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息，这种中间实体一般称为信箱。该通信方式广泛应用于计算机网络中
    - 管道通信：
        - 所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间的通信的一个共享文件，又名pipe文件
        - 以**字符流形式**传输，只支持**半双工通信**
        - 管道机制必须提供三方面的协调能力：互斥、同步、确定对方的存在
        - 管道可以克服使用文件进行通信的两个问题：
            - 管道的大小是受限的
            - 管道满，写阻塞；管道空，读阻塞
        - 管道内部已经实现同步机制，能够保证数据一致性（保证数据的安全性，在写数据的时候不会被别人读，不会发生二义性）

#### e)进程调度的基本准则；典型调度算法：先来先服务调度算法、短作业(短进程、短线程)优先调度算法、时间片轮转调度算法、优先级调度算法

调度的概念：
- 基本概念
  - 调度是处理机进行分配，即从**就绪队列**中按一定算法（公平，高效的原则）选择一个进程并将处理机分配给他运行，以实现进程并发地执行
  - 调度是多道程序OS的基础；调度是OS设计的核心问题
- 高级调度/作业调度
    - 是**内存与辅存的调度**，从后备队列中调度作业
    - 每个作业只调入调出一次
    - 通常存在于多道批处理系统中
    - 内存与磁盘之间交换数据的转态转换：就绪态到挂起态（408不考挂起）
- 中级调度/内存调度
    - 目的是提高内存利用率和系统吞吐量
    - **将暂时不能运行的进程调到外存等待，设为挂起态**，最后修改状态为就绪态，挂在就绪队列上
    - 是存储器管理中的对换功能
- 低级调度/进程调度
    - 从就绪队列中选取一个进程，调用频率很高
    - 各种OS都必须配置这种调度
- 三种调度的联系
    - 作业调度为进程活动做准备，进程调度使进程正常活动
    - 中级调度将暂时不能运行的进程挂起，中级调度处于另外两个调度之间
    - 调用频率：作业调度 < 内存调度 < 进程调度
    - 进程调度是最基本的，不可或缺
- 易错点：
  - 作业是用户提交的，以用户任务为单位
  - 进程是系统自动生成的，以操作系统控制为单位
  - 进程的调度就是把一个进程从就绪态转换为了运行态

**调度的目标：**
- CPU利用率 = CPU有效工作时间 / (CPU有效工作时间 + CPU空闲等待时间)
- 系统吞吐率：单位时间内CPU完成作业的数量
- *周转时间：指从作业提交到完成所经历的时间*
    - 周转时间 = 作业完成时间 - 作业提交时间
    - 平均周转时间 = (作业1的周转时间 + ... + 作业n的周转时间) / n
    - 带权周转时间 = 作业周转时间 / 作业实际运行时间
    - 平均带权周转时间 = (作业1的带权周转时间 + ... + 作业n的带权周转时间) / n
- *等待时间：进程等待时间之和，处理机调度算法的主要影响指标*
- *响应时间 = 系统响应时间 - 作业提交时间，该指标在交互式系统里很重要*
- 调度最终目标要考虑的元素：**特定用户的要求 + 系统整体效率 + 调度算法的开销**

调度的实现：
- 调度器：用于调度和分派CPU的组件
    - 排队器：按策略给就绪进程排出一个或多个队列
    - 分派器：从就绪队列中取出进程，并分配CPU
    - 上下文切换器：在对处理机进行切换时，会发生两对上下文的切换操作（原进程→分派器，分派器→新进程）（这个一般不考）
    - 通常采用两组寄存器，其中一组供内核使用，一组供用户使用
- 调度的时机：
  - 不能进行调度与切换的情况：
        - 在处理中断的过程中
        - 进程在OS内核临界区中
        - 其他需要完全屏蔽中断的原子操作过程中
    - 可以进行调度与切换的情况：
        - 发生引起调度条件且当前进程无法继续进行下去时（非剥夺调度）
        - 中断处理结束或自陷处理结束后，被置上请求调度标志（剥夺方式的调度）
- 调度方式：非抢占调度方式、抢占调度方式

**典型的调度算法：**
- FCFS（先来先服务）调度算法：
    - 既可用于作业调度，也可用于进程调度
    - 属于不可剥夺算法
    - 对长作业比较有利，对短作业比较不利
- SJF（短作业优先）/ SPF （短进程优先）调度算法：
    - 对长作业很不利，甚至可能会导致“饥饿”现象
    - 选择的作业时间是用户估计时间，选择的进程时间是系统估计的运行时间
    - 该算法的平均等待时间和平均周转时间最少
- 优先级调度算法：
    - 适合实时操作系统
    - 既可用于作业调度，也可用于进程调度
    - 可分为非抢占式优先级调度和抢占式优先级调度
    - 根据优先级是否可以改变，可分为静态优先级和动态优先级
    - 优先级设置原则：
        - 系统进程优先于用户进程
        - 交互型进程优先于非交互型进程
        - I/O型进程优先于计算型进程
- 高响应比优先调度算法：FCFS + SJF
    - 主要用于作业调度
    - *响应比Rp = (等待时间 + 要求服务时间) / 要求服务时间*
    - 作业的等待时间相同时，要求服务时间越短，响应比越高，有利于短作业，因而类似于SJF
    - 要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而类似于FCFS
    - 对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，也可获得处理机，克服了“饥饿”现象
- 时间片轮转调度算法：
    - 适合分时系统
  - 若时间片过大，退化为FCFS
  - 若时间片过小，则切换频繁，处理机开销增大
    - 时间片的大小应选择适当，时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力
- 多级队列算法：设置多个就绪队列，不同队列使用不同的调度算法
- 多级反馈队列调度算法：FCFS + 优先级 + 时间片
    - 1. 设置多个就绪队列，并为每个队列赋予不同的优先级（优先级算法）
    - 2. 赋予各个队列的进程运行时间片的大小各不相同（时间片轮转）
    - 3. 每个队列都采用FCFS算法（FCFS）

多级反馈队列调度算法|FCFS|SJF|高响应比|时间片轮转|多级反馈队列
:-:|-|-|-|-|-
可抢占？|**×**|√|√|√|队列内算法不一定
不可抢占？|√|√|√|×|队列内算法不一定
优点|公平且实现简单|平均等待时间最少，效率最高|兼顾长短作业，满足短作业优先且不会发生饥饿现象|兼顾长短作业，为了多个用户能及时干预系统，绝对可抢占的|兼顾长短作业，有较好的响应时间，可行性强
缺点|不利于短作业|长作业会饥饿，估计时间不易确定|计算响应比的开销大|平均等待时间最长，上下文切换浪费时间|无
适用于|无|作业调度，批处理系统|无|分时系统，人机交互系统|相当通用，大家都满意的算法
默认决策模式|非抢占|非抢占|非抢占|抢占|抢占

进程切换的实现：对于通常的进程而言，其创建、撤销及要求由系统设备完成的IO操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的，因此可以说，**任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的**

模式切换与上下文切换的区别：模式切换时，CPU逻辑上可能还在执行同一进程。用户进程最开始都运行在用户态，若进程因中断或异常进入核心态运行，执行完后又回到用户态刚被中断的进程运行。用户态和内核态之间的切换称为模式切换，而不是上下文切换，因为没有改变当前的进程。上下文切换只能发生在内核态，它是多任务操作系统中的一个必需的特性

调度和切换的区别：调度是指决定资源分配给哪个进程的行为，**是一种决策行为**；切换是指实际分配的行为，**是执行行为**。一般来说，先有资源的调度，然后才有进程的切换

**王道习题：**

一轮标记题：1 3 17 22 26 35

二轮重做：3 32(注意调度切换时间要算上) 

大题：1 6 7 8 9 12

1.
- 答：多级反馈队列调度算法能较好地满足各种类型用户的需要。对终端型作业用户而言，由于它们提交的作业大多属于交互型作业，作业通常比较短小，**系统只要能使这些作业在第1级队列所规定的时间片内完成，便可使终端型作业用户感到满意**；对于短批处理作业用户而言，它们的作业开始时像终端型作业一样，若仅在第1级队列中执行一个时间片即可完成，便可获得与终端型作业一样的响应时间，对于稍长的作业，**通常也只需要在第2级队列和第3级队列中各执行一个时间片即可完成，其周转时间仍然较短**；对于长批处理作业用户而言，它们的长作业将依次在第1,2,...,n级队列中运行，然后按时间片轮转方式运行，**用户不必担心其作业长期得不到处理**

2.
- 答：略

3 ~ 6、10.
- 解：画好甘特图就不难

7.（注意，是优先数越小，优先级越高！）
- 答：具有两道作业的批处理系统，内存只存放两道作业，它们采用抢占式优先级调度算法竞争CPU，而将作业调入内存采用的是短作业优先调度。8:00，作业1到来，此时内存和处理机空闲，作业1进入内存并占用处理机；8:20，作业2到来，内存仍有一个位置空闲，因此将作业2调入内存，又由于作业2的优先数高，相应的进程抢占处理机，在此期间8:30作业3到来，**但内存此时已无空闲，因此等待**。直至8:50，作业2执行完毕，此时作业3、4竞争空出的一道内存空间，作业4的运行时间短，因此先调入，但它的优先数低于作业1，因此作业1先执行。到9:10时，作业1执行完毕，再将作业3调入内存，且由于作业3的优先数高而占用CPU

8.
- 解：
    - 可抢占式SJF：P1 - P2 - P4 - P1 - P3，平均周转时间为13
    - 时间片轮转算法按就绪队列的FCFS进行轮转，**在时刻2，P被挂到就绪队列队尾，队列顺序为P2, P3, P1，此时P4还未到达**

9.
- 答：
    1. 6%
    2. (1次调度 + 1次切换) / 一个时间片，答案为1.5%。注意题设问的是切换消耗，所以分子不需要加中断的消耗
    3. 为提高CPU的效率，一般情况下要尽量减少时钟中断的次数，如由每秒120次降低到100次，以延长中断的时间间隔。或将每个时间片的中断数量（时钟数）加大，如由24个中断加大到36个。也可优化中断处理程序，减少中断处理开销，如将每次500μs的时间降低到400μs。若能这样，则时钟中断和进程切换的总开销占CPU的时间比为(36×400μs + 1ms + 2ms) / (1/100 × 36) ≈ 4.8%

11.
- 解：
    1. J1: 10:00 ~ 10:35; J4: 10:35 ~ 10:55; J2:10:55 ~ 11:25; J5: 11:25 ~ 11:55; J3:11:55 ~ 12:40
    2. 75min

12.
- 解：
    1. nice值较大的进程可能会始终无法得到调度，产生“饥饿”现象
    2. nice + (1 + cpuTime) / (1 + waitTime); 处于就绪态时，waitTime定时加1，该值会逐渐减小
- 答：
    2. nice + k1 * cpuTime - k2 * waitTime

错题总结：
- 该类题型的做法，依旧是画甘特图较为行之有效
- 时间片轮转增加了系统开销，所以不会使得系统高效运行
- 所谓CPU繁忙型，是指该类作业需要大量的CPU时间进行计算，其定义更接近于长作业。FCFS有利于CPU繁忙型的作业，而不利于IO繁忙型的作业
- UNIX属于分时操作系统
- 中断向量本身是用于存放中断服务例行程序的入口地址，而中断向量的地址应是该入口地址的地址（也就是地址从0开始的一系列中断向量）
- 抢占式的短作业优先算法 = “**最短剩余时间**优先算法”（SRTN）
- 注意时间片轮转算法的就绪队列在最开始时的轮转调度，极易出错！

#### f)死锁的形成原因与必要条件；死锁预防、死锁避免、死锁检测和解除

死锁的形成原因与必要条件:
- 为什么会出现死锁？
  1. 系统资源的竞争【空间上】	
        - 系统中不可剥夺资源不足以满足多个进程
    - 只有对不可剥夺资源（如磁带机，打印机）的竞争才可能产生死锁
  2. 进程推进顺序非法【时间上】	
        - 进程运行时，请求和释放资源的顺序不当
    - 系统对独占资源分配不当
    3. 系统资源不足不是系统产生死锁的原因，资源不足只会对进程造成“饥饿”
- 产生死锁的必要条件
  - 互斥条件：多个线程不能同时使用同一个资源
  - 不剥夺条件：进程A已经拥有资源1，在自己使用完之前不能被其他进程获取
  - 请求并保持条件：进程A已经有资源1，想申请资源2，但是资源2被进程B持有，进程A处于等待状态，但是进程A不释放资源1
  - 循环等待条件：两个线程获取资源的顺序构成了环形链（注意，有环形链不代表就是死锁！）

**死锁预防、死锁避免、死锁检测和解除：**
- 死锁预防

名称|特点|举例
:-:|-|-    
破坏互斥条件|缺点：如打印机等临界资源只能互斥使用|该方法不太可行
破坏不剥夺条件|常用于状态易于保存和恢复的资源（CPU的寄存器和内存资源）|**剥夺资源法**
破坏请求并保持条件|可能会导致饥饿现象|**一次性分配策略、静态分配策略**
破坏循环等待条件|可采用顺序资源分配法，但是编号必须相对稳定，限制了新类型设备的增加|**资源有序分配策略**

- 死锁避免	
    - 系统安全状态：死锁包含在不安全状态之中（系统处于安全状态时，一定无死锁；系统处于不安全状态时，不一定出现死锁）
    - 银行家算法
    0. Column: Available(Work) Max(Only used in step 1) Allocation Need
    1. Need = Max - Allocation（先算Need）
    2. Request ≤ Need & Request ≤ Available?（第一次检测）
    3. Try: Available -= Request, Allocation += Request, Need -= Request（该减减，该加加）
    4. Safety test: Work = Available, while(Work ≥ Need) {Work += Allocation}（第二次检测）
    - 具体到画表，推荐画三列：Allocation、Need、Available(Work)
    - **死锁避免时不会限制用户申请资源的顺序**；需要进程运行所需资源总量信息；不会给可能导致死锁的进程分配资源
- 死锁的检测
    1. 资源分配图：资源分配图是一个有向图，用于表示某时刻系统资源与进程之间的状态。**圆圈代表进程，框代表一类资源；从进程到资源的边叫做请求边；从资源到进程的边叫做分配边**
    2. 死锁定理：S为死锁的条件是当且仅当S状态的资源分配图是不可完全简化的
- 死锁的解除
    1. 资源剥夺法：挂起某些死锁进程，并抢占它的资源
    2. 撤销进程法：强制撤销部分甚至全部死锁进程并剥夺这些进程的资源
    3. 进程回退法：让一个或多个进程回退到足以回避死锁的地步
- 各个策略的比较：

名称|资源分配策略|各种可能模式|主要优点|主要缺点
-|-|-|-|-
死锁预防|保守，宁可资源闲置|一次请求所有资源，资源剥夺，资源按序分配|适用于突发式处理的进程，不必进行剥夺|效率低，进程初始化时间延长；剃夺次数过多；不便灵活申请新资源
死锁避免|是“预防”和“检测”的折中（在运行时判断是否可能死锁）|寻找可能的安全允许顺序|不必进行剥夺|必须知道将来的资源需求；进程不能被长时间阻塞
死锁检测|宽松，只要允许就分配资源|定期检查死锁是否己经发生|不延长进程初始化时间，允许对死锁进行现场处理|通过剥夺解除死锁，造成损失

**王道习题：**

二轮重做：18 21 22

大题：（死锁是没考过大题的）

1.
- 答：2 > 1 > 3

2.
- 答：系统会死锁。因为对两个账户进行加锁操作是可以分割进行的，若此时有两个用户同时进行转账，P先对账户A进行加锁，再申请账户B；P先对账户B进行加锁，再申谓账户A，此时产生死锁。解决的办法是：可以采用资源顺序分配法对A、B账户进行编号，用户转账时只能按照编号由小到大进行加锁；也可采用资源预分配法，要求用户在使用资源前将所有资源一次性申请到

3.
- 答：略

4.
- 解：不发生死锁要求，**必须保证至少有一个进程能得到所需的全部资源并执行完毕，m ≥ n * (k 1. + 1时，一定不会发生死锁**

5.
- 解：略

6.
- 解：
    1. 安全，例如P2, P3, P4, P1
    2. P2, P3, P4, P1
    3. **若2)中的两个请求立即得到满足，则此刻系统并未立即进入死锁状态，因为这时所有的进程未提出新的资源申请，全部进程均未因资源请求没有得到满足而进入阻塞态。只有当进程提出资源申请且全部进程都进入阻塞态时，系统才处于死锁状态**

7 ~ 8.
- 解：略

9.（加入改错本）
- 解：见改错本

错题总结：
- 王道的21题较难，被称作“单行线问题”，说是单行线，其实是在说“两个方向都能通行，但一边要等另一边的车通行完的单行线”

#### 本章小结

- 死锁与饥饿：
    - 一组进程处于死锁状态是指组内的每个进程都在等待一个事件，而该事件只可能由组内的另个进程产生。这里所关心的主要是事件是资源的获取和释放
    - 与死锁相关的另一个问题是**无限期阻塞（Indefinite Blocking）或饥饿（Starvation）**，即进程在信号量内无穷等待的情况
    - 产生饥饿的主要原因是：在一个动态系统中，对于每类系统资源，操作系统需要确定一个分配策略，当多个进程同时申请某类资源时，由分配策略确定资源分配给进程的次序。有时**资源分配策略可能是不公平的**，即不能保证等待时间上界的存在。在这种情况下，即使系统没有发生死锁，某些进程也可能会长时间等待。当等待时间给进程推进和响应带来明显影响时，称发生了进程“饥饿”，当“饥饿”到一定程度的进程所赋予的任务即使完成也不再具有实际意义时，称该进程被“饿死”
    - “饥饿”并不表示系统一定会死锁，但至少有一个进程的执行被无限期推迟。“饥饿”与死锁的主要差别如下:
        1. 进入“饥饿”状态的进程可以只有一个，而因循环等待条件而进入死锁状态的进程却必须大于等于两个
        2. **处于“饥饿”状态的进程可以是一个就绪进程，如静态优先权调度算法时的低优先权进程，而处于死锁状态的进程则必定是阻塞进程**

### <a name="13">（三）内存管理</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

基本概述：
内存管理是操作系统对内存的划分和动态分配。

内存管理的目的：
1. 为了更好地支持多道程序并发执行
2. 方便用户
3. 提高内存利用率

内存管理的功能：
1. 内存空间的分配与回收：由OS完成主存储器空间的分配和管理
2. 地址转换：存储管理将逻辑地址转换为物理地址
3. 内存空间的扩充：利用虚拟存储技术/自动覆盖技术，从逻辑上扩充内存
4. 内存共享：允许多个进程访问内存的同一部分
5. 存储保护：保证多道作业在各自的存储空间运行，互不干扰

内存管理的分配：
1. 连续分配：单一连续分配--「**单道发展到多道OS**」-->固定分区分配--「**为了适应大小不同的程序**」-->动态分区分配
2. 不连续分配：分段存储管理--->分页存储管理--->段页存储管理

#### a)程序装入与链接；逻辑地址与物理地址空间；重定位；内存保护。

程序装入与链接：
1. 编译：由编译程序将用户源代码编译成若干目标模块
2. 链接：由链接程序将目标模块和库函数链接，形成完整的装入模块
    - 链接类别：静态链接、装入时动态链接、运行时动态链接（**只有最后一种是运行时才去链接所需模块**）
3. 装入：是**由装入程序**将装入模块装入内存运行
    - 静态装入：只适用于单道程序环境。在编译时把物理地址计算好
    - 可重定位装入（静态重定位）：装入时把逻辑地址转换为物理地址，但装入后不能改变
    - 动态运行时装入（**动态重定位**）：
        - 装入程序把装入模块装入内存后，**并不立即把装入模块中的逻辑地址转换为物理地址**，而是把这种地址转换推迟到程序真正要执行时才进行
        - 这样可以将程序分配到不连续的存储区；在程序运行之前**可以只装入部分代码即可投入运行**，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享
        - 需要**重定位寄存器**的支持

逻辑地址与物理地址空间：

区别|逻辑地址|物理地址
-|-|-
定义|每个目标模块都从0号单元开始编址的地址|物理地址空间是指内存中物理单元的集合
特点|1.不同进程可以有系统的逻辑地址，这些逻辑地址可以映射到主存的不同位置；2.进程运行时，看到和使用的地址都是逻辑地址；3.将逻辑地址转换为物理地址的过程叫做地址重定位，该过程通过MMU实现|物理地址是地址转换的最终地址

- 形成逻辑地址的阶段：链接
- 形成物理地址的阶段：装入或程序运行时

重定位：
1. 动态重定位是在作业的**执行**过程中进行的
2. 静态重定位是在装入的时候进行的
3. 固定分区分配可以采用静态重定位（装入后位置不再改变）
4. 在**整个系统**设置一个重定位寄存器，**用来存放程序在内存中的始址**


内存保护：
- 目的：确保每个进程都有一个单独的内存空间
- 有两种方法：
1. 在CPU中设置一对上下限存储器，判断CPU访问的地址是否越界
2. 使用重定位寄存器和界地址寄存器（只有OS内存才可以使用这两个寄存器）
  - 重定位寄存器（也叫**基地址寄存器**）含最小的物理地址值【用于“加”】
  - **界地址寄存器**含逻辑机制的最大值【用于“比”】
  - 逻辑地址 + 基地址寄存器的值 --映射-→ 物理地址
    - 加载重定位寄存器和界地址寄存器时**必须使用特权指令**，只有操作系统内核才可以加载这两个存储器
- 内存保护需要由OS和硬件机构合作完成，以保证进程空间不被非法访问

内存共享：
- 概念：
    - 只有只读区域的进程空间可用共享
    - 纯代码/可重入代码 = 不能修改的代码，不属于临界资源
    - 可重入程序通过减少交换数量来改善系统性能
- 实现方式
    1. 段的共享
    2. 基于共享内存的进程通信（第二章的同步互斥）
    3. 内存映射文件

#### b)分区管理；交换与覆盖技术。

分区管理：
- 定义：连续分配管理是为一个用户程序分配一个连续的内存空间
- 特点
    - 用户程序在主存中都是连续存放的
    - 非连续分配的方式的存储密度 < 连续分配方式
- 碎片
    - 内部碎片：当程序小于固定分区大小时，也要占用一个完整的内存分区，导致分区内部存在空间浪费
    - 外部碎片：内存中产生的小内存块
- 分类

静态分区管理|1.单一连续分配|2.固定分区分配
-|-|-
定义|在此方法下，内存分为两个区：系统区：供OS用，在低地址区；用户区：内存用户空间由一道程序独占|用户内存空间划分为固定大小（分区大小相等或不等）的区域；每个区装一道作业
优点|简单，无外部碎片；无需进行内存保护（内存中永远只有一道程序）|简单
缺点|只能用于单用户单任务的OS；有内部碎片，存储器利用率极低|程序太大可能放不下任何一个分区，有内部碎片；不能实现多进程共享一个主存区，存储空间利用率低

3. 动态分区分配：进程转入内存时，根据进程的实际需要，动态地分配内存；动态分区是在作业装入时动态建立的；会产生**外部碎片**，克服外部碎片需要**紧凑**技术，这需要动态重定位寄存器的支持

动态分配算法|**空闲分区按什么次序链接的**|特点
-|-|-
a.首次适应算法|按地址递增的次序|最简单，效果最好，速度最快
b.邻近适应算法（循环首次适应算法）||比首次适应算法差
c.最佳适应算法|按容量递增的次序|**性能很差**，会产生最多的外部碎片
d.最坏适应算法|按容量递减的次序|可能导致没有可用的大内存块，性能差

交换与覆盖技术：
- 覆盖：
    - 基本思想：由于程序运行时并非任何时候都要访问程序及数据的各个部分，因此可把用户空间分成一个固定区和若干覆盖区。将经常活跃的部分放在固定区，将那些**即将要访问的段**放入覆盖区
    - 特点：打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，此外，内存中能够更新的地方只有覆盖区的段，不在覆盖区中的段会常驻内存。覆盖技术对用户和程序员**不透明**
    - 单一连续存储管理可采用覆盖技术
- 交换（对换）：
    - 基本思想：把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序**从内存移到辅存**，把内存空间腾出来，这一过程又称**换出**；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称**换入**。第2章介绍的中级调度采用的就是交换技术
    - 交换通常在有许多进程运行且内存空间吃紧时开始启动，而在系统负荷降低时就暂停
    - 使用交换技术时，一个进程正在I/O操作，则不能交换出主存；开辟一个缓冲I/O区后，可以交换出主存
- 覆盖和交换的提出是为了解决主存空间不足的问题，不是从物理上解决，而是将暂时不用的部分换出主存以节省空间，从而在逻辑上扩充主存

#### c)分页管理方式；分段管理方式；段页式管理方式。

**分页管理方式：**
- 基本概念：
    - 页/页面：进程中的块
        - 页面大--->页内碎片增多，降低内存的利用率
        - 页面小--->进程的页面数大，页表过长，占用大量内存，增加物理地址转换的开销，降低页面换入/出的效率
    - 页框/页帧：内存中的块
    - 块/盘块：外存中的块
    - 页表：由页表项组成
- 逻辑地址：假设每页为4KB，则：**31--页号P--12-11--页内偏移量W--0**
- 页表项：假设逻辑空间为32位，字节编址，则共需要2^32B / 4KB = 1M页帧，那么：**页表始址+页号×页表项长度（隐含）→ 19--页帧号b--0**
- 📈图解 ![img](https://api2.mubu.com/v3/document_image/325c5532-e1e8-4d99-b9cc-81b4e5b954ac-329792.jpg)
- 物理地址：设页面大小为L，逻辑地址为A
    1. 计算页号计算页号P (P = A / L）和页内偏移量W（W = A % L)
    2. 比较页号Р和页表长度M，若P ≥ M，则产生越界中断，否则继续执行
    3. 页表中页号Р对应的页表项地址 = 页表始址F + 页号P × 页表项长度，取出该页表项内容b，即为页帧号。注意区分页表长度和页表项长度。页表长度是指一共有多少页，页表项长度是指页地址占多大的存储空间
    4. 计算物理地址E = b × L + W，用得到的物理地址E去访问内存
- 📈图解 ![img](https://api2.mubu.com/v3/document_image/c134e860-8e0e-4522-9e42-c29d2b7a02a4-329792.jpg)
- 快表（相联存储器）：这个时候的页表项：**39--页号--20-19--页帧号b--0**
- 两级页表/多级页表：顶级页表最多只能有1个页面
- 特点
    - 所有进程都有一张页表
    - 分页是面向计算机的
    - 系统设置一个页表寄存器PTR用于存放**页表在内存中起始地址和长度**
    - 无论采用什么页面置换算法，每种页面第一次访问时不可能在内存中，必然发生缺页，所以缺页次数 ≥ 不同的页号数量

**分段管理方式：**
- 逻辑地址：**段号S + 段内偏移量W**
    - 在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显式提供，在高级程序设计语言中，这个工作由编译程序完成
- 段表项：段表项地址（隐含）+ 段长 + 始址 
- 物理地址（**访问了两次内存**）：
    1. 从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。注意，在地址变换的题目中，要注意逻辑地址是用二进制数还是用十进制数给出的
    2. 比较段号S和段表长度M，若S ≥ M，则产生越界中断，否则继续执行
    3. 段表中段号S对应的段表项地址 = 段表始址F + 段号S × 段表项长度，取出该段表项的前几位得到段长C。若段内偏移量 ≥ C，则产生越界中断，否则继续执行
    4. 取出段表项中该段的始址b，计算E = b + W，用得到的物理地址E去访问内存。
- 优点
    - 能产生连续的内存空间
    - 分段存储管理能反映程序的逻辑结构并有利于段的共享和保护
    - 程序的动态链接与逻辑结构有关，分段存储管理有利于程序的动态链接
- 缺点
    - 会产生**外部碎片**
    - 内存交换的效率低
- 特点
    - 方便编程、分段共享
    - 分段管理地址空间是二维的（段号和段内偏移要用户显式给出）
    - 每段的长短不同
    - 系统设置一个段表寄存器STR用于存放**段表在内存中起始地址和长度**

**段页式管理方式：**
- 实现方法
    1. 将程序划分为多个有逻辑意义的段【分段】
  2. 对分段划分出来的连续空间，再划分固定大小的页【分页】
- 逻辑地址：**段号S + 段内页号P + 页内偏移量W**
  - 对内存的管理以存储块为单位，地址空间是二维的
- 物理地址（**访问了三次内存**）：
    1. 访问段表（**页表长度 + 页表起始地址，相当于PTR**），得到**页表起始地址**
  2. 访问页表，得到物理页号
  3. 将物理页号与页内偏移组合，得到物理地址
- 特点
    - 系统依旧要设置一个段表寄存器STR用于存放**段表在内存中起始地址和长度**
    - 同样可以使用快表，此时tag由段号、页号组成，value则是页帧号和保护码

**王道习题：**

一轮标记题：2 8 10 12 14 18 19 21 25 27 30 31 33 34 41 47 48 49 51 54

二轮重做：2 10 18 30 41 47 49

大题：

1.
- 答：动态分区和固定分区分配方式相比，内存空间的利用率要高一些。但是，总会存在一些分散的较小空闲分区，即外部碎片，它们存在于已分配的分区之间，不能充分利用。可以采用拼接技术加以解决。固定分区分配方式存在内部碎片，而无外部碎片；动态分区分配方式存在外部碎片，无内部碎片

2.
- 首次适应算法显然不满足，最佳适应算法满足

3 ~ 12.
- 不做了

错题总结：
- 对于交换技术，要明确其对象是**主存与辅存**，因此：在使用交换技术时，若一个进程正在I/O操作，则不能交换出主存，否则其I/O数据区将被新换入的进程占用，导致错误。不过可以在操作系统中开辟I/O缓冲区，将数据从外设输入或将数据输出到外设的I/O活动在系统缓冲区中进行，这时系统缓冲区与外设I/O时，进程交换不受限制
- 动态重定位是在作业的**执行**中进行的
- 页表和段表同样存储在内存中，**系统提供给用户的物理地址空间为总空间大小减去页表或段表的长度**。由于页表和段表的长度不能确定，所以提供给用户的物理地址空间大小也不能确定
- 页式管理中很重要的一个问题是页面大小如何确定。确定页面大小有很多因素，如**进程的平均大小、页表占用的长度**等。而一旦确定，**所有的页面就是等长的**，以便易于系统管理
- 存储管理的目的是**方便用户**和**提高内存利用率**
- 在多个进程并发执行时，所有进程的页表大多数驻留在内存中，在系统中只设置一个页表寄存器(PTR)，它存放页表在内存中的始址和长度。平时，**进程未执行时，页表的始址和页表长度存放在本进程的PCB中**，当调度到某进程时，才将这两个数据装入页表寄存器中。每个进程都有一个单独的逻辑地址，有一张属于自己的页表
- 段内位移的最大值就是最大段长

#### d)虚拟内存基本概念和局部性原理；缺页中断；地址变换过程。

虚拟内存基本概念和局部性原理：
- 传统存储管理方式的特征
    - 一次性：作业必须一次性全部装入内存，才能开始运行
    - 驻留性： 
      - 作业被装入内存后，就一直驻留在内存中，直到作业结束
      - 运行中的进程会因等待I/O而被阻塞，可能处于长期等待状态
- 局部性原理
    - 时间局部性：程序中的某条指令一旦执行，不久后该指令可能再次运行；出现的原因是**程序中存在着大量的循环结构**
    - 空间局部性：程序在一段时间内所访问的地址，可能集中在一定的范围内
- 虚拟存储器
    - 定义：系统为用户提供的一个比实际内存容量大得多的存储器
    - 特征：
        - 多次性 = 即只需将当前运行的那部分程序和数据装入内存即可开始运行【最重要的特征】
      - 对换性 = 即作业无需一直常驻内存，要用时换入，不要用时换出
      - 虚拟性 = 从逻辑上扩充内存的容量【最重要的目标】
- 虚拟内存的实现
    - 方式(离散分配)
        1. 请求分页存储管理
        2. 请求分段存储管理
      3. 请求段页式存储管理
    - 需要的东西：
        - 一定的硬件支持，一定容量的内存和外存
        - *页表/段表机制*作为主要的数据结构
        - **中断机制，当程序要访问的部分还未调入内存时，产生中断**
        - *地址变换机构*

请求分页管理方式：
- 特点
    - 只要求将当前一部分页面装入内存，便可启动作业运行，不需要一次全部装入
    - 在作业执行的过程中，当访问的页面不存在时，再通过调页功能将其调入
- 相比基本分页管理增加的功能
    - 请求调页功能：将要用的页面调入内存【调入】
    - 页面置换功能：将不用的页面换出到外存【调出】
- 页表项的构成：**页号 + 页帧号 + 状态位P + 访问字段A + 修改位M + 外存地址L**
    - 状态位/合法位P：标记该页是否已被调入内存中 → 供程序访问时参考，用于判断是否触发缺页异常
    - 访问字段A：记录本页在一段时间内被访问的次数 → 供置换算法换出页面时参考
    - 修改位M：标识该页在调入内存后是否被修改过 → 当页面被淘汰时，若页面数据没有修改，则不用写回外存
    - 外存地址L：用于指出该页在外存上的地址，通常是物理块号 → 供写回外存和从外存中调入此页时参考
    - 对比：Cache行的构成 = *状态位* + 主存块地址tag + 数据块副本 + *脏位/修改位* + *置换标记位/访问字段*，三处相同，页表项的页号 + 页帧号与Cache的tag等效
- **缺页中断**
    - 定义：缺页是在CPU执行某条指令过程中，进行取指令或读写数据时发生的一种故障，是内中断或者叫做异常
    - 产生时间
        - 每当要访问的页面不在内存中时，便产生一个缺页中断，请求OS将所缺的页调入内存
        - 缺页中断是**访存指令**引起的，说明所要访问的页面不在内存中
        - 进行缺页中断处理并调入所要访问的页后，**访存指令应该重新执行**
    - 特点	
        - **在指令执行期间而非一条指令执行完后产生和处理中断信号**
        - 一条指令在执行期间，可能产生*多次缺页中断*
        - 请求分页存储器中，页面尺寸增大，存放程序需要的页帧数减少，缺页中断次数也会减少
        - 影响缺页中断的因素有：缺页率，磁盘读写时间，内存访问时间
        - 缺页处理过程中可能执行的操作：*修改页表项，分配页框/置换页面，磁盘I/O*（内存没有页面，需要从外存读入）
- 地址变换机构新增功能
    1. 产生和处理中断信号
    2. 从内存中换出一页
- 请求分页系统外存组成	
    - 存放文件的文件区【采用离散分配方式】
    - 存放对换页面的对换区【采用连续分配方式】
    - 📢对换区的磁盘I/O速度更快

#### e)页面置换算法：最佳置换算法(OPT)、先进先出置换算法(FIFO)、最近最少使用置换算法(LRU)、时钟置换算法(CLOCK)；工作集模型。

**页面置换算法（即选择调出页面的算法）：**

页面置换算法|最佳置换算法OPT|先进先出置换算法FIFO|最近最久未使用置换算法LRU|时钟置换算法CLOCK
-|-|-|-|-
被淘汰的页面|以后永不使用的|在内存中驻留时间最久的页面|最近最长时间未访问过的页面|最近未使用的页面
特点|◎ 基于队列实现的；◎ **该算法无法实现**；◎ 只能用于评价其他算法|◎ 会出现*Belady异常*（分配的物理块数增大但页故障数不减反增）；◎ 性能差，但实现简单|◎ 性能好，但实现复杂；◎ 需要寄存器和栈道硬件支持；◎ 堆栈类算法；◎ 耗费高因为要对所有页排序|◎ FIFO和LRU的结合

CLOCK算法的淘汰顺序：访问位为A，修改位为M
- 1类A = 0, M = 0: 最近未被访问且未被修改，**是最佳淘汰页**
- 2类A = 0, M = 1: 最近未被访问，但已被修改，不是很好的淘汰页（也就是说，**访问比修改的优先级要高**！符合逻辑）
- 3类A = 1, M = 0: 最近已被访问，但未被修改，可能再被访问
- 4类A = 1, M = 1: 最近已被访问且已被修改，可能再被访问

抖动/颠簸：
- 定义
    - 在页面置换时，出现频繁的页面调度行为
  - 所有页面置换策略都有可能造成抖动
- 产生原因	
    - 系统中同时运行的进程太多—>分配给每个进程的物理块太少—>进程在运行时频繁出现缺页—>频繁的调动页面
  - 主要原因是因为页面置换算法不合理
- 解决方法
    - 撤销部分进程
  - 增加磁盘交换区大小和提高用户进程优先级都与抖动**无关**

工作集模型：
- 定义：在某段时间间隔内，进程要访问的页面集合
- 如何确定工作集：基于局部性原理，用最近访问过的页面来确认
- 有什么作用
    - 工作集反映了进程在接下来一段时间内很可能频繁访问的页面集合
    - 为了防止抖动现象，要使分配给进程的物理块数（驻留集大小） > 工作集大小

**王道习题：**

一轮标记题：1 2 10 13 23 26 29 33 43

二轮重做：29 35 39 43

大题：

1.
- 答：
    1. 覆盖技术与虚拟存储技术最本质的不同在于，覆盖程序段的最大长度要受内存容量大小的限制，而虚拟存储器中程序的最大长度不受内存容量的限制，只受计算机地址结构的限制。另外，覆盖技术中的覆盖段由程序员设计，且要求覆盖段中的各个覆盖具有相对独立性，不存在直接联系或相互交叉访问；而虚拟存储技术对用户的程序段没有这种要求。
    2. 交换技术就是把暂时不用的某个程序及数据从内存移到外存中，以便腾出必要的内存空间，或把指定的程序或数据从外存读到内存中的一种内存扩充技术。交换技术与虚存中使用的调入/调出技术的主要相同点是，都要在内存与外存之间交换信息。交换技术与虚存中使用的调入/调出技术的主要区别是：交换技术调入/调出**整个进程**，因此一个进程的大小要受内存容量大小的限制；而虚存中使用的调入/调出技术在内存和外存之间来回传递的是**页面或分段**，而不是整个进程，从而使得进程的地址映射具有更大的灵活性，且允许进程的大小比可用的内存空间大

2.
- 答：每页32B，即页内偏移地址为5位
    - 101：转换为二进制：001 000 001，则页号为2，物理地址为f3,1
    - 204：转换为二进制：010 000 100，则页号为4，不在TLB里，查内存页表得到物理地址为f5,4
    - 576：缺页中断

3 ~ 14.
- 不做了

15 ~ 21.
- 待做

错题总结：
- 内存抖动是指频繁地引起主存页面淘汰后又立即调入，调入后又很快淘汰的现象。这是**由页面置换算法不合理引起**的一种现象，是页面置换算法应当尽量避免的
- 当系统处于频繁的（缺页导致的）换入换出过程时，说明内存不够用了，我们可以：
    - 增大内存
    - 减少多道程序的度数
    - 但注意：增大磁盘对换区容量，提高磁盘对换速度或者CPU速率，这些都于事无补！
- 在任一时刻t，都存在一个集合，**它包含所有最近k次内存访问所访问过的页面**。这个集合w(k, t)就是工作集
- 系统调用是由用户进程发起的，请求操作系统的服务。例如：创建新进程可以通过系统调用来完成，如Linux中通过fork系统调用来创建子进程。以下行为则不属于系统调用：当内存中的空闲页框不够时，操作系统会将某些页面调出，并将要访问的页面调入，这个过程完全由操作系统完成，不涉及系统调用；进程调度完全由操作系统完成，无法通过系统调用完成；生成随机数只需要普通的函数调用，不涉及请求操作系统的服务

#### f)其他

进程的内存映像：
操作系统内核段（**高地址**）
↓
用户栈（运行时创建）
↓
↑
共享库的存储映射区
↑
动态生成的堆（运行时由malloc创建）
读/写数据段（.data、.bss）
只读代码段（.init、.text、.rodata）
未使用区（**低地址**）

其中：
- 共享库用来存放进程用到的共享函数库代码，如printf()函数等
- 在读/写数据段中，.data是已初始化的全局变量和静态变量；.bss是未初始化及所有初始化为0的全局变量和静态变量
- 在只读代码段中，.init是程序初始化时调用的_init函数；.text是用户程序的机器代码；.rodata是只读数据

页框分配（进程准备执行时，由OS决定给特定进程分配几个页框）：
- 驻留集 = 给一个进程分配的物理页框（也叫做物理块）的集合
- 驻留集的大小
    1. 分配给进程的页框越少，驻留在内存的进程就越多，CPU的利用率就越高
    2. 进程在主存中的页面过少，缺页率相对较高
    3. 分配的页框过多，对进程的缺页率没有大的影响
- 分配策略
    - 固定分配局部置换：物理块固定，缺页时先换出一个线程再调入所缺页
    - 可变分配全局置换：物理块可变，缺页时增加物理块再调入所缺页
    - 可变分配局部置换：物理块可变，若不频繁缺页则用局部置换，频繁缺页再用全局置换
    - 📢对各进程进行固定分配时页面数不变，不可能出现全局置换
- 物理块调入算法
    1. 平均分配算法
    2. 按比例分配算法
    3. 优先权分配算法
- 调入页面的时机
- 预调页策略 = 运行前的调入，主要用于进程的首次调入，由程序员指出应先调入哪些页
- 请求调页策略 = 运行时的调入
    - 调入的页一定会被访问，策略易于实现
    - 每次仅调入一页，增加了磁盘I/O开销
- 从何处调入页面
    1. 系统拥有足够的对换区空间
    2. 系统缺少足够的对换区空间
    3. UNIX方式
- 如何调入页面	
    - 情况1：所访问的页面不在内存时--->缺页中断--->无空闲物理块--->决定淘汰页--->调出页面--->调入所缺页面
    - 情况2：所访问的页面不在内存时--->缺页中断--->有空闲物理块--->调入所缺页面

内存映射文件：
- 定义：与虚拟内存有些相似，将**磁盘文件的全部或部分内容**与进程虚拟地址空间的某区域建立映射关系
- 作用：**可以直接访问**被映射的文件，而不必执行文件I/O操作，也无需对文件内容进行缓存处理 
- 优点：适合用来管理大尺寸文件

虚拟存储器性能影响因素：
1. 页面较大—>缺页率较低—>可以减少页表长度，但使得页内碎片增大
2. 页面较小—>缺页率较高
  - —>可以减少内存碎片，提高内存利用率
  - —>使得页表过长，占用大量内存
3. 分配给进程的物理块数越多，缺页率就越低
4. 分配给进程的物理块数超过某个值时，对缺页率的改善并不明显
5. 好的页面置换算法可以使进程在运行过程中具有较低的缺页率
6. *LRU，CLOCK*将未来可能要用到的进程保存在内存中，可以提高页面的访问速度
7. 编写程序的局部化程度越高，执行时的缺页率越低
8. 存储和访问尽量使用系统的访问方式（如都按行存储就按行访问）

### <a name="14">（四）设备管理</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### a) I/O控制方式：程序控制、中断、DMA、通道；缓冲技术；假脱机技术(SPOOLing)。

I/O控制方式：
- 见组原
- 通道
    - 定义：当CPU要完成一组相关的读（或写）操作及相关控制时，只需向I/O通道发送一条I/O指令，以给出其所要指向的通过程序的首地址和要访问的I/O设备，之后CPU就可以去执行其他操作了
    - 特性
      - CPU、通道、I/O设备可并行工作，资源利用率很高。
      - 实现复杂，需要专门的硬件支持。
        - 一个通道可以控制多台设备与内存的数据交换
- 四种方式的比较：

I/O控制方式|过程|CPU干预频率|每次传输数据的单位|数据流向
-|-|-|-|-
程序直接控制方式|CPU发出指令后需要不断轮询|极高|字|设备-CPU-内存
中断驱动方式|CPU发出I/O指令后可以做其他事，本次I/O完成后设备控制器发出中断信号|高|字|设备-CPU-内存
DMA方式|CPU发出I/O指令后可以做其他事，本次I/O完成后DMA控制器发出中断信号|中|块|设备-内存
通道控制方式|CPU发出I/O指令后可以做其他事。通道会执行通道程序以完成I/O，完成后通道向CPU发出中断信号|低|一组块|设备-内存

假脱机技术(SPOOLing)：
- 脱机技术
    - 引入目的：缓解设备与CPU的速度矛盾，实现预输入，缓输出
    - 组成：外围机+更高速的设备--磁带
- 假脱机技术
    - 又叫SPOOLing技术，用软件的方式模拟脱机技术
    - OS中一项将独占设备改造成共享设备的软件技术
- SPOOLing系统的组成
    - 输入进程和输出进程【预输入程序管理】
        - 用于模拟脱机技术中的外围控制机
        - 需要和用户进程并发执行才可以模拟脱机技术，所以要实现SPOOLing技术需要多道程序技术的支持
    - 输入井和输出井【井输入程序管理】
        - 用于模拟脱机技术中的磁带
    - 输入缓冲区和输出缓冲区【缓输出程序管理】
        - 输入缓冲区用于暂存从输入设备输入的数据，之后再转存到输入井中
        - 输出缓冲区用于暂存从输出井传送的数据，之后再传送到输出设备上
- SPOOLing系统的特点
  - 提高了I/O速度，**将对低速I/O设备执行的I/O操作**演变为**对磁盘缓冲区中数据的存取**
  - 缓和了CPU和低速I/O设备之间的速度不匹配的矛盾
  - 将独占设备改造为共享设备，且没有为任何进程分配设备
  - 实现了虚拟设备功能，对每个进程而言，都认为自己独占了一个设备
  - 以空间换时间
  - 需要磁盘空间（输入输出井）和内存空间（输入输出缓冲区）
- 实例：共享打印机的实现
  - 打印机是独占设备，只允许各个进程串行使用设备，一段时间内只能满足一个进程的请求。
    - 实现过程
        1. 当多个用户提出输出打印的请求时，系统会答应它们的请求，但是并不会真正把打印机分配给它们，而是有假脱机管理进程为每个进程做两件事
        2. 在磁盘输出井中为进程申请一个空闲磁盘块，之后假脱机管理进程会**将进程要打印的数据送入刚申请的空闲磁盘块中**
        3. 为用户进程申请一张空白的打印请求表，并将用户的打印请求填入表中（用来说明用户的打印数据存放位置等信息），再将该表挂到假脱机文件队列上
        4. 当打印机空闲时，输出进程会从文件队列的队头取出一张打印请求表，并根据表中的要求打印数据从输出井传送到输出缓冲区，再输出到打印机打印
        5. 虽然系统中只有一台打印机，但每个进程提出打印请求时，系统都会为在输出井中为其分配一个存储区（相当于一个逻辑设备），使每个用户进程都觉得自己在独占一台打印机，从而实现对打印机的共享

**王道习题：**

一轮标记题：1 2 4 11 12 13 14 15 19 21 24 25

二轮重做：

错题总结：

#### b）磁盘的结构；磁盘调度算法；廉价冗余磁盘阵列。

磁盘的基本概念：
- 磁盘、磁道、扇区：
  - 磁盘的表面是由一些磁性物质组成，可以用这些磁性物理记录二进制数据
  - 磁盘表面被划分长的一个个磁道
  - 一个磁道又被划分为一个个扇区，每个扇区就是一个“磁盘块”。每个扇区的数据量相同（如1KB）
- 如何在磁盘中读/写数据？
  - 在磁盘中读写数据，需要借助磁头
  - step1：将磁头移动到想要读/写的扇区所在的磁道
  - step2：磁盘会转动，让目标扇区从磁头下面划过，才能完成对扇区的读/写操作
- 盘面、柱面
  - 磁盘是由多个盘片摞起来的，**每个盘片有两个盘面**。每个盘面都对应一个磁头。所有的磁头都连在同一个磁臂上
  - 磁臂可以沿着盘面作径向运动，从而带动磁头到达不同的磁道来对不同扇区的读写操作
  - 所有盘面中的相对位置相同的磁道组成了柱面
- 磁盘的物理地址
  - 使用（**柱面号，盘面号，扇区号**）来定位任意一个磁盘块
  - 文件数据存放在外存中的几号块，这里的块号就可以转换为（柱面号，盘面号，扇区号）的地址形式
  - 根据物理地址读取一个“块”
  1. 根据柱面号移动磁臂，让磁头指向指定柱面
  2. 激活指定盘面对应的磁头
  3. 磁盘旋转的过程，指定的扇区会从磁头下面划过。这样就完成了对指定扇区的读写
- 磁盘的分类
  - 根据磁头**是否可以活动**划分
    - 活动头磁盘
    - 固定头磁盘
  - 根据盘面**是否可以更换**划分
    - 可换磁盘
    - 固定盘磁盘

磁盘的管理：
- 磁盘初始化
  - 低级/物理格式化：在磁盘可以存储数据之前，将它分为扇区，以便磁盘控制器能够进行读写操作
- 分区
  - step1：将磁盘分为由**一个或多个柱面**组成的分区(如C区，D区)
  - step2: 对物理分区进行逻辑格式化(创建文件系统)
- 引导块
  - 计算机启动时需要运行一个初始化程序(自举程序)，该程序存放在ROM中
  - 启动/系统磁盘：磁盘具有启动分区的磁盘
- 坏块
  - 对坏块的处理实质上就是用某种机制使系统不去使用坏块

**一次磁盘读/写操作需要的时间：**
- 寻找时间（寻道时间）Ts【一般最长】
  - 在读/写数据前，需要将磁头移动到指定磁道所花费的时间。
  - 寻道时间分两步：
  (1) 启动磁头臂消耗的时间s
  (2) 移动磁头消耗的时间：假设磁头匀速移动，每跨越一个磁道消耗时间为m，共跨越n条磁道。
  - Ts = s + m * n。
- 延迟时间Tr
  - 通过旋转磁盘，使磁头定位到目标扇区所需要的时间
  - Tr =  (1/2)*(1/r) = 1/2r
  - 1/r就是转一圈所需的时间。找到目标扇区平均需要转半圈，因此再乘以1/2
- **传输时间Tt**
  - 从磁盘读出或向磁盘中写入数据所经历的时间
  - 假设磁盘转速为r，此次读/写的字节数为b，每个磁道上的字节数为N
  - Tt = (b/N) * (1/r) = b/(rN)
  - 每个磁道可存N字节数据，因此b字节数据需要b/N个磁道才能存储。而读/写一个磁道所需的时间刚好是转一圈的时间1/r
- 总的平均时间
  - Ta = Ts + 1/2r + b/(rN)
  - 无法通过操作系统优化延迟时间和传输时间。所以**只能优化寻找时间**

**常用的磁盘调度算法：**
- 先来先服务算法（FCFS）
  - 算法思想：根据进程请求访问磁盘的先后顺序进行调度
  - 举例
    - 假设磁头的初始位置是100号磁道，有多个进程先后陆续地请求访问55、58、39、18、90、160、150、38、184号磁道
    - 按照先来先服务算法规则，按照请求到达的顺序，磁头需要一次移动到55、58、39、18、90、160、150、38、184号磁道
    - 磁头共移动了 45 + 3 + 19 + 21 + 72 + 70 + 10 + 112 + 146 = 498个磁道。
    - 响应一个请求平均需要移动498 / 9 = 55.3个磁道（平均寻找长度）
  - 优点：公平；如果请求访问的磁道比较集中的话，算法性能还算可以
  - 缺点：如果大量进程竞争使用磁盘，请求访问的磁道很分散，FCFS在性能上很差，寻道时间长
- 最短寻找时间优先（SSTF）
  - 算法思想：优先处理的磁道是与当前磁头最近的磁道。可以保证每次寻道时间最短，不能保证总的寻道时间最短
  - 是贪心算法的思想，**只是选择眼前最优，但是总体未必最优**
  - 举例
    - 假设磁头的初始位置是100号磁道，有多个进程先后陆续地请求访问55、58、39、18、90、160、150、38、184号磁道。
    - 磁头总共移动了（100 -18）+ （184 -18） = 248个磁道。响应一个请求平均需要移动248 / 9 = 27.5个磁道（平均寻找长度）
    - 如果在处理18号磁道的访问请求时又来了一个38号磁道的访问请求，处理38号磁道的访问请求又来了一个18号磁道访问请求
    - 如果有源源不断的18号、38号磁道访问请求，那么150、160、184号磁道请求的访问就永远得不到满足，从而产生饥饿现象
    - 这里产生饥饿的原因是磁头在一小块区域来回移动
  - 缺点：**可能产生饥饿现象**
- 扫描算法（SCAN）（LOOK）
  - 为了防止饥饿问题，规定：
    - 磁头**只有移动到请求最外侧磁道或最内侧磁道才**可以反向移动
    - 如果在磁头移动的方向上已经没有请求，就可以立即改变磁头移动，不必移动到最内/外侧的磁道
    - 这就是扫描算法的思想。由于磁头移动的方式很像电梯，因此也叫电梯算法
  - 举例（LOOK）
    - 假设某磁盘的磁道为0 ~ 200号，磁头的初始位置是100号磁道，且此时磁头正在往磁道号增大的方向移动
    - 有多个进程先后陆续的访问55、58、39、18、90、160、150、38、184号磁道
    - 磁头共移动了（184 - 100）+ （184 -18） = 250个磁道。响应一个请求平均需要移动 250 / 9 = 27.5个磁道（平均寻找长度）
  - 优点：性能较好，寻道时间较短，不会产生饥饿现象
  - 缺点：SCAN算法对于各个位置磁道的响应频率不平均
    - 假设此时磁头正在往右移动，且刚处理过90号磁道，那么下次处理90号磁道的请求就需要等待磁头移动很长一段距离
- 循环扫描算法（C-SCAN）（C-LOOK）
  - 为了解决各个位置磁道的响应频率不平均这个问题，规定
    - 只有磁头朝某个特定方向移动时才处理磁道访问请求
    - 而返回时直接快速移动至最靠边缘的并且需要访问的磁道上而不处理任何请求
    - 通俗理解：**改变磁头方向时不处理磁盘访问请求而是直接移动到另一端最靠边的磁盘访问请求的磁道上**
  - 举例（C-LOOK）
    - 假设某磁盘的磁道为0 ~ 200号，磁头的初始位置是100号磁道，且此时磁头正在往磁道号增大的方向移动
    - 有多个进程先后陆续的访问55、58、39、18、90、160、150、38、184号磁道
    - 磁头共移动了（184 -100）+ （184 - 18）+（90 - 18）= 322个磁道，响应一个请求平均需要移动322 / 9 = 35.8个磁道（平均寻找长度）
  - 优点：相比于SCAN算法，对于各个位置磁道响应频率很平均
  - 缺点：相比于SCAN算法，平均寻道时间更长

廉价冗余磁盘阵列：
- RAID（独立磁盘冗余磁盘阵列）是指将多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理盘上分割交叉存储、并行访问，具有更好的存储性能、可靠性和安全性
- RAID的分级如下所示。在 RAID1 ~ RAID5几种方案中，无论何时有磁盘损坏，都可随时拔出受损的磁盘再插入好的磁盘，而数据不会损坏，提升了系统的可靠性
  - RAIDO：无冗余和无校验的磁盘阵列
    - RAID0把连续多个数据块交替地存放在不同物理磁盘的扇区中，几个磁盘交叉并行读写，不仅扩大了存储容量，而且提高了磁盘数据存取速度，但RAID0没有容错能力
  - **RAID1**：镜像磁盘阵列
    - 为了提高可靠性，RAID1使两个磁盘同时进行读写，互为备份，若一个磁盘出现故障，可从另一磁盘中读出数据
    - 两个磁盘当一个磁盘使用，意味着容量减少一半
  - RAID2：采用纠错的海明码的磁盘阵列
  - RAID3：位交叉奇偶校验的磁盘阵列
  - RAID4：块交叉奇偶校验的磁盘阵列
  - RAID5：无独立校验的奇偶校验磁盘阵列

**王道习题：**

一轮标记题：5 6 20 22

二轮重做：

大题：

1.
- 待做

错题总结：

#### c) 其他

I/O软件层次结构：
1. 用户层I/O软件
    - 待补充
2. 设备独立性软件
    - 待补充
3. 设备驱动程序
4. 中断处理程序
5. 硬件

设备分配与回收：
- 待补充

**王道习题：**

一轮标记题：9 12 15 16 18 20 30

二轮重做：

错题总结：

#### 本章小结

### <a name="15">（五）文件系统</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### a) 文件与文件系统的基本概念；组织方式；文件控制块；目录结构；文件存取控制；文件系统层次结构。

文件的基本概念：
- 文件是什么？	
    - 文件是以硬盘为载体的存储在计算机上的信息集合
    - 文件可以是文本文档，图片，程序
    - 用户进行的输入输出中，以文件为基本单位
- 文件由什么组成？	
    1. 一块存储空间
  2. **分类和索引**的信息
  3. 关于**访问权限**的信息
- 文件属性 / 文件元数据
    - 文件名；文件类型
  - 创建者；所有者
  - 位置；大小；保护；创建信息

文件系统的基本概念和目标：
- 概念
    - 文件系统 = OS中负责管理持久数据的子系统
    - 文件系统 = 与文件管理有关的软件 + 被管理的文件 + 文件管理所需的数据结构
    - 文件系统需先挂在到某个目录才可正常使用
    - 文件的基本操作单位就是数据块
- 目标
    1. 实现对文件的基本操作 = **按名存取**文件 + 组织成合适的结构 + 文件共享 + 文件保护【用户角度】
    2. 管理与磁盘的信息交换 + **完成逻辑结构和物理结构的变换**【OS角度】
    3. 组织文件在磁盘上的存放 + 采取好的文件排放顺序和磁盘调度方法【OS角度】
- 分类
    - 磁盘的文件系统
    - 它是直接把数据存储在磁盘中，比如 Ext 2/3/4、XFS 等都是这类文件系统
  - 内存的文件系统
    - 这类文件系统的数据不是存储在硬盘的，而是占用内存空间
    - 我们经常用到的 /proc 和 /sys 文件系统都属于这一类
    - 读写这类文件，实际上是读写内核中相关的数据
  - 网络的文件系统
    - 用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等

**文件的数据结构：**
- 目录项
    - 相关概念：
        - 目录项 / FCB = 用来记录文件的名字，索引节点指针以及其他目录项的层级关联关系
        - （文件）目录 / 目录文件 = **FCB的集合**
        - 目录项是由内核维护的一个数据结构，缓存在内存，目录项文件存储在磁盘（存疑）
        - 目录文件存放该目录中所有子目录文件和数据文件的目录（存疑）
    - 包含信息
        - **基本信息**：文件名，文件物理地址，文件逻辑结构，文件物理结构
        - **存取控制信息**：文件主或核准用户或一般用户的存取权限
        - **使用信息**：文件创立时间，上次修改时间
- 索引结点（i结点）
    - 概念	
        - 索引节点是用来记录文件的元信息，是文件的唯一表示
        - 索引节点同样占用磁盘空间
        - 将文件描述信息从目录项中分离，此时目录项 = **文件名** + 索引节点**指针**
        - 使用索引节点可以减少查找文件时的I/O信息量
    - 分类	
        - 磁盘索引节点
          - 指存放在磁盘上的索引节点，每个文件有一个唯一的磁盘索引节点
          - 包含内容：文件主标识符；文件类型；文件存取权限；**文件物理地址**（13个地址项）；文件长度；文件链接计数；文件存取时间
      - 内存索引节点
          - 指存放在内存中的索引节点，文件打开后，将磁盘索引节点复制到内存中
          - 新增内容：索引节点编号；状态；访问计数；逻辑设备号；链接指针
- 示例图：![img](https://files.catbox.moe/h4ooau.jpg)

文件的操作：
- 基本操作
    - 创建文件；写文件；读文件；重新定位文件；删除文件；截断文件
- 文件打开的过程
    - 文件打开就是调用open，根据文件名搜索目录，将指明文件的属性（包括该文件在外存上的物理地址），从外存复制到内存打开文件表的一个表目中，并将该表目的编号（也叫索引）返回给用户
    - 【打开文件操作的主要工作就是把指定文件的目录复制到内存指定的区域】
    - 【open操作会把文件的FCB调入内存，而不会把文件内容读到内存，只有进程希望获取文件内容时才会读入文件内容】
- 打开文件的关联信息
    - 文件指针；文件打开计数；文件磁盘位置；访问权限
    - 📢文件描述符（UNIX）/ 文件句柄（Windows） = 打开文件的标识 / 索引

文件的保护：
- 保护的目的: 解决对文件的读，写，执行的许可问题
- 一个文件的访问常由用户访问权限和文件属性（包括保存在FCB中对文件访问的控制信息）共同设置
- 保护的方式
    - 非访问控制方式：
        - 口令
            - 定义：用户建立一个文件时需要提供口令；用户请求访问时必须提供相应口令
            - 优点：时间空间开销不多
            - 缺点：**口令直接存在系统内部**，不安全
        - 加密保护
            - 定义：对文件进行加密，访问时需要密钥
            - 优点：保密性强，节省了存储空间
            - 缺点：编码和译码需要时间
    - 访问控制方法：
        - 访问控制的目的：用于控制用户对文件的访问方式
        - 访问控制的对象：读；写；执行；添加；删除；列表清单
        - 访问控制机制必须由系统实现
        - 方法一
            - 定义：为每个文件和目录增加一个访问控制列表ACL，该表规定**每个用户名及其所允许的空间管理**
            - 优点：可以使用复杂的访问方法
            - 缺点：长度无法预计并且可能导致复杂的空间管理
        - 方法二：
            - 定义：采用精简的访问列表，该列表采用**拥有者，组和其他**三种用户类型
            - 优点：只需要三个域即可列出访问表中这三类用户的访问权限

文件的逻辑结构【用户角度的文件组织形式】（本质是为**查找数据**服务）：
- 定义：即文件中的数据在逻辑层面是如何组织起来的
- 无结构文件/流式文件	
    - 最简单的文件组织形式，是有序相关信息项的集合，**以字节为单位**
    - 对基本信息单元操作不多的文件适合该方式
- 有结构文件/记录式文件
    1. 顺序文件
        - 串结构：只能按顺序查找，费时
        - 顺序结构：可采用折半查找，检索效率高
    2. 索引文件
        - 提高了存取速度，但索引表增加了存储空间
    3. 索引顺序文件
        - 提同一组中的关键字可以无序，但组与组之间的关键字必须有序
        - 先通过索引表顺序查找所在的组，然后再该组中使用顺序查找
        - 顺序查找平均次数N/2；索引顺序查找平均次数N^(1/2)
    4. 哈希文件

**文件的物理结构**【文件在外存上的存储组织形式】：
- 定义
    - 研究文件数据在物理存储设备上是如何分布和组织的
    - 文件在磁带上--->连续存放方式
    - 文件在磁盘上--->不采用连续存放方式
    - 文件在内存上--->随机存放方式
- 文件的存储方式（对磁盘非空闲块的管理）
    - 顺序分配【类似数组】（访问磁盘1次）
        - **目录项物理地址 = 起始块地址 + 文件长度**
        - 要求连续的存储空间
        - 可随机访问（文件定长）
    - 链表分配【类似链表】（访问磁盘n次）
        - 存放是离散的，不用连续的，于是就可以消除磁盘碎片
        - 可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展
        - 隐式链接无法直接访问数据块，只能通过指针顺序访问文件
            - **目录项 = 起始块地址 + 末尾块地址**  
        - 显式链接把用于链接文件各数据块的指针，显式地存放在内存的**一张**链接表中，内存中的这样一个表格称为文件分配表FAT
            - **目录项 = 起始块地址**
        - **不可随机访问**
    - 索引分配【类似索引表】（m级访问磁盘m+1次）
        - 为**每个文件**创建一个「索引数据块（表）」
        - 里面存放的是指向文件数据块的指针列表
        - 像书的目录一样，要找哪个章节的内容，看目录查就可以
        - 可随机访问
        - **目录项 = 索引数据块指针**
        - 可选方案：链接索引；多层索引；**混合索引**
    - 混合索引分配
        - 为了能够较全面地照顾到小型、中型、大型和特大型文件，可采用混合索引分配方式
        - 对于小文件，为了提高对众多小文件的访问速度，**最好能将它们的每个盘块地址直接放入FCB**，即为直接寻址
        - 对于中型文件，可以采用单级索引方式，**需要先从FCB中找到该文件的索引表，从中获得该文件的盘块地址**，即为一次间址
        - 对于大型或特大型文件,可以采用两级和三级索引分配方式
        - UNIX系统采用的就是这种分配方式，在其索引结点中，共设有13个地址项，即i.addr(0) ~ i.addr(12)
            1. 直接地址。为了提高对文件的检索速度，在索引结点中可设置10个直接地址项，即用i.addr(0) ~ i.addr(9)来存放直接地址，即文件数据盘块的盘块号。假如每个盘块的大小为4KB，当文件不大于40KB时，便可直接从索引结点中读出该文件的全部盘块号
            2. 一次间接地址。对于中、大型文件，可再利用索引结点中的地址项i.addr(10)来提供一次间接地址。**这种方式的实质就是一级索引分配方式**。在一次间址块中可存放1024个盘块号，因而允许文件长达(4KB / 4B(指针大小)) * 4KB = 4MB
            3. 多次间接地址。当文件长度大于4MB + 40KB时，系统还需采用二次间接地址分配方式。这时，用地址项i.addr(11)提供二次间接地址。该方式的实质是两级索引分配方式。系统此时在二次间址块中记入所有一次间址块的盘号。地址项i.addr(11)作为二次间址块，允许文件最大长度可达4GB。同理，地址项iaddr(12)作为三次间址块，其允许的文件最大长度可达4TB
- 文件的存储空间管理（对磁盘空闲块的管理）
    1. 空闲表法
        - 为所有空闲空间建立一张表
        - 表内容包括空闲区的第一个块号和该空闲区的块个数
    2. 空闲链表法
        - 每一个空闲块里有一个指针指向下一个空闲块
        - 这样能很方便的找到空闲块并管理起来
    3. 位图法
        - 位图是利用二进制的一位来表示磁盘中一个盘块的使用情况
        - 磁盘上所有的盘块都有一个二进制位与之对应
        - 当值为 0 时，表示对应的盘块空闲；值为 1 时，表示对应的盘块已分配
        - 通常可用m * n个位数来构成m行n列的位示图，且m * n等于磁盘的总块数
        - Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的
    4. 成组链法
        - 结合空闲表和空闲链表的优点，克服表长的缺点

目录结构：

名称|定义|优点|缺点
-|-|-|-
单级目录结构|整个文件系统只建立一张目录表；每个文件占一个目录项|~|查找速度慢；文件不允许重名；不便于文件共享；不适合多用户的OS
两级目录结构|文件目录分为主文件目录MFD和用户文件目录UFD；MFD记录用户名UFD所在的存储位置；UFD记录用户文件的FCB信息|解决了多用户之间的文件重名问题；文件系统可以在目录上实现访问限制|缺乏灵活性，不能对文件分类
🌲型目录结构|使用绝对路径，相对路径，当前路径的结构；不同的用户的文件，文件名可相同可不同；数据文件一定在树叶上；大多OS采用这种目录结构|可以很方便的对文件进行分类；能够有效地进行文件的管理和保护|查找文件增加了磁盘访问次数，会影响查询速度
无环图目录结构|在树形目录结构上，加入有向边，组成一个有向无环图DAG；一个文件可以有多个父目录；|实现了文件共享|使系统的管理变得更加复杂

文件系统的层次结构：
- I/O控制
    - **设备驱动程序**：将输入的命令翻译成底层硬件的特定指令
  - **中断处理程序**：利用指令使IO设备与系统交互
- 基本文件系统
    - 向对应的设备驱动程序发送通用命令，以读取和写入磁盘的物理块
  - 管理内存缓冲区，保存各种文件系统，目录和数据块的缓冲
- 文件组织模块
    - 组织文件及其逻辑块和物理块
    - 可以将逻辑地址转换为物理地址
    - 有空闲空间管理器，以跟踪未分配的块，根据需要提供给文件组织模块
- 逻辑文件系统（虚拟文件系统）
    - 用于管理元数据信息（包括文件系统的所有结构，不包括文件内容）
    - 管理目录结构
    - 通过FCB维护文件结构
    - 负责文件保护

**王道习题：**

二轮重做：1 6 9 22 23 30(好题！) 31 37；2 8；7 8

大题：

1.
- 待做

错题总结：
- 不同用户进程在其**打开文件**表上对于同一个文件的数据不一定相同，例如读写指针位置不一定相同
- 整个文件系统只有一个系统**打开文件**表（里面的表项都是不重复的），同一文件打开多次只需增加打开计数
- 将文件描述信息从目录项中分离，即应用了索引结点的方法，磁盘的盘块中可以存放更多的目录项，**查找文件**时可以大大减少其I/O信息量
- 用户访问权限是指用户有没有权限访问该文件，而用户优先级是指在多个用户同时请求该文件时应该先满足谁。比如，图书馆的用户排队借一本书，某用户可能有更高的优先级，即他排在队伍的前面，但有可能轮到他时被告知他没有借阅那本书的权限
- **索引分配支持变长的文件**，同时可以随机访问文件的指定数据块
- 文件系统管理空闲磁盘块的数据结构包括位图、链表、**文件分配表**

#### b) 其他

目录的查询/检索：
- 概念
    - 目录查询通过在磁盘上反复搜索完成，**需要不断进行I/O操作**，开销大
    - 可以**把当前使用的文件目录复制到内存**，从而降低磁盘操作次数，提高系统速度
- 实现方法
    - 线性列表【对应线性查找】
        - 采取线性列表存储文件目录项
        - 实现简单
        - 查找费时
    - 哈希表【对应散列查找】
        - 采取哈希表存储文件目录项
        - 查找迅速，插入删除简单
        - 需要一些措施来避免冲突

文件共享：
- 概念
    - 文件共享使多个用户共享同一个文件，系统只需保留该文件的一个副本
- 文件共享方式：

文件共享方式|基于索引节点的关系方式【硬链接】|基于符号链实现文件共享【软链接】
-|-|-
定义|硬链接就是多个指针指向一个索引节点；文件的物理地址和其他文件属性信息放在索引节点中|软链接相当于重新创建一个文件；新文件只包含被链接文件的路径名
特点|硬链接不可用于跨文件系统（跨卷）；硬链接查找速度比软链接快|软链接可以跨文件系统
新增文件时|建立硬链接时，引用计数值加1|符号链接，计数值直接复制
删除文件时|删除文件时，计数值减1；若得到的值不为0，则不能删除此文件；即只要还有一个指针在，索引节点就不会被删除|删除操作对符号链接不可见；以后再通过符号链接访问时，若发现文件不存在，直接删除符号链接
示例|mklink /h|快捷方式

文件系统的布局：
- 在磁盘中的结构
    - 最前面的第一个块是引导块，在系统启动时用于启用引导
    - 接着后面就是一个一个连续的块组了，块组的内容如下👇
    - 超级块
        - 包含的是文件系统的重要信息
        - 比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数
    - 块组描述符
        - 包含文件系统中各个块组的状态
        - 比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」
    - 数据位图 & inode 位图
        - 用于表示对应的数据块或 inode 是空闲的，还是被使用中
    - inode 列表
        - 包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据
    - 数据块
        - 包含文件的有用数据
- 在内存中的结构
    - 内存中的信息用于管理文件系统并通过**缓存**来提高信息传输速率
    - 这些结构有以下类型👇
        - 内存中的安装表
        - 内存中的目录结构的缓存包含最近访问目录的信息
        - 整个系统的打开文件表
        - 每个进程的打开文件表

虚拟文件系统VFS：
- 目的：为**用户程序**提供了文件系统**操作的统一接口**，屏蔽了不同文件系统差异和操作细节
- 特性
    1. 能提高系统性能
    2. 不是一种实际的文件系统
    3. 只存在于内存中，不存在与任何外存空间中
    4. 在系统启动时建立，在系统关闭时消亡
- VFS的数据结构
    1. 超级块对象
    2. 索引节点对象
    3. 目录项对象
    4. 文件对象
- 图例：![img](https://files.catbox.moe/zlfvxn.png)

分区和安装：
- 一个磁盘可划分为多个区，**每个分区都可以创建单独的文件系统**，**每个分区都可包含不同的操作系统**
- 文件在使用前必须先安装（即挂载）

**王道习题：**

二轮重做：

大题：

错题总结：
- 在树型目录中，为了加快文件检索速度，可设置当前目录，于是文件路径可以从当前目录开始查找
- 文件系统采用多级目录的目的是解决命令冲突
- 树形目录结构中，用户对文件的首次访问通常采用文件路径名，之后对文件的访问通常使用文件描述符（一个整数）
- 在顺序检索法时，只要路径名的一个分量名未找到，**就应停止查找**

#### 本章小结

- UNIX相关知识
    1. UNIX采用树型目录结构，文件信息存放在索引节点中，超级块是用来描述文件系统的
    2. UNIX系统所有设备都被视为特殊的文件
    3. UNIX每个目录文件中，默认有两个目录项，"."表示当前目录，".."表示父目录
- **各种表，图**
    1. **打开文件**表：存放已打开文件信息的表，将指名文件的属性从外存复制到内存，再使用该文件时直接返回索引
    2. 位图：详见磁盘管理方法
    3. 空闲盘链表：详见磁盘管理方法
    4. 索引表：记录每个文件所存放的盘块地址
    5. 系统调用表：是一张由指向实现各种系统调用的内核函数的函数指针组成的表，该表可以基于系统调用函数进行索引，来定位函数地址，完成系统调用
- 文件性能相关
    - 与单个文件长度/大小有关的因素：文件块大小，地址项个数，间接地址索引的级数（索引节点总数与单个文件大小无关）
    - 提高文件访问速度的方法：提前读，延迟写，为文件分配连续的簇，采用磁盘高速缓存
    - 文件在磁带上采用连续存放方式；在硬盘上不采用连续存放方法；在内存上采用随机存放方法
    - 连续结构的文件数据读最快，链式的方法不能随机存取，索引的方法占面积
- 文件打开相关	
    - 文件打开open是**把FCB读到内存**，不是把文件内容读到内存（即不会读入文件数据，只有用read的时候才会读数据）
    - open参数包含文件名
    - read/write参数不包含文件名，**而是open返回的文件索引**
- **文件打开的过程**
    1. 检索文件
    2. 检验访问权限
    3. 设置两种打开文件表，返回文件描述符fd
- 文件保护相关	
    - 防止文件受损的方法---->备份；
    - 用于多用户之间的存取权限保护---->存取控制矩阵方法
- 其他	
    - 系统级安全管理包括注册和登陆
    - 用户确定文件的逻辑结构，由操作系统设计者根据文件存储器的特性确定文件的物理结构，一旦确定，由操作系统管理

## <a name="16">计算机网络</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

### <a name="17">（一）计算机网络概述</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)计算机网络定义与分类

计算机网络：一般认为，计算机网络是一个将分散的、具有独立功能的计算机系统，通过通信设备与线路连接起来，由功能完善的软件实现资源共享和信息传递的系统

计算机网络的组成：
- 从组成部分上看，由硬件、软件、协议三大部分组成
- 从工作方式上看，分为边缘部分和核心部分
- 从功能组成上看，由通信子网和资源子网组成，通信子网 = 各种传输介质 + 通信设备 + 相应的网络协议，资源子网 = 实现资源共享功能的设备 + 相应软件

计算机网络的功能：1.数据通信（最基本和最重要的功能）；2.资源共享；3.分布式处理；4.提高可靠性；5.负载均衡（即：将工作任务均衡分配）

计算机网络的分类：
- 按分布范围分：1.广域网（WAN）2.城域网（MAN）3.局域网（LAN）4.个人区域网（PAN）
- 按传播技术分：1.广播式网络：局域网、广域网中的无线和卫星通信网络；2.点对点网络，采用分组存储转发与路由选择机制
- 按拓扑结构分：主要分为总线形、星形、环形和网状网络等，前三者多用于局域网，网状网络多用于广域网
- 按使用者分：分为公用网和专用网
- 按交换技术分：1.电路交换网络（典型：传统电话网络）；2.报文交换网络（又称存储-转发网络）；3.分组交换网络（又称包交换网络，现在的主流网络基本都是这种）
- 按传输介质分：分为有线和无线两大类

计算机网络的性能指标：
- 带宽：在计算机网络中，是“最高数据传输速率”的同义语，单位是比特/秒
- 时延：由发送时延（分组长度/信道带宽）、传播时延（信道长度/电磁波在信道上的传播速率）、处理时延（存储转发时的处理时间）、排队时延（进入路由器时要排队）组成，后两者一般可忽略不计
- 时延带宽积 = 传播时延 × 信道带宽
- 往返时延：指从发送端发出一个短分组，到发送端收到来自接收端的确认（接收端收到数据后立即发送确认)，总共经历的时延。在互联网中，往返时延还包括各中间结点的处理时延、排队时延及转发数据时的发送时延
- 吞吐量（Throughput）：单位时间内通过某个网络（或信道、接口）的数据量
- 速率：也称数据传输速率、数据率或比特率
- 信道利用率 = 有**数据**通过时间 / （有 + 无）数据通过时间

**王道习题：**

一轮标记题：6 10 12 16 18

二轮重做：3 16 18

大题：1 5 6

1.
- 解：101000B，25000B，10000B；

2.
- 解：80Mb/s，409.6Mb/s

3.
- 解：略
- 答：如果网络容易丢失分组，那么对每个分组逐一进行确认较好，此时仅重传丢失的分组。另一方面，如果网络高度可靠，那么在不发生差错的情况下，仅在整个文件传送的结尾发送一次确认，从而减少了确认次数，节省了带宽。不过，即使只有单个分组丢失，也要重传整个文件。

4.
- 解：电路：s + x / b + k * d；分组：设共有n个分组，则n * p / b + (k 1. * p / b + k * d
- 解析：**计算分组交换的时延时，我们可以从最后一个分组的视角进行考虑，它首先需要排队等n次传播时延，然后又需要经过k次传播时延和k-1次中间结点的传输时延**

5.
- 解：t = (x / p + k 1. * (p + h) / b，t对p求导，得p = √((xh)/(k-1))

6.
- 解：
    - 1)2RTT + 1000 * 1024 * 8 / (1.5 * 10 ^ 6) + 0.5RTT = 0.2 + 5.46 + 0.05 = 5.71s
    - 2)5.71 + 999RTT = 105.61s
    - 解析：**最后一个分组虽然没有确认，但此时已经满足题设要求的“直到文件的最后一位到达目的地”了**
    - 3)2RTT + 49RTT + 0.5RTT = 5.15s

7.
- 解：略
- 答：不相同。在报文流中，网络保持对报文边界的跟踪；而在字节流中，网络不进行这样的跟踪。例如，一个进程向一条连接写了1024B，稍后又写了1024B，那么接收方共读了2048B。对于报文流，接收方将得到两个报文，每个报文1024B。而对于字节流，报文边界不被识别，接收方将全部2048B作为一个整体，在此已经体现不出原先有两个不同报文的事实

错题总结：
- 广播式网络共享广播信道（如总线)，通常是局域网的一种通信方式（局域网工作在数据链路层)，因此不需要网络层，因而也不存在路由选择问题。但数据链路层使用物理层的服务必须通过服/访问点实现
- ARPAnet是最早的计算机网络，它是因特网的前身

#### (2)计算机网络体系结构

计算机网络体系结构：计算机网络各层及其协议的集合

*n-SDU + n-PCI = n-PDU = (n-1)-SDU*

协议：由**语法**、**语义**和**同步**三部分组成，语法规定了传输数据的格式，语义规定了所要完成的功能，同步规定了执行各种操作的条件、时序关系等

接口：同一结点内相邻两层间交换信息的连接点。在典型的接口上，同一结点相邻两层的实体通过SAP进行交互。**物理层的服务访问点就是网卡接口，数据链路层的服务访问点是MAC地址，网络层的服务访问点是IP地址，传输层的服务访问点是端口号，应用层提供的服务访问点是用户界面**

服务：下层为紧邻的上层提供的功能调用，上层与下层之间交换的命令称为服务原语
- 服务原语：请求（Request）（C->S）、指示（Indication）（S->C）、（对请求的）证实（Confirmation）（S->C）、（对指示的）响应（Response）（C->S），无应答服务只有前两者
- 注意：**协议是“水平”的，但服务是“垂直”的**
- 注意：**只有能被上层看到的功能，才能算得上是服务！**
- 服务的分类：
    - 面向连接服务和无连接服务
    - 可靠服务和不可靠服务
    - 有应答服务和无应答服务

OSI参考模型：**有7层**，自下而上依次为**物理层、数据链路层、网络层、传输层、会话层、表示层、应用层**，低三层统称为通信子网，传输层承上启下，高三层统称为资源子网。其中，会话层允许不同主机上的各个进程之间进行会话，表示层主要处理在两个通信系统中交换信息的表示方式，应用层为特定类型的网络应用提供访问OSI参考模型环境的手段

TCP/IP模型：APRA在研究APRAnet时提出了TCP/IP模型，从低到高依次为**网络接口层、网际层、传输层和应用层**，并由于得到了广泛应用而成为事实上的国际标准

两个模型的对比：
- 相似之处：都采取分层的体系结构；都基于独立的协议栈；都可以解决异构网络的互联问题；
- 差别：
    - OSI精准地定义了服务、协议和接口三个概念，与面向对象思想非常吻合
    - OSI通用性良好，TCP/IP则不适合于非TCP/IP的协议栈
    - TCP/IP在设计之初就考虑到了多种异构网的互联问题，OSI是后来加上的
    - 主要考察点：**OSI在网络层就支持无连接和面向连接的通信，在传输层仅有面向连接的通信，而TCP/IP则选择了更省钱的做法**

**王道习题：**

二轮重做：1 8 12 13 

大题：

2.
- 解：物理层；网络层；数据链路层；应用层；会话层

错题总结：
- 在OSI参考模型中，会话层的两个主要服务是会话管理和同步。会话层使用校验点可使通信会话在通信失效时从校验点继续恢复通信，实现数据同步
- 在OSI参考模型中，**2、3、4层均提供差错控制、流量控制等功能，3、4层均提供拥塞控制功能**

### <a name="18">（二）物理层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)物理层的基本概念

- 物理层解决了什么？
  - 物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。
- 物理层主要任务？
  - 确定与传输媒体接口有关的一些特性
- 与传输媒体接口有关的特性？
  - 机械特性：定义物理连接的特性，规定物理连接时所采用的规格、接口形状、引线数目、引脚数量和排列情况
  - 电气特性：规定传输二进制时，线路上信号的**电压范围**，阻抗匹配、传输速率和距离限制。如某网络在物理层规定，信号的电平用+10V ~ +15V表示二进制0，用-10V ~ -15V表示二进制1，电线长度限于15m之内，这些都是电气特性
  - 功能特性：指明某条线上出现的某一电平的**电压表示何种意义**。注意与电气特性区分，如描述一个物理层接口引脚处高电平时的含义表示的是功能特性
    - 过程特性：指明对于不同功能的各种可能事件的出现顺序
- 物理层协议也称物理层接口标准，或物理层规程（Procedure）
- 常用的物理层接口标准：EIA RS-232-C、ADSL、SONET/SDH、EIA/TIA RS-449、CCITT的X.21等

**物理层设备：**
中继器（转发器/放大器）：
- 中继器的功能：对信号再生和还原（而非简单地将衰减的信号放大），保持与原数据相同，以增加信号传输的距离，延长网络的长度
- 中继器的两端
  - 中继器两端的网络部分是网段，而不是子网，使用中继器连接的几个网段**仍然是一个局域网**
    - **中继器没有存储转发功能，因此它不能连接两个速率不同的网段，中继器两端的网段一定要使用同一个协议**
- 5-4-3规则
  - 网络标准中对信号的延迟范围作了具体的规定，因而中继器只能在规定的范围内进行，否则会网络故障。
  - 采用粗同轴电缆的10BASE5以太网规范中，4个中继器，串联5段通信介质，只有3段可以挂接计算机，其余2段只能用作扩展通信范围的链路段

集线器：
- 本质是一个多端口的中继器
- 集线器功能
  - 对信号进行再生放大转发
  - 端口收到数据后，从除输入端口外的所有端口转发出去
    - 不具备信号的定向传送能力，是一个共享设备

**王道习题：**

一轮标记题：2 3 8

二轮重做：7

#### (2)数据通信的基础知识

基础知识：
- 数据：传送信息的实体，通常是有意义的符号序列
- 信号：数据的电气 / 电磁的表现，是数据在传输过程中的存在形式
    - 数字信号（离散信号）：代表消息的参数取值是离散的
    - 模拟信号（连续信号）：代表消息的参数取值是连续的
- 信源：产生或发送数据的源头
- 信宿：接收数据的终点
- 信道：信号的传输媒介。一般用来表示向某一个方向传送信息的介质，因此一条通信线路往往包含一条发送信道和一条信道
- 信道分类：
    - 按传输信号：模拟信道用于传输模拟信号；数字信道用于传输数字信号
    - 按传输介质：无线信道、有线信道
- 信号分类：
    - 基带信号：将数字信号1和0直接用两种不同的电压表示，然后送到数字信道上传输（基带传输）
    - 宽带信号：将基带信号进行调制后形成频分复用模拟信号，然后送到模拟信道上传输（宽带传输）
- 通信方式：
    - 单工通信：
        - 单向通信。即只能有一个方向的通信而没有反方向的交互
        - 如无线电广播、有线电广播
    - 半双工通信：
        - 双向交替通信。即通信双方都可以发送信息，但不能双方不能同时发送
        - 这种方式是一方发送另一方接收
    - 全双工通信
        - 双向同时通信。即通信双方可以同时发送或接收信息
        - 单工通信需要一条信道，而半双工通信和全双工通信需要两条信道
- 数据传输方式：
    - 串行传输	
        - 1比特1比特地按照时间顺序传输
        - 速度慢，费用低，适合远距离
    - 并行传输	
        - 若干比特通过多条通信信道同时传输
        - 速度快，费用高，适合近距离
        - 适用于计算机内部数据传输



- 码元：码元是指用一个**固定时长**的信号波形（数字脉冲）表示一位k进制数字，代表不同离散数值的基本波形，是数字通信中数字信号的计量单位，这个时长内的信号称为k进制码元，而该时长称为码元宽度。1码元可以携带若干比特的信息量
    - 在使用二进制编码时，只有两种不同的码元，一种代表0状态，一种代表1状态，是二进制码元
    - 一个码元所携带的信息量是不固定的，是由调制方式和编码方式决定的
- 速率 && 波特
    - 1波特表示数字通信系统每秒传输一个码元
    - **码元传输速率 = 码元速率 = 波特率 = 波形速率 = 符号速率 = 调制速率**：表示单位时间内数字通信系统所传输的码元个数（也可以称为脉冲个数或信号变化的次数），单位是波特（Baud）
    - **信息传输速率 = 信息速率 = 比特率**：表示单位时间内数字通信系统传输的二进制码元个数（或者比特数），单位：b/s
    - 关系：波特率 = 比特率 / 每码元所含比特数
    - 信道的**极限容量**是指信道的最高码元传输速率或信道的极限信息传输速率



**奈氏准则 & 香农定理：**
- 码间串扰：信号中的许多高频分量往往不能通过信道，否则在传输中会衰减，导致接收端收到的信号波形失去码元之间的清晰界限
- 影响失真程度的因素：码元传输速率、信号的传输距离、噪声干扰、传输媒体的质量
- 奈氏准则 / 采样定理 / 奈奎斯特定理：
  - **在理想低通（无噪声、带宽有限）的信道中，为了避免码间串扰，极限码元传输速率为2W Baud**（W是信道带宽，单位是Hz）
      - **带宽只有在奈氏准则和香农定理中单位是HZ，其余都是b/s**
        - 理想低通信道下的极限数据传输率 = 2W *log2V（W是信道带宽，单位：Hz。V是码元的离散电平数目，即共有几种码元）
    - 在任何信道中，码元传输速率是有上限的，如果传输速率超过这个上限，就会出现严重的码间串扰问题，使接收端对码元的识别成为不可能
    - 如果信道的频带越宽，也就是能够通过的信号高频分量越多，那么就可以用更高速率传送码元而不出现码间串扰
    - 由于码元的传输速率受奈氏准则的制约，所以**要提高数据的传输速率，就必须设法使每个码元能携带更多的个比特量的信息**
- 香农定理：
  - **在带宽受限且有噪声的信道中，为了不产生误差，信息的数据传输率有上限值**
    - 信噪比
        - 信号的平均功率和噪声的平均功率之比，常记于S/N，并用分贝（dB）作为度量单位
        - 信噪比（dB） = 10 lg(S/N) (dB)
    - 信道的极限数据传输速率 = W log2(1+S/N) (b/s)
    - 信道的带宽越大或信道的信噪比越大，则信息的极限传输速率就越高
    - 对一定的传输带宽和一定的信噪比，信息传输速率的上限就确定了
    - **只要信息的传输速率低于信道的极限传输速率，就一定能找到某种方法来实现无差错传输**

**编码与调制：**
- **编码：数据→数字信号；调制：数据→模拟信号**
- 信号是数据的具体表示形式，它和数据有一定的关系，但又和数据不同。数字数据可以通过**数字发送器**转换为数字信号传输，也可以通过**调制器**转换成模拟信号传输；同样，模拟数据可以通过**PCM编码器**转换成数字信号传输，也可以通过**放大器调制器**转换成模拟信号传输。这样，就形成了4种编码方式
- **基带信号 & 带通信号：**
    - 基带信号：**来源于信源的信号**。将数字信号1和0直接用两种不同的电压表示，再送到数字信道上传输（基带传输）
        - 计算机输出的代表各种文字或图像文件的数据信号都属于基带信号
        - 基带信号就是发出的直接表达了要传输的信息的信号。如说话的声波就是基带信号
      - 基信号往往包含较多带的低频成分，甚至有直流成分，而许多信道并不能传输这种低频分量或直流分量。为了解决这个问题，就必须对基带信号进行调制
    - 带通信号：**经过载波调制后的信号（即仅在一段频率范围内能通过信道）**
- **基带调制 & 带通调制：**
    - 基带调制：
        - 仅仅对基带信号的波形进行变换，使它能够与信道特性相适应
        - 经过变换后的信号仍然是基带信号
        - **由于基带调制是把数字信号从一种形式转换为另一种形式的数字信号，所以这种过程又称为编码**
    - 带通调制：
        - 使用载波进行调制，**把基带信号的频率搬移到更高的频段，并转换为模拟信号**，这样就可以更好地在模拟信道中传输
- 数字数据**编码为**数字信号
  - 归零编码（RZ）
        - 信号电平在一个码元之内都要恢复到零的编码方式
    - 这种编码在传输过程中处于低电平的情况多，信道利用率低
  - 非归零编码（NRZ）
        - 正电平为1，负电平为0
    - 编码容易实现，但没有检错功能，且无法判断一个码元的开始和结束，以至于收发双方难以保持同步
    - 需要在接收方和发送方另外建立一条信道来传输时钟周期信号来保证同步，无法保证自同步
    - **只有非归零编码不含同步信息**
  - 反向不归零编码（NRZI）
        - 信号电平翻转表示0，信号电平不变表示1
    - 反向不归零编码对于全部是1的信号同样难以确认一共发送了多少个信号，同样需要在收发双方之间另外建立一条信道传输时钟周期信号，无法实现自同步
  - **曼彻斯特编码**
        - **前高后低表示1，前低后高表示0**
    - 该编码特点是在每一个码元的中间出现电平跳变，位中间的跳变既作为时钟信号（可用于同步），又作为数据信号
    - **所占的频带宽度是原始的基带宽度的两倍，即每个码元都被调成两个电平，所以数据传输速率只有波特率的1/2**（在一个时钟周期内电平变化了两次，而只传输了一位比特），编码效率为50%
        - **以太网使用的编码方式就是曼彻斯特编码**
  - 差分曼彻斯特编码	
        - 若码元为1，则前半个码元的电平与上一个码元的电平相同，若为0，则相反。（**前同后异为1，前异后同为0**）
    - 该编码的特点是在每个码元中间都有一次电平的跳转，可以实现自同步，且抗干扰强于曼彻斯特编码。
  - 4B/5B编码：
        - 比特流中插入额外的比特以打破一连串的0或1，就是用5个比特来编码4个比特的数据，之后再传给接收方，因此称为4B/5B，编码效率为80%
        - 5位码共32种组合，但只采用其中的16种对应16种不同的4位码，其他16种作为控制码（帧的开始和结束、线路的状态信息等）或保留
- 数字数据**调制为**模拟信号
    - 1）幅移键控（ASK）：调幅
    - 2）频移键控（FSK）：调频
    - 3）相移键控（PSK）：调相
    - 4）正交振幅调制（QAM）：在频率相同的前提下，将ASK与PSK结合起来，形成叠加信号。设波特率为B，采用m个相位，每个相位有n种振幅，则该QAM技术的数据传输速率R为 R= B log2(mn) (b/s)
- 模拟数据**编码为**数字信号
  - 计算机内部处理的是二进制，处理的都是数字音频，所以需要将模拟音频通过采样、量化转换成有限个数字表示的离散序列（即实现音频数字化）
  - 典型的例子
    - 对音频信号进行编码的脉码调制（PCM），在计算机应用中，能够达到最高保真水平的就是PCM编码。它的主要步骤包括三步：抽样、量化、编码
  - 抽样
    - 对模拟信号进行周期性扫描，把时间上连续的信号变成时间上离散的信号
    - 为了使得所得到的离散信号能无失真地代表被抽样的模拟数据，要使采样定理进行采样：**f采样频率 ≥ 2f信号最高频率**
  - 量化：把抽样取得的电平幅值**按照一定的分级标度**转化为对应的数字值，并取整数，这就把连续的电平幅值转换为离散的数字量
  - 编码：把量化的结果转换为与之对应的二进制编码
- 模拟数据**调制为**模拟信号
  - 在模拟信号传输过程中，可能信道的长度非常长，环境比较恶劣，会导致传输的模拟信号会受到衰减
  - 为了保证传输的有效性，需要将信号调制成频率更高的信号来应对传输过程的衰减
    - 接收方接收到调制的信号后，通过**解调器**将信号还原为原来的信号

**王道习题：**

一轮标记题：1 3 4 9 10 17 18 20 25 29 33 36

二轮重做：9 16 17 18 25 41

大题：2 4 5(答案都看不懂！)

1.
- 答：分组交换生成的PDU的长度较短且是固定的，而报文交换生成的PDU的长度不是固定的。正是这一差别使得分组交换具有独特的优点：①缓冲区易于管理；②分组的平均延迟更小，网络中占用的平均缓冲区更少；③更易标准化；④更适合应用。因此，现在的主流网络基本上都可视为分组交换网络

2.
1. 2.57s
2. 32MB
3. 它表示发送方在收到一个响应之前能够发送的数据量
4. 在图像可以开始到达地面之前，至少需要一个RTT。假定仅有带宽延迟，那么发送需要的时间等于25MB/(100Mb/s)=(25×1024×1024×8)bit/(100Mb/s)≈2.1s。因此，直到最后一个图像位到达地球，总共花的时间等于2.1+2.57=4.67s

3.
1. (10000b / 10Mb/s) * 2 + 20μs * 2 + 35μs = 2075μs
2. 10000b / 10Mb/s + 5000b / 10Mb/s + 20μs * 2 + 35μs = 1575μs

4.
- 解：每部电话平均每小时通话次数=4/8=0.5次，每次通话6分钟，因此一部电话每小时占用一条电路3分钟，即20部电话可共享一条线路。**由于只有10%的呼叫是长途，因此200部电话占用一条完全时间的长途线路**。局间干线复用了10^6/(4×10)=250条线路，每条线路支持200部电话，因此一个端局能支持的最大电话数是200×250=50000部

5.
- 解：由于每个话路采用7bit编码，然后再加上1bit信令码元，因此一个话路占用8bit。帧同步码是在24路的编码之后加上1bit，因此每帧有8bit×24 + 1bit = 193bit。因为每秒采样8000次，因此采样频率为8000Hz，即采样周期为1/8000s = 125μs。所以T1的数据率为193bit/(125×10^-6s)= 1.544Mb/s

6.
- 解：
    - 整个传输过程的总时延 = 连接建立时延 + 源点发送时延 + 中间结点的发送时延 + 中间结点的处理时延 + 传播时延
    - 源点要将L位的报文分割成分组，分组数 = L/p，每个分组的长度为(h+p)，源点要发送的数据量 = (h+p)L/p，所以源点的发送时延 = (h+p)L/(pb)秒
    - 每个中间结点的发送时延 = (h+p)/b秒，源点和终点之间的线路数为k，所以有k-1个中间结点，因此中间结点的发送时延 = (h + p)(k - 1)/b秒
    - 中间结点的处理时延 = m(k-1)秒，传播时延 = kd秒。
    - 所以源结点开始发送数据直至终点收到全部数据所需要的时间= s +(h +p)L/(pb)+(h+ p)(k- 1)/b + m(k- 1)+ kd秒。

错题总结：
- 注意区分「采样频率」和「信道频率」
- 不同的数据交换方式有不同的性能。为了使数据在网络中的传输时延最小，首选的交换方式是电路交换；为保证数据无差错地传送，不应选用的交换方式是电路交换；在出错率很高的传输系统中，选用数据报方式更合适
- 电路交换是真正的物理线路交换，例如电话线路；**虚电路交换是多路复用技术，每条物理线路可以进行多条逻辑上的连接**。虚电路不只是临时性的，它提供的服务包括永久性虚电路(PVC)和交换型虚电路(SVC)，其中前者是一种提前定义好的、基本上不需要任何建立时间的端点之间的连接，而后者是端点之间的一种临时性连接，这些连接只持续所需的时间，并且在会话结束时就取消这种连接。数据报服务是无连接的，不提供可靠性保障，也不保证分组的有序到达。
- 虚电路服务需要有建立连接的过程，每个分组使用短的虚电路号，属于同一条虚电路的分组按照同一路由进行转发，分组到达终点的顺序与发送顺序相同，可以保证有序传输，不需要为每条虚电路预分配带宽

#### (3)传输介质及其特性

定义：
- 传输介质也称传输媒体，它是数据传输系统中发送设备和接收设备之间的物理通路
- 传输信息所利用的一些传输媒体，如双绞线、光缆、无线信道等，**并不在物理层协议之内而在物理层协议之下**，因此有人将物理媒体称作第0层（物理层规定了电气特性，所以能识别所传送的是比特流。）
- 传输介质可以分为：导向性传输介质和非导向性传输介质
    - 导向性传输介质：铜线，光纤
    - 非导向性传输媒介质：空气，真空，海水

双绞线：
- 把两根互相绝缘的铜导线并排放在一起，然后用规则的方法绞合起来。绞合可减少对相邻导线的电磁干扰
- 双绞线的带宽取决于铜线的粗细和传输的距离
- 从用户电话机到交换机的双绞线称为用户线或用户环路
- 非屏蔽双绞线UTP：无屏蔽层的双绞线
- 屏蔽双绞线STP：为了提高双绞线抗电磁干扰的能力，可以在双绞线的外面再加上一层用金属丝编织成的屏蔽层
- 优缺点：价格便宜，通信距离短，长距离的模拟传输需要放大器放大衰减信号，对于数字传输则要用**中继器**将失真的信号整形

同轴电缆：
- 同轴电缆由内导体铜质芯线（单股实心线或多股绞合线）、绝缘层、**网状编织的外导体屏蔽层**（也可以是单股的）以及保护塑料外层所组成
- 基带同轴电缆：传送基带数字信号，用于局域网
- 带宽同轴电缆：传送宽带信号，用于有线电视系统
- 优缺点：由于外导体屏蔽层的作用，同轴电缆具有很好的抗干扰特性，被广泛用于传输较高速率的数据，其传输距离比双绞线更远，价格也更高

光纤：
- 光纤通信就是利用光导纤维（以下简称为光纤）传递光脉冲来进行通信。有光脉冲相当于1，而没有光脉冲相当于0
- 特点：
  - 传输损耗小，中继距离长，对远距离传输特别经济。
  - 抗雷电和电磁干扰性能好。
  - 无串音干扰，保密性好，也不易被窃听或截取数据。
  - 体积小，重量轻。
- 分类：

名称|定义|光源|特点
:-:|-|-|-
单模光纤|一种在**横向模式**直接传输光信号的光纤|定向性很好的激光二极管|**衰耗小**，适合远距离传输
多模光纤|有**多种**传输光信号模式的光纤|发光二极管|**易失真**，适合近距离传输

联动：
- 10BASE-T是传送**基带信号**的**双绞线以太网**，**T表示采用双绞线**，现10BASE-T采用的是**无屏蔽双绞线(UTP)**，传输速率是10Mb/s。物理上采用星型拓扑，逻辑上总线型，每段双绞线最长为100m，采用**曼彻斯特编码**，采用CSMA/CD介质访问控制

**王道习题：**

一轮标记题：1 3 4 7

二轮重做：7 9 ~ 12

错题总结：
- 传统以太网采用广播的方式发送信息，同一时间只允许一台主机发送信息，否则各主机之间就会形成冲突，因此主机间的通信方式是半双工
- 同轴电缆比双绞线的传输速率更快，得益于其高屏蔽性，从而既有很高的带宽，又有很好的抗噪性
- **光纤的直径减小到与光线的一个波长相同时，光纤就如同一个波导，光在其中没有反射，而沿直线传播，这就是单模光纤**

#### (4)信道复用技术

- 复用是通信技术中的一个重要概念
- 复用就是通过一条物理线路同时传输多路用户的信号
- 当网络中传输媒体的传输容量大于多条单一信道传输的总通信量时，可利用复用技术在一条物理线路上建立多条通信信道来充分利用传输媒体的带宽
- 信道划分的实质就是通过分时、分频、分码等方法把原来的一条广播信道，逻辑上分为几条用于两个结点之间通信的互不干扰的子信道，实际上就是把广播信道转变为点对点信道。具体见3-6（介质访问控制协议）

#### (5)数字传输系统

早期的数字传输系统存在的缺点：
1. 速率标准不统一
2. 不是同步传输

SDH/SONET标准的制定，使北美、日本和欧洲这三个地区三种不同的数字传输体制在STM-1等级上获得了统一。各国都同意将这一速率以及在此基础上的更高的数字传输速率作为国际标准。这是第一次真正实现了数字传输体制上的世界性标准。现在SDH/SONET标准已成为公认的新一代理想的传输网体制，因而对世界电信网络的发展具有重大的意义。SDH标准也适合于微波和卫星传输的技术体制

#### (6)宽带接入技术

ADSL技术：
- 非对称数字用户线ADSL技术就是用数字技术对现有的模拟电话用户线进行改造，使它能够承载带宽业务（**这里的非对称体现在上行与下行的带宽不对称**）
- 标准模拟电话信号的频带被限制在300 ~ 3400Hz的范围内，但用户线本身实际可通过的信号频率仍然超过1MHz
- ADSL技术就把0 ~ 4kHz低端频谱留给传统电话使用，而把原来没有被利用的高端频谱留给用户上网使用
- ADSL在用户线（铜线）的两端各安装一个**ADSL调制解调器**
- ADSL的传输距离
    - ADSL的传输距离取决于数据率和用户线的线径（用户线越细，信号传输时的衰减就越大）
    - ADSL所能够得到的最高数据传输速率于实际的用户线上的信噪比密切相关。
    - 例如：0.5毫米线径的用户线，传输速率为1.5 ~ 2.0 Mb/s时可传送5.5公里，但当传输速率提高到6.1Mb/s时，传输距离旧缩短为3.7公里。如果把用户线的线径减小到0.4毫米，那么在6.1Mb/s的传输速率下就只能传送2.7公里

**光纤***同轴*混合网（HFC网）：
- HFC网是在目前覆盖面很广的有线电视网CATV的基础上开发的一种居民宽带接入网
- HFC网的主干线采用**光纤**
- 每个家庭要安装一个用户接口盒，用户接口盒UIB（user interface box）要提供三种连接，即：
    - 使用**同轴电缆**连接到机顶盒（set-top box），然后再连接到用户的电视机
    - 使用**双绞线**连接到用户的电话机
    - 使用**电缆调制解调器**连接到用户的计算机

FTTx技术：
- FTTx是一种实现宽带接入网的方案，代表多种宽带光纤接入方式：
    - 光纤到户FTTH（fiber to the home）：光纤一直铺设到用户家庭，可能是居民接入网最后的解决方法
    - 光纤到大楼FTTB（fiber to the building）：光纤进入大楼后就转换为电信号，然后用电缆或双绞线分配到各用户
    - 光纤到路边FTTC（fiber to the curb）：光纤铺到路边，从路边到各用户可使用**星形结构双绞线**作为传输媒体

#### (7)其他

电路交换、报文交换与分组交换：
- 电路交换：需要建立一条专用的数据通信路径，这条路径上可能包含许多中间节点。这条通信路径在整个通信过程中将被独占，直到通信结束才会释放资源。电路交换**适合实时性要求较高的大量数据传输的情况**
- 报文交换（注意，此处的“报文”与UDP中的“报文”不是同一个意思！）：以报文作为数据传输单位，携带有源地址和目的地址等信息。报文交换主要使用在早期的电报通信网中，现在较少使用，通常被较先进的分组交换方式所取代
- 分组交换：分组交换根据其通信子网向端点系统提供的服务，**还可进一步分为面向连接的虚电路方式和无连接的数据报方式**。这两种服务方式都由**网络层**提供。要注意数据报方式和虚电路方式是分组交换的两种方式

#### 本章小结

什么是基带传输、频带传输和宽带传输?三者的区别是什么?
- 基带传输（数据→数字）：通常用于**局域网**；常用的编码方法有不归零编码和曼彻斯特编码
- 频带传输（数据→模拟）：用数字信号对特定频率的载波进行调制（数字调制)，将其变成适合于传送的信号后再进行传输，这种传输方式就是频带传输。远距离传输或无线传输时，数字信号必须用频带传输技术进行传输。利用频带传输，不仅解决了电话系统传输数字信号的问题，而且可以实现多路复用，进而提高传输信道的利用率。同样传输1010，经过调制，一个码元对应4个二进制位，假设码元A代表1010，那么在模拟信道上传输码元A就相当于传输了1010，这就是频带传输。**借助频带传输，可将链路容量分解成两个或多个信道，每个信道可以携带不同的信号，这就是宽带传输**。宽带传输中所有的信道能同时互不干扰地发送信号，链路容量大大增加。比如把信道进行频分复用，划分为2条互不相关的子信道，分别在两条子信道上同时进行频带传输，链路容量就大大增加了，这就是宽带传输

什么是同步通信和异步通信？
- 同步通信的通信双方必须先建立同步，即双方的时钟要调整到同一个频率。收发双方不停地发送和接收连续的同步比特流。主要有两种同步方式：一种是全网同步，即用一个非常精确的主时钟对全网所有结点上的时钟进行同步；另一种是准同步，即各结点的时钟之间允许有微小的误差，然后采用其他措施实现同步传输。**同步通信数据率较高，但实现的代价也较高**
- 异步通信在发送字符时，所发送的字符之间的时间间隔可以是任意的，但接收端必须时刻做好接收的准备。发送端可以在任意时刻开始发送字符，因此必须在每个字符开始和结束的地方加上标志，即开始位和停止位，以便使接收端能够正确地将每个字符接收下来。异步通信也可以帧作为发送的单位。这时，帧的首部和尾部必须设有一些特殊的比特组合，使得接收端能够找出一帧的开始（即帧定界）。**异步通信的通信设备简单、便宜，但传输效率较低（因为标志的开销所占比例较大)**

如何提高信息传输速率？
- 要么设法提高传输线路的带宽，要么设法提高所传信道的信噪比，此外没有其他任何办法

### <a name="19">（三）数据链路层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)数据链路层功能和设计要点

数据链路层在网络体系结构中的地位：
- 为网络层提供服务
    - 无确认的无连接服务【适用于实时通信或误码率较低的通信信道 - 以太网】
    - 有确认的无连接服务【适用于误码率较高的通信信道 - 无线通信】
    - 有确认的有连接服务【适用于对可靠性，实时性要求较高的场合】
- 使用**点对点**信道的数据链路层
    - **三个重要问题：封装成帧，透明传输，差错检测**
- 使用**广播**信道的数据链路层
    - 共享式以太网的媒体接入控制协议CSMA/CD
    - 802.11局域网的媒体接入控制协议CSMA/CA
- 数据链路层的互连设备
    - 网桥和交换机的工作原理
    - 集线器（物理层互连设备）与交换机的区别

**组帧（封装成帧）：**
- 封装成帧是指数据链路层给上层交付的协议数据单元添加**帧头和帧尾**使之成为帧
    - 帧头和帧尾中包含有重要的控制信息
    - 帧头和帧尾的作用之一就是帧定界
- 为了提高帧的传输效率，应当使帧的数据部分的长度尽可能大些
- 考虑到差错控制等多种因素，每一种数据链路层协议都规定了帧的数据部分的长度上限，即**最大传送单元MTU**
- 透明传输是指**数据链路层对上层交付的传输数据没有任何限制**，就好像数据链路层不存在一样
- 组帧方法：【目前最常用的是比特填充法+违规编码法】
    - 字符计数法	
        - 在帧头部使用一个计数字段来标明帧内字符数
        - 缺点：如果计数字段出错，就失去了帧定界划分的依据【计数字段的脆弱性】
    - 使用字符填充的首位定界法	
        - SOH表示帧的首部开始，EOT表示帧的结束
        - 在特殊字符前面填充一个转义字符ESC来区分
        - 接收方收到数据会删除ESC然后得到原来的数据
        - 缺点：实现复杂与不兼容
    - 使用比特填充的首位标志法	
        - 使用01111110表示一帧的开始和结束（6个1）
        - 在数据中如果出现连续的5个1，就插入一个0
        - 很容易用硬件实现，性能优于字符填充法
        违规编码法	
        - 在**物理层进行比特编码**时，通常采用违规编码法
        - 局域网IEEE 802标注采用这个方法
        - 违规编码法不需要填充技术，只适合于采用冗余编码的特殊编码环境
可靠传输
**王道习题：**

大题：

1.
- 答：
    1. 5 A B ESC FLAG（二进制）
    2. FLAG A B ESC ESC ESC FLAG FLAG（二进制）
    3. 01111110 01000111 11**0**100011 111**0**00000 011111**0**10 01111110

#### (2)错误检测和纠正（408压根没考过这个，961不知道考不考，先不复习）

#### (3)基本数据链路协议，包括：停止-等待协议、后退N帧协议和选择重传协议；

可靠传输的基本概念：
- 数据链路层向上层提供的服务类型
    - 不可靠传输服务：仅仅丢弃有误码的帧，其他什么也不做
    - 可靠传输服务：想办法实现发送端发送什么，接收端就收到什么
- 一般情况，有线链路的误码率比较低，为了减小开销，并不要求数据链路层向上提供可靠传输服务。即使出现误码，可靠传输由上层处理
- 传输差错还包括分组丢失，分组失序，分组重复
    - 分组丢失，分组失序以及分组重复一般不会出现在数据链路层，而出现在上层
- 可靠传输服务并不局限于数据链路层，其他各层也可以实现可靠传输
- 捎带确认：将确认帧捎带在一个回复的数据帧中
- 自动重传请求（ARQ）→连续ARQ协议：通信中用于处理信道所带来的差错
- 信道吞吐率 = 信道利用率 × 发送方的发送速率

停止-等待协议（SW）：
- 从滑动窗口机制的角度看，停止-等待协议相当于发送窗口和接收窗口大小均为1的滑动窗口协议
- ①数据帧错（误码）；②确认帧错（无数据帧没法发、丢失了、迟到了）
- 需要给数据分组编号，只需要1个比特编号，即编号0和1
- 超时计时器设置的重传时间一般略大于“从发送方到接收方的平均往返时间”
  - 在数据链路层点对点的往返时间好确认，重传时间好确认
    - 在传输层，由于端到端往返时间不确定，重传时间不好确认

后退N帧协议（GBN）：
- 为了减少开销，GBN协议规定接收端不一定每收到一个正确的数据帧就必须立即发回一个确认帧，而可以**在连续收到好几个正确的数据帧后，才**对最后一个数据帧发确认信息，或者可在自己有数据要发送时才将对以前正确收到的帧加以**捎带确认**。这就是说，对某一数据帧的确认就表明该数据帧和此前所有的数据帧均已正确无误地收到
- 若采用n比特对帧编号，**则其发送窗口的尺寸W_T应满足1 ≤ W_T ≤ 2 ^ n - 1**。若发送窗口的尺寸大于2 ^ n - 1，则会造成接收方无法分辨新帧和旧帧
- 由于接受窗口仍为1，因此可以保证数据的有序接收

选择重传协议（SR）：
- 在选择重传协议中，接收窗口和发送窗口的大小是相同的（选择重传协议是对单帧进行确认，所以发送窗口大于接收窗口会导致溢出，发送窗口小于接收窗口没有意义)，且最大值都为序号范围的一半，若采用n比特对帧编号，则**需要满足:W_Tmax = W_Rmax = 2 ^ (n - 1)**
- 所需缓冲区的数目等于窗口的大小

**王道习题：**

一轮标记题：3 8 13 14 15

二轮重做：3 4 8 10 13 15

大题：1 

1.
- 答：发送方:01234567012345670，发送方发送0 ~ 5号共6个数据帧时，因发送窗口已满，发送暂停。接收方收到所有数据帧，对每个帧都发送确认帧，并期待后面的6、7、0号帧。若所有的确认帧都未到达发送方，经过发送方计时器控制的超时时间后，发送方再次发送之前的6个数据帧，**而接收方收到0号帧后，无法判断是新的数据帧还是旧的重传的数据帧**。

2.
- 解：300bit

3.
- 解：
    - RTT = 250×2 = 500ms = 0.5s. 一个帧的发送时间等于2000bit / (100kb/s) = 20 × 10 ^ -3s
    - 一个帧发送完后经过一个单程时延到达接收方，再经过一个单程时延发送方收到应答，从而可以继续发送，因此要达到传输效率最大，就是不用等确认也可继续发送帧。设窗口值等于x，令2000bit × x / (100kb/s) = 20 × 10 ^ -3s + RTT = 0.52s，得x=26。要取得最大信道利用率，窗口值是26即可，因为在此条件下，可以不间断地发送帧，所以发送速率保持在100kb/s
    - 因此帧的顺序号应为5位。在使用后退N帧ARQ的情况下，最大窗口值是31，大于26，可以不间断地发送帧，此时信道利用率是100%

 4 ~ 7.
- 待做

错题总结：
- 计算信道利用率：推荐用**画图法**
- 发送窗口的大小 ≤ 窗口总数 - 1
- 数据帧长度不确定时，为保证信道利用率达到最高，**应以最短的帧长计算**

#### (4)滑动窗口协议

GBN和SR，就是滑动窗口协议与请求重传技术的结合

#### (5)点对点协议PPP（408没考过，这年头谁还拨号上网）

- 广域网：通常是指覆盖范围很广（远超一个城市的范围）的长距离网络，它是因特网的核心部分
    - 广域网由**一些结点交换机（注意不是路由器）及连接这些交换机的链路**组成。结点交换机的功能是将分组存储并转发。结点之间都是点到点连接，但为了提高网络的可靠性，通常一个结点交换机往往与多个结点交换机相连（一言以蔽之，**局域网——路由器——结点交换机——结点交换机——路由器——个人主机**）
- 互联网：互联网不等于广域网，互联网可以连接不同类型的网络（既可以连接局域网，又可以连接广域网)，通常使用路由器来连接
- 以太网：802.3局域网称为以太网
- 局域网和广域网的区别：

区别|广域网|局域网
-|-|-
覆盖范围|很广，通常跨区域|较小，通常在一个区域内
连接方式|结点之间都是**点到点连接**，但为了提高网络的可靠性，一个结点交换机往往与多个节点交换机相连|普遍采用**多点接入**技术
OSI参考模型层次|三层：物理层，数据链路层，**网络层**|两层：物理层，数据链路层
着重点|强调资源共享，通信子网主要使用分组交换技术|强调数据传输

- 局域网和广域网的联系：
    1. 广域网和局域网都是互联网的重要组成构建，从互联网的角度来看，二者平等！**（不是包含关系）**
    2. 连接到一个广域网和一个局域网上的主机在该网内进行通信，只需要使用其网络的物理地址

- PPP (Point-to-Point Protocol）是使用串行线路通信的**面向字节**的协议，该协议应用在直接连接两个结点的链路上。设计的目的主要是用来通过**拨号或专线方式**建立点对点连接发送数据，使其成为**各种主机、网桥和路由器之间简单连接**的一种共同的解决方案
    - **PPP和HDLC协议均是数据链路层协议**
    - HDLC是面向比特的协议，PPP协议是面向字节的协议
    - **PPP只支持全双工链路**
    - PPP协议不使用序号和确认机制，只保证无差错接收（CRC检验），而端到端差错检测由高层协议负责。HDLC协议的信息帧使用了编号和确认机制，能够提供可靠传输
  - **PPP协议的组成：**
    - 链路控制协议LCP：用于建立、配置以及测试数据链路的连接
    - 一套网络控制协议NCPs：其中的每一个协议支持不同的网络层协议
    - 一个将IP数据报封装到串行链路的方法
    - PPP帧：**标志字段F(7E) + 地址字段A(FF) + 控制字段C(03) + 协议字段（2字节）+ 信息字段（长度可变，大于等于0且小于等于1500）+ 帧检验序列FCS（2字节，即CRC里的冗余码，检验区为地址字段 + 控制字段 + 协议字段 + 信息字段）+ 标志字段F(7E)**，其中的7E就是上文的01111110
        - 注意：**因为PPP是点对点的，并不是总线形，所以无须采用CSMA/CD协议，自然就没有最短帧，所以信息段占0 ~ 1500字节，而不是46 ~ 1500字节**。另外，当数据部分出现和标志位一样的比特组合时，就需要采用一些措施来实现透明传输
    - PPP协议的状态变迁：从设备之间无链路开始，到先建立物理链路，再建立链路控制协议LCP链路。经过鉴别后再建立网络控制协议NCP链路，然后才能交换数据
        - 由此可见：PPP协议不是纯粹的数据链路层的协议，它还包含了物理层和网络层的内容。
  - PPP两端的网络层可以运行不同的网络层协议，但仍然能使用同一个PPP进行通信
    - PPP支持PAP和CHAP认证
        - CHAP的安全性更高
        - PAP在传输密码时是明文，CHAP在传输过程中传输哈希值
        - PAP认证通过两次握手实现，CHAP通过三次握手
    - PPP可用于拨号连接，支持动态分配IP地址

**王道习题：**

二轮重做：1 5 6 8

错题总结：
- 广域网不等于互联网。互联网可以连接不同类型的网络（既可以连接局域网，又可以连接广域网)，通常使用路由器来连接。广域网是单的网络，通常使用结点交换机连接各台主机（或路由器），而不使用路由器连接网络。其中**结点交换机在单个网络中转发分组**，而路由器在多个网络构成的互联网中转发分组
- 以太网是局域网的一种实现形式，其他实现形式还有令牌环网、FDDI（光纤分布数字接口，IEEE 802.8）等

#### (6)介质访问控制协议，包括介质访问控制基本概念、协议分类、CSMA/CD协议；

信道划分介质访问控制：
- 频分多路复用：分频
- 时分多路复用：分时。可分为同步时分多路复用和异步时分多路复用（又称统计时分复用）
  - 同步时分多路复用是一种静态时分复用技术，预先分配时间片
    - 异步时分多路复用是一种动态时分复用技术，动态分配时间片
    - FDM适合传输模拟信号，TDM适合传输数字信号
- 波分多路复用：光纤，分频
- 码分多路复用：
    - CDM是另一种共享信道的方法。
    - 由于CDM主要用于多址接入，常用的名词为码分多址CDMA
    - 与FDM和TDM不同，CDM的每一个用户可以在同样的时间使用同样的频带进行通信
    - 由于各用户使用经过特殊挑选的不同码型，因此各用户之间不会造成干扰
    - CDM最初用于军事通信，这种系统所发送的信号有很强的抗干扰能力频谱类似于白噪声，不易被敌人发现
    - 随着技术的进步，CDMA设备的价格和体积都大幅度下降，因而现在已广泛用于民用的移动通信中
    - CDMA中，每一个比特时间再划分为m个短的间隔，称为码片
    - 通常m=64或128
    - 使用CDMA的每一个站被指派一个唯一的m bit码片序列
        - *一个站如果要发送比特1，则发送他自己的m bit码片序列*
        - *一个站如果要发送比特0，则发送他自己的m bit码片序列的二进制反码*
    - 码片序列的挑选原则：
        1. 分配给每个站的码片序列**必须各不相同**，实际采用伪随机序列
        2. **分配给每个站的码片序列必须相互正交（内积=0）**‘
    - **具体到如何计算：序列中的1对应1，0对应-1，将对应站的码片序列与信道上的序列求规格化内积（也就是算完内积求平均），若计算结果为数值1，则被判断的站发送了比特1；若计算结果为数值-1，则被判断的站发送了比特0；若计算结果为数值0，则被判断的站未发送数据**

**随机访问协议分类【胜利者通过争用获得信道，从而获得信息的发送权，又称争用型协议】：**
- 纯ALOHA协议：纯ALOHA系统采用的重传策略是让各站等待一段随机的时间，然后再进行重传。若再次发生碰撞，则需要再等待一段随机的时间，直到重传成功为止
- **时隙**ALOHA协议
    - 时隙ALOHA协议把所有各站在时间上同步起来，并将时间划分为一段段等长的时隙(Slot)，规定只能在每个时隙开始时才能发送一个帧。从而避免了用户发送数据的随意性，减少了数据产生冲突的可能性，提高了信道的利用率
    - 帧到达 = 帧准备发送
    - 碰撞之后的重传策略与纯ALOHA类似
- CSMA（载波监听多点访问）
    - 并不适用确认机制
    - 1-坚持CSMA：坚持监听，且空闲时发送概率为1
    - 非坚持CSMA：如果信道忙，不坚持监听，而是等待一个随机的时间
    - p-坚持CSMA：
        - 如果信道忙，就持续监听（p-坚持CSMA适用于时隙信道，此处持续侦听就是推迟到下一个时隙再侦听）
        - 如果信道空闲，以概率p发送数据，以概率1-p推迟到下一个时隙。下一个时隙亦是如此，这个过程一直持续到数据发送成功或因其他结点发送数据而检测到信道忙为止，若是后者，则等待下一个时隙再重新开始侦听
        - 三者的比较：

信道状态|1-坚持CSMA|非坚持CSMA|p-坚持CSMA
-|-|-|-
空闲|立即发送数据|立即发送数据|以概率P发送数据，以概率1-p推迟到下一个时隙
忙|继续坚持侦听|放弃侦听，等待一个随机的时间再侦听|持续侦听，直到信道空闲

**CSMA/CD（载波监听多点访问/碰撞检测）：**
- 是对CSMA的改进，是早期共享信道以太网适用的信道访问控制协议，适用于总线形网络或**半双工**网络环境
- 流程：“先听后发，**边听边发**，冲突停发，随机重发”：
    1. 适配器从网络层获得一个分组，封装成以太网帧，放入适配器的缓存，准备发送
    2. 如果适配器侦听到信道空闲，那么它开始发送该帧。如果适配器侦听到信道忙，那么它持续侦听直至信道上没有信号能量（**空闲9.6μs/96比特时间，即帧间间隔**），然后开始发送该帧
    3. 在发送过程中，适配器持续检测信道。若一直未检测到碰撞，则顺利地把这个帧发送完毕。若检测到碰撞，则中止数据的发送，并发送一个拥塞信号，以让所有用户都知道
    4. 在中止发送后，适配器就执行**指数退避算法**，等待一段随机时间后返回到步骤2
- 站A在发送帧后至多经过时间2τ（端到端传播时延的2倍）就能知道所发送的帧有没有发生碰撞，因此**把以太网端到端往返时间2τ称为争用期（又称冲突窗口或碰撞窗口）**。只有经过争用期这段时间还未检测到碰撞时，才能确定这次发送不会发生碰撞
- *最小帧长 = 总线传播时延 × 数据传输速率 × 2*
- 以太网规定取51.2μs为争用期的长度。对于10Mb/s的以太网，在争用期内可发送512bit，即64B。因此，**以太网规定最短帧长为64B**，凡长度小于64B的帧都是由于冲突而异常中止的无效帧，收到这种无效帧时应立即丢弃。如果只发送小于64B的帧，**那么需要在MAC子层中于数据字段的后面加入一个整数字节的填充字段**，以保证以太网的MAC帧的长度不小于64B
- **截断二进制指数退避算法**【可使重传需要推迟的平均时间随重传次数的增大而增大（这也称**动态退避**），因而能降低发生碰撞的概率，有利于整个系统的稳定】
    1. 确定基本退避时间，一般取两倍的总线端到端传播时延2τ（即争用期）
    2. 定义参数k，它等于重传次数，**但k不超过10，即k=min(重传次数,10)**。当重传次数不超过10时，k等于重传次数；当重传次数大于10时，k就不再增大而一直等于10（这个条件往往容易忽略）
    3. 从离散的整数集合(0,1,...,2^k-1)中随机取出一个数r，重传所需要退避的时间就是r倍的基本退避时间，即2rτ
    4. 当重传达**16次**仍不能成功时，说明网络太拥挤，认为此帧永远无法正确发出，抛弃此帧并向高层报告出错（这个条件也容易忽略）
- 并不适用确认机制
- 总结！：
    - 帧的发送流程：封装成帧 → 载波监听（CS）→ 碰撞检测（CD） → 截断二进制指数退避算法 → 发送该帧 → 发送结束
    - 帧的接收流程：监听信道 → 信道活跃？ → 开始接收帧 → 接收完成？ → **帧太短？**（小于最短帧长则认为遭遇了碰撞）→ **地址正确？**（帧的目的MAC地址与接收方的MAC地址相同或是广播地址）→ **校验正确？**（使用CRC检查帧是否出现了误码）→ 接收该帧 → 接收结束

轮询访问——令牌传递协议：逻辑拓扑必须是环，适合负载很高的广播信道，证明了即使是广播信道也可通过介质访问控制机制使广播信道逻辑上变为点对点的信道，所以说数据链路层研究的是“点到点”之间的通信

**王道习题：**

一轮标记题：7 9 10 12 14 17 25 26 27 30

二轮重做：10 27

大题：3(考察时隙ALOHA)

1.
- 答：
    - CSMA/CD是一种动态的介质随机接入共享信道方式，而TDM是一种静态的信道划分方式，所以从对信道的利用率来说，CSMA/CD用户共享信道，更灵活，信道利用率更高。TDM不同，它为用户按时隙固定分配信道，**用户没有数据传送时，信道在用户时隙就浪费了**
    - CSMA/CD让用户共享信道，因此同时有多个用户需要使用信道时会发生碰撞，从而降低信道的利用率；而在TDM中，用户在分配的时隙中不会与其他用户发生冲突
    - 对局域网来说，连入信道的是相距较近的用户，因此通常信道带宽较大。使用TDM方式时，用户在自己的时隙中没有发送的情况更多，不利于信道的充分利用
    - 对于计算机通信来讲，突发式的数据更不利于使用TDM方式

2.
- 解：100bit

3.
- 解：50 / 8000 = 0.00625

4 ~ 8.
- 待做

错题总结：
- 王道第10题，**本质就是一个初中物理：s = vt**，现在v增加了，那么要么增加s，要么减少t！而t，即传播时延，又存在一个s = vt，传播速率一般是不会增加或减少的，由此可知，**传播时延与链路距离成正比**

#### (7)以太网，包括MAC地址、IEEE局域网标准、以太网、高速以太网技术；

局域网的基本概念和体系结构：
- 基本概念：局域网是指在一个较小的地理范围（如一所学校）内，将各种计算机、外部设备和数据库系统等通过双绞线、同轴电缆等连接介质互相连接起来，组成资源和信息共享的计算机互联网络。
- 三要素：拓扑结构、传输介质、介质访问控制方式
    - 常见拓扑结构：①星形结构；②环形结构；③总线形结构；④星形和总线形结合的复合型结构
    - 常用传输介质：双绞线、铜缆和光纤等多种传输介质，其中双绞线为主流传输介质
    - 常用介质访问控制方式：CSMA/CD、令牌总线和令牌环，其中前两种方法主要用于总线形局域网，令牌环主要用于环形局域网
- 简单了解：前面我们知道有TCP/IP、OSI，现在还有个IEEE 802模型，其定义的局域网只对应OSI的数据链路层 + 物理层，且数据链路层 = LLC子层 + MAC子层（由于以太网在局域网市场中取得垄断地位，几乎成为局域网的代名词，而802委员会制定的LLC子层作用已经不大，因此现在许多网卡仅装有MAC协议而没有LLC协议）

**以太网与IEEE 802.3：**
- 以太网的一系列关键词：**逻辑拓扑是总线形结构**；物理拓扑是星形或拓展星形结构；基带信号；CSMA/CD；广播和组播；无连接服务；曼彻斯特编码
- 以太网的传输介质与网卡：

参数|10BASE5|10BASE2|10BASE-T|10BASE-FL
-|-|-|-|-
传输媒体|**基带同轴电缆（粗缆）**|**基带同轴电缆（细缆）**|**非屏蔽双绞线**|**光纤对(850nm)**
编码|曼彻斯特编码|曼彻斯特编码|曼彻斯特编码|曼彻斯特编码
物理拓扑结构|总线形|总线形|**星形**|**点对点**
最大段长|500m|185m|100m|2000m
最多结点数目|100|30|2|2

- **以太网的MAC帧：**
    - MAC地址也叫物理地址
    - MAC地址长6字节，一般用由连字符（或冒号）分隔的12个十六进制数表示，如02-60-8c-e4-b1-21。高24位为厂商代码，低24位为厂商自行分配的网卡序列号
    - 以太网V2的MAC帧：前导码（7字节的前同步码 + 1字节的帧开始定界符，注意，这一部分不属于MAC帧）+ **目的地址（6字节）+ 源地址（6字节）+ 类型（2字节，指出数据域中携带的数据应交给哪个协议实体处理）+ 数据（46 ~ 1500字节）+ 填充 + 校验码**（采用CRC，校验范围是整个MAC帧但不包括自己）
    - 以太网802.3的MAC帧：类型 → 长度/类型
    - 区分：不同的Type字段值可以用来区别这两种帧，当Type字段值小于等于1500（或者十六进制的0x05DC）时，帧使用的是EEE802.3格式。当Type字段值大于等于1536（或者十六进制的0x0600）时，帧使用的是V2格式。以太网中大多数的数据帧使用的是V2格式
- 高速以太网：
    - 100BASE-T以太网：基本与10BASE-T一致，但速率为100Mb/s。可在全双工方式下工作而无冲突发生，在全双工方式下不使用CSMA/CD协议；帧间时间间隔从原来的9.6μs改为现在的0.96μs
    - 吉比特以太网：又称千兆以太网，允许在1Gb/s速率下用全双工和半双工两种方式工作
    - 10吉比特以太网：10吉比特以太网不再使用铜线而**只使用光纤**作为传输媒体。10吉比特以太网**只工作在全双工方式**，因此没有争用问题，也不使用CSMA/CD协议

**VLAN基本概念与基本原理：**

- 802.3ac标准定义了支持VLAN的以太网帧格式的扩展。它在以太网帧中插入一个4字节的标识符（**插入在源地址字段和类型字段之间**)，称为VLAN标签，用来指明发送该帧的计算机属于哪个虚拟局域网。插入VLAN标签的帧称为802.1Q帧，由于VLAN帧的首部增加了4字节，**因此以太网的最大帧长从原来的1518字节变为1522字节**
- VLAN标签的前两个字节置为0x8100，表示这是一个802.10帧。在VLAN标签的后两个字节中，前4位没有用，后12位是该VLAN的标识符VID，它唯一标识了该802.1Q帧属于哪个VLAN。**12位的VID可识别4096个不同的VLAN，但0和4095都不用来表示VLAN，因此用于表示VLAN的VID的有效取值范围是1 ~ 4094**。插入VID后，802.1Q帧的FCS必须重新计算
- 不同VLAN的主机之间的通信，需要通过上层的路由器

**王道习题：**

一轮标记题：4 5 8 9 10 11 13 16 17 20 22

二轮重做：4 10 16 17 20 22

错题总结：
- 在以太网中，如果一个结点要发送数据，那么它将以“广播”方式把数据通过作为公共传输介质的总线发送出去，连在总线上的所有结点（**包括发送结点**）都能“收听”到发送结点发送的数据信号
- T表示传输介质为双绞线，F表示光纤
- 链路聚合是解决交换机之间的宽带瓶颈问题的技术

#### (8)局域网互连技术，包括物理层及数据链路层互连技术、网桥概念和工作原理、局域网交换机工作原理；

- 网段：两个或多个以太网通过网桥连接后，就成为一个覆盖范围更大的以太网，而原来的每个以太网就称为一个网段
- 网桥：网桥工作在链路层的MAC子层，可以使以太网各网段成为隔离开的碰撞域（又称冲突域）
    - 如果把网桥换成工作在物理层的转发器，那么就没有这种过滤通信量的功能
    - 网桥具有路径选择的功能，例如：网络1和网络2通过网桥连接后，网桥接收网络1发送的数据帧，检查数据帧中的地址，如果是网络2的地址，那么就转发给网络2；如果是网络1的地址，**那么就将其丢弃，因为源站和目的站处在同一个网段，目的站能够直接收到这个帧而不需要借助网桥转发**
- **局域网**交换机（以太网交换机）：多端口网桥
    - 利用以太网交换机还可以方便地实现虚拟局域网VLAN，VLAN不仅可以隔离冲突域，而且可以隔离广播域
    - 以太网交换机的每个端口都直接与单台主机相连（网桥的端口往往连接到一个网段），并且一般都工作在**全双工方式**
    - 对于传统 10Mb/s 的共享式以太网，若共有N个用户，拥有N个端口的交换机的总容量就是N × 10Mb/s，这是交换机最大的优点
    - 以太网交换机主要采用两种交换模式：
        1. 直通式交换机，只检查帧的目的地址，这使得帧在接收后几乎能马上被传出去。这种方式速度快，但缺乏智能性和安全性，也无法支持具有不同速率的端口的交换
        2. 存储转发式交换机，先将接收到的帧缓存到高速缓存器中，并检查数据是否正确，确认无误后通过查找表转换成输出端口将该帧发送出去。如果发现帧有错，那么就将其丢弃。优点是可靠性高，并能支持不同速率端口间的转换，缺点是延迟较大
    - 以太网一般都具有多种速率的端口
    - 决定一个帧是应该转发到某个接口还是应该将其丢弃称为过滤。决定一个帧应该被移动到哪个接口称为转发。交换机的过滤和转发借助于交换表(switch table)完成
    - 自学习的过程见习题
    - 交换表中的每个表项都设有一定的有效时间，过期的表项会自动删除。这就保证了交换表中的数据符合当前网络的实际状况

**王道习题：**

一轮标记题：4 7 12 13 17

二轮重做：7 12 16 17

错题总结：
- 交换机能隔离冲突域，工作在全双工状态，使网络中多对结点同时通信，提高了网络的利用率，这是交换机的优点
- 直通交换方式是指以太网交换机可以在各端口间交换数据。它在输入端口检测到一个数据包时，检查该包的包头，获取包的目的地址，启动内部的动态查找表转换成相应的输出端口，在输入与输出交叉处接通，把数据包直通到相应的端口，实现交换功能。通常情况下，直通交换方式只检查数据包的包头即前14个字节，由于不需要考虑前导码，只需要检测目的地址的6B

#### (9)无线局域网(IEEE802.11)基本知识，包括CSMA/CA协议原理等。

无线局域网的组成：
- 有固定基础设施无线局域网：IEEE制定了无线局域网的802.11系列协议标准，802.11使用星形拓扑，其中心称为接入点AP，在MAC层使用CSMA/CA协议。使用802.11系列协议的局域网又称Wi-Fi
    - 802.11标准规定无线局域网的最小构件是基本服务集BSS。一个基本服务集覆盖的地理范围称为一个基本服务区BSA，无线局域网的基本服务区的范围直径一般不超过100m
    - *移动站A → AP1 →（有线）→ AP2 → 移动站B*
- 无固定基础设施移动自组织网络：又称自组网络(ad hoc network)。自组网络没有上述基本服务集中的AP，而是由一些平等状态的移动站相互通信组成的临时网络。各结点之间地位平等，中间结点都为转发结点，因此都具有路由器的功能
    - 自组网络和移动IP并不相同。移动IP技术使漫游的主机可以用多种方法连接到因特网，其核心网络功能仍然是基于固定网络中一直使用的各种路由选择协议。而自组网络是把移动性扩展到无线领域中的自治系统，具有自己特定的路由选择协议，并且可以不和因特网相连
- 无线网不能使用CSMA/CD的原因：
    1. 接收信号的强度往往会远小于发送信号的强度，因此若要实现碰撞检测，则硬件上的花费就会过大
    2. 在无线通信中，并非所有的站点都能够听见对方，即**存在“隐蔽站”问题**

**CSMA/CA（载波监听多点访问/碰撞避免）：**
- 是802.11局域网采用的无线信道访问控制协议
- 802.11局域网在使用CSMA/CA的同时，还使用链路层的ARQ方案
- 为了尽量避免碰撞，802.11规定，所有的站完成发送后，必须再等待一段很短的时间（继续监听）才能发送下一帧。这段时间称为帧间间隔IFS
- **当且仅当检测到信道空闲且这个数据帧是要发送的第一个数据帧时，才不使用退避算法**。其他所有情况都必须使用退避算法，具体为：①在发送第一个帧前检测到信道忙；②每次重传；③每次成功发送后要发送下一帧
- 退避算法简单总结：随机选取回退值，忙则不变，空闲（**检测到DIFS**）则自减，减至0则可以发送了
- 预约：信道预约不是强制性规定，各站可以自己决定使用或不使用信道预约。只有当数据帧长度超过某一数值时，使用RTS和CTS帧才比较有利

**CSMA/CD与CSMA/CA的区别:**
1. CSMA/CD可以检测冲突，但无法避免；CSMA/CA发送数据的同时不能检测信道上有无冲突，本结点处没有冲突并不意味着在接收结点处就没有冲突，只能尽量避免
2. 传输介质不同。CSMA/CD用于总线形以太网，CSMA/CA用于无线局域网802.11a/b/g/n等
3. 检测方式不同。CSMA/CD通过**电缆中的电压变化**来检测；而CSMA/CA采用**能量检测、载波检测和能量载波混合检测**三种检测信道空闲的方式

**802.11局域网的MAC帧：**
- 802.11局域网的MAC帧——数据帧：MAC首部（共30字节，很复杂）+ 数据部分（不超过2312字节）+ 帧检验序列FCS（4字节）
- IEEE 802.11数据帧有4种子类型，分别是IBSS、From AP、To AP 和 WDS，下面介绍的是中间的两种。注意，接受地址 ≠ 目的地址，发送地址 ≠ 源地址！

去往 AP|来自 AP|地址1|地址2|**地址3**|地址4
:-:|:-:|:-:|:-:|:-:|:-:
0|1|接收地址 = 目的地址|发送地址 = AP地址|**源地址**|~
1|0|接收地址 = AP地址|发送地址=源地址|目的地址|~

#### 本章小结

- 链路(Link) ≠ 数据链路(Data Link)，电路接通 ≠ 数据链路接通
- 数据链路层使用PPP协议或CSMA/CD协议时，既然不保证可靠传输，为什么要对所传输的帧进行差错检验？
    - 如果在接收端不进行差错检测，那么接收端上交给主机的帧就可能包括在传输中出了差错的帧，而这样的帧对接收端主机是没有用处的
    - 数据链路层的可靠传输并不能保证网络层的传输也是可靠的
- 局域网、广域网、因特网：局域网和广域网都是通过**交换机**进行通信，而因特网由大局域网（广域网）和小局域网共同通过**路由器**相连
- 与OSI参考模型不同的是：在IEEE 802局域网参考模型中没有网络层。局域网中，在任意两个结点之间只有唯一的一条链路，不需要进行路由选择和流量控制
- 在IEEE 802.3标准以太网中，为什么说如果有冲突，那么冲突一定发生在冲突窗口内？或者说一个帧如果在冲突窗口内没有发生冲突，那么该帧就不会再发生冲突？
    - 一个数据帧在从结点A向**最远的结点**传输的过程中，如果有其他结点也正在发送数据，那么此时就会发生冲突，冲突后的信号需要经过冲突窗口时间后传回结点A，**结点A会检测到冲突**，所以说如果有冲突，那么一定发生在冲突窗口内
- 一个网段就是一个冲突域，一个局域网就是一个广播域
- 与传统共享式局域网相比，使用局域网交换机的交换式局域网为什么能改善网络的性能和服务质量？
    - 传统共享式局域网的核心设备是**集线器**，而交换式局域网的核心是**以太网交换机**。在使用共享式集线器的传统局域网中，在任何时刻只能有一个结点能够通过共享通信信道发送数据；在使用交换机的交换式局域网中，**交换机可以在它的多个端口之间建立多个并发连接，从而实现结点之间数据的并发传输**，有效地改善网络性能和服务质量
- 中继器、集线器、网桥和交换机这四种网络互联设备的区别与联系。
    - 中继器工作在物理层，用来连接两个速率相同且数据链路层协议也相同的网段
    - 集线器也工作在物理层，相当于一个多接口的中继器，**它可将多个结点连接成一个共享式的局域网，但任何时刻都只能有一个结点通过公共信道发送数据**
    - 网桥工作在数据链路层，可以互联不同的物理层、不同的MAC子层及不同速率的以太网。网桥具有过滤帧及存储转发帧的功能
    - 交换机工作在数据链路层，相当于一个多端口的网桥，**是交换式局域网的核心设备**。它允许端口之间建立多个并发连接，实现多个结点之间的并发传输。因此，交换机的每个端口结点所占用的带宽不会因为端口结点数目的增加而减少，且整个交换机的总带宽会随着端口结点的增加而增加

### <a name="20">（四）网络层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)网络层提供的数据报和虚电路服务

分组交换根据通信子网向端点系统提供的服务，分为数据报方式和虚电路方式：

属性|数据报服务|虚电路服务
-|-|-
连接的建立|不需要建立网络层连接|必须建立**网络层**连接
携带信息|每个分组在传输过程中都要携带源地址和目的地址|分组**只需要携带虚电路标识**
目的地址|每个分组都有完整的目的地址|**仅在建立连接阶段使用**，之后每个分组使用长度较短的虚电路号
路由选择|每个分组独立地进行路由选择和转发|属于同一条虚电路的分组按照同一路由转发
分组顺序|不保证分组的有序到达|保证分组的有序到达
可靠性|不保证可靠通信，**可靠通信应当由用户主机来保证**|**可靠通信应当由网络来保证**
对网络故障的适用性|出故障的节点丢失分组，其他分组路径选择发生变化时可正常传输|**所有经过故障节点的虚电路均不能正常工作**
差错处理和流量控制|由用户主机进行流量控制，不保证数据报的可靠性|**可由分组交换网负责，也可由用户主机负责**

网络层的主要功能：
- 异构网络互联	
    - 异构网络：数据链路层和物理层均不同的网络
    - 网络层的任务之一就是使异构网络实现互联
    - 网络互联通常是指用路由器进行网络互联和路由选择
- 路由选择与分组转发（路由器的两个功能）
    - 路由选择【确定哪一条路径】
    - 分组转发【当一个分组到达时所采取的动作】
- 拥塞控制
    - 拥塞：在通信子网中，因出现过量的分组而引起网络性能下降的现象。此时所有节点都来不及接受分组，而要丢弃大量分组
    - 判断是否拥塞的方法
        - 观察网络吞吐量与网络负载的关系
        - 随着通信子网负载的增加，吞吐量反而降低，即可能发生拥塞
        - 轻度拥塞--->拥塞---->死锁（吞吐量为0）
    - 拥塞控制的方法
        - 开环控制【静态】：事先考虑可能发生拥塞的情况，一旦系统启动，就不修改
        - 闭环控制【动态】：采用检测网络监视哪里发生了拥塞，动态调整网络系统运行
    - 流量控制和拥塞控制的区别：
        - 流量控制往往是指在发送端和接收端之间的点对点通信量的控制。流量控制所要做的是抑制发送端发送数据的速率，以便使接收端来得及接收
        - 拥塞控制必须确保通信子网能够传送待传送的数据，**是一个全局性的问题**，涉及网络中所有的主机、路由器及导致网络传输能力下降的所有因素

#### (2)IP协议及ARP协议

IP地址的定义：
- IPV4地址由 32 位正整数来表示，IP 地址在计算机是以二进制的方式处理的
- IP地址最大值 = 2^32 = 43亿左右	
- MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输
- 源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化
- **IP 地址并不是根据主机台数来配置的，而是以网卡**。像服务器、路由器等设备，都是有 2 个以上的网卡，因此：
    - 一台主机至少可以设置 1 个以上的IP
    - 一台路由器可以设置 2 个以上IP
    - 一块网卡也可以设置 2 个以上的IP

IPv4分组的格式：**4-1-8**
- 版本：占4比特，表示IP协议的版本。通信双方使用的IP协议的版本必须一致。目前广泛使用的IP协议版本号为4（即IPv4）
- **首部长度**：占4比特，表示IP数据报首部的长度。该字段的取值**以4字节为单位**
    - 最小十进制取值为5，表示IP数据报首部只有20字节固定部分
    - 最大十进制取值为15，表示IP数据报首部包含20字节固定部分和最大40字节可变部分。可选字段长度从1个字节到40个字节不等。用来支持排错、测量及安全等措施
- 区分服务：占8比特，用来获得更好的服务。一般情况下都不使用该字段
- **总长度**：占16比特，表示IP数据报的总长度（首部 + 数据载荷）。最大取值为十进制检验和的65535，**以1字节为单位**。但其实不能超过链路层的MTU值（例如以太网的1500B）
- 标识（Identification）：占16比特，**属于同一个数据报的各分片数据报应该具有相同的标识**。IP软件维持一个计数器，每产生一个数据报，**计数器值加1，并将此值赋给标识**，但它并不是序号（因为IP是无连接服务）
- 标志（Flags）：占3比特，各比特含义如下：
    - 最高位是保留位，必须为0
    - 中间的一位是DF，**只有当DF = 0时才允许分片**
    - 标志字段的最低位为 MF，**MF = 1表示后面还有分片，MF = 0表示最后**
- 片偏移：占13比特，指出分片数据报的数据载荷部分偏移其在原数据报的位置有多少个单位。片偏移**以8个字节为单位**
- 生存时间（TTL）：占8比特，表示IP数据报的生存时间
    - 最初以秒为单位，最大生存周期为255秒。路由器转发IP数据报时，将IP数据报首部中的该字段的值减去IP数据报在本路由器上所耗费的时间，若不为0就转发，否则就丢弃
    - 现在以“跳数”为单位，路由器转发IP数据报时，将IP数据报首部中的该字段的值减1、若不为0就转发，否则就丢弃
    - 因此，**IP数据报每经过一个路由器，路由器都要重新计算首部检验和**，因为某些字段（生存时间、标志、片偏移等）的取值可能发生变化
- 协议：占8比特，指明IPv4数据报的数据部分是何种协议数据单元。常用的一些协议和相应的协议字段值如下。

协议名称|ICMP|IGMP|**TCP**|**UDP**|IPv6|OSPF
-|-|-|-|-|-|-
协议字段值|1|2|**6**|**17**|41|89

- 首部检验和：占16比特，用来检测首部在传输过程中是否出现差错。比CRC检验码简单，称为因特网检验和
    - 由于IP层本身并不提供可靠传输的服务，并且计算首部校验和是一项耗时的操作，因此在IPv6中，路由器不再计算首部校验和
- 源IP地址和目的IP地址：各占32比特
- 可选字段：增加了IP数据报的功能，但这同时也使得IP数据报的首部长度成为可变的。这就增加了每一个路由器处理IP数据报的开销。实际上可选字段很少被使用
- 填充字段：确保首部长度为4字节的整数倍。使用全0进行填充

IPv4分片：
- 以太网MTU【最大传输单元】不超过1500
- DF=1时，分组的长度又超过MTU时，丢弃该分组，**并用ICMP差错报文向源主机报告**
- MF=1，表示接收到的分片不是最后一个分片
- 所有片中的**有效数据荷载都是8的倍数**【偏移值的单位是8B】
- 在目的主机中对分片后的数据报重组

**分类编制的IPV4地址：**
- 分类：
    - A类（1 ~ 126）（0）：1 + 7（网络号） + 24（主机号）
    - B类（128 ~ 191）（10）：2 + 14（网络号） + 16（主机号）
    - C类（192 ~ 223）（110）：3 + 21（网络号） + 8（主机号）
    - D类（224 ~ 239）（1110）：4 + 多播地址
    - E类（240 ~ 255）（1111）：4 + 保留为今后使用
- CIDR的网络前缀 = 类别位 + 网络号
- 特殊IP地址：见背60
- IP分类的优点
  - 简单明了、选路（基于网络地址）简单
- IP分类的缺点
  - 同一网络下没有地址层次，缺少地址层次的灵活性
  - C类地址254个太少了，B类地址65534个又太多了，不能很好的与显示网络匹配
  - 上述两个缺点都可用【CIDR】解决

**ARP协议**【IP地址到MAC地址的映射】：
- ARP主要内容
    - ARP广播只在子网中传播
    - MAC地址只具有本地意义，每当路由器将IP数据报转发到一个具体的网络时，都需要重新封装源MAC地址和目的MAC地址
    - 路由器在收到分组后，剥离该分组的数据链路层协议头，然后在分组被转发之前，给分组加上一个新的链路层协议头
    - **ARP请求**是**广播发送**【由于不知道目标设备在哪里】
    - **ARP响应**是**单播发送**
- ARP过程	
    - 目的主机在本局域网
        - 先在ARP高速缓存中查看有无目的IP地址与MAC地址的映射
        - 有，则把MAC地址写入MAC帧，然后通过局域网把该MAC帧发往此MAC地址
        - 无，则通过广播ARP请求分组，在获得目的主句的ARP响应分组后，将目的主机的IP地址与MAC地址写入ARP告诉缓存
    - 目的主机不在本局域网
        - 将IP分组发送给本局域网的路由器，**先通过上述方式**获得**路由器**的IP地址和MAC地址的映射关系

#### (3)划分子网和构造超网

**划分子网的IPV4地址：**
- 为什么要划分子网？
  - 两级IP地址分类的地址空间流动率有时很低，用子网划分的方法来改善这个问题
- 划分子网的好处
  - 增加子网的数量--->减少广播域的大小--->减少了主机的数量--->提高了IP地址的利用率
  - 不增加网络的数量
- 什么是子网划分？
  - 将主机地址分为两个部分【子网网络地址和子网主机地址】的过程
  - 未做子网划分的 ip 地址：网络地址＋主机地址
  - 做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）
- 如何得到网络地址？
  - 将子网掩码和 IP 地址按位计算 AND，就可得到网络号
- 默认子网掩码
  - A类：255.0.0.0
  - B类：255.255.0.0
  - C类：255.255.255.0
- 怎么进行子网划分？
  - 假设对 C 类地址进行子网划分
  - 网络地址 218.75.230.0，使用子网掩码 255.255.255.192 对其进行子网划分
  - C 类地址中前 24 位是网络号，最后 8 位是主机号
  - 根据子网掩码可知从 8 位主机号中借用 2 位作为子网号
  - 由于子网网络地址被划分成 2 位，那么子网地址就有 4 个，分别是 00、01、10、11

无分类编制的IPV4地址【CIDR】：
- 为什么引入CIDR
  - CIDR消除了**传统的A类，B类和C类地址，以及划分子网**的概念
- CIDR的作用？
  - CIDR是一种**归并技术**，可以把小的网络汇聚成大的**超网**
  - CIDR可以更加有效地分配IPV4的地址空间，并且可以在新的IPV6使用之前允许因特网的规模继续增长
CIDR的细节？
    - CIDR的**表示形式**，最小地址，最大地址，地址数量，聚合网络数量，地址掩码
    - 举例：128.14.35.7/20（表示形式）
        - 最小地址：128.14.32.0
        - 最大地址：128.14.47.255
        - 地址数量：2^(32-20)
        - 聚合C类网的数量：2^(32-20) ÷ 2^8
        - 地址掩码：255.255.240.0
- 路由聚合（构造超网）
  - 为了减小路由表的消耗，用路由聚合来聚合网络地址
  - 网络前缀越长，地址快越小，路由越具体
    - 最长前缀匹配：有多条路由可选的时候，**选择网络前缀最长的那条**

IPV4地址的应用规划：
- 定长的子网掩码
    - 使用同一个子网掩码来划分子网
    - 子网划分方式不灵活，只能划分出 2^n 个子网
    - 每个子网所分配的IP地址数量相同，容易造成IP地址浪费
- 变长的子网掩码
    - 使用不同的子网掩码来划分子网
    - 子网划分方式灵活：可以按需分配
    - 每个子网所分配的IP地址数量可以不同，尽可能减少对IP地址的浪费

#### (4)ICMP协议

**ICMP【互联网控制报文协议】：**
- 为了提高IP数据报交付成功的机会，在网络层使用了**网际控制报文协议**（ICMP）来让主机或路由器报告差错和异常情况。ICMP报文作为**IP层数据报的数据**，加上数据报的首部，组成IP数据报发送出去（即ICMP是IP层协议）
- ICMP报文的种类有两种，即ICMP差错报告报文和ICMP询问报文：
    - ICMP差错报告报文用于目标主机或到目标主机路径上的路由器向源主机报告差错和异常情况。共有以下5种类型：
        1. **终点不可达**。当路由器或主机不能交付数据报时，就向源点发送终点不可达报文
        2. **源点抑制**。当路由器或主机由于**拥塞**而丢弃数据报时，就向源点发送源点抑制报文，使源点知道应当把数据报的发送速率放慢
        3. **时间超过**。当路由器收到生存时间（TTL）为零的数据报时，除丢弃该数据报外，还要向源点发送时间超过报文。当终点在预先规定的时间内不能收到一个数据报的全部数据报片时，就把已收到的数据报片都丢弃，并向源点发送时间超过报文
        4. **参数问题**。当路由器或目的主机收到的数据报的首部中有的字段的值不正确时，就丢弃该数据报，并向源点发送参数问题报文
        5. **改变路由**（重定向）。路由器把改变路由报文发送给主机，让主机知道下次应将数据报发送给另外的路由器（可通过更好的路由）
    - 不应发送ICMP差错报告报文的几种情况如下:
        1. 对ICMP差错报告报文不再发送ICMP差错报告报文
        2. **对第一个分片的数据报片的所有后续数据报片都不发送ICMP差错报告报文**
        3. 对**具有组播地址**的数据报都不发送ICMP差错报告报文。
        4. 对具有特殊地址（如127.0.0.0或0.0.0.0）的数据报不发送ICMP差错报告报文 
    - ICMP询问报文有4种类型：**回送请求和回答**报文、**时间戳请求和回答**报文、地址掩码请求和回答报文、路由器询问和通告报文，最常用的是前两类
        1. ICMP回送请求报文是由主机或路由器向一个特定的目的主机发出的询问。收到此报文的主机必须给源主机或路由器发送ICMP回送回答报文。这种询问报文用来测试目的站**是否可达及了解其有关状态**
        2. ICMP时间戳请求报文是请某个主机或路由器回答当前的日期和时间。在ICMP时间戳回答报文中有一个32位的字段，其中写入的整数代表从1900年1月1日起到当前时刻一共有多少秒。这种询问报文用来进行**时钟同步和测量时间**
- ICMP的两个常见应用是分组网间探测PING（**用来测试两台主机之间的连通性**）和Traceroute（UNIX中的名字，在Windows中是Tracert，可以**用来跟踪分组经过的路由**）。其中**PING使用了ICMP回送请求和回答报文**，**Traceroute（Tracert）使用了ICMP时间超过报文**
    - 注意：**PING工作在应用层**，它直接使用网络层的ICMP，而未使用传输层的TCP或UDP；Traceroute/Tracert工作在网络层。

**王道习题：**

一轮标记题：10 13 15 17 20 25 27 

二轮重做：15 21 22 31 43 48(好好研究一下这个图！) 49 52 54 55

大题：

1.
- 解：40 * 1 - 5 * 4 = 20B

12.
- 解：
    1. 子网的划分结果为子网1:202.118.1.0/25，子网2:202.118.1.128/25；地址分配方案:子网1分配给局域网1，子网2分配给局域网2
    2. R1到互联网的路由**实质上相当于一个默认路由**(即*当某一目的网络IP地址与路由表中其他任何一项都不匹配时，匹配该默认路表项*)，默认路由一般写为0/0，即目的地址为0.0.0.0，子网掩码为0.0.0.0。对应的下一跳转发地址是202.118.2.2，转发接口是L0
    3. 目的IP：202.118.1.0；子网掩码：255.255.255.0；下一跳IP：202.118.2.1；接口：L0

13.
- 待做

错题总结：
- 硬件地址只具有本地意义，因此每当路由器将IP数据报转发到一个具体的网络中时，都需要重新封装源硬件地址和目的硬件地址。
- NAT的表项需要管理员添加，这样才能控制一个从内网到外网的网络连接
- 变长子网划分举例：
    - 0 10 110 1110 1111
    - 10 110 111

#### (5)路由算法及协议，包括路由表及路由转发、路由算法分类、距离向量路由算法及RIP协议、链路状态路由算法及OSPF协议、BGP基本原理；

**路由器的组成和功能：**
- 路由器是一种具有多个输入/输出端口的**专用计算机**
- 路由器主要实现物理层，数据链路层，网络层的功能
- 路由器是网络层设备
- 路由器的任务：**连接异构网络**并完成**路由转发**
- 路由器的功能
    - 分组转发：处理通过路由器的数据流
    - 路由计算：通过和其他路由器进行路由协议的交互，完成路由表的计算
- 路由器的组成
    - 路由选择部分
        - 三个组成部分：**路由选择处理机 + 路由选择协议 + 路由表**
        - 也叫控制部分，核心是路由选择处理机
        - 任务是根据所选定的路由选择协议构造出路由表
        - 同时不断更新路由信息和维护路由表
    - 分组转发部分
        - 三个组成部分：交换结构（本身就是一个网络）+ 一组输入端口 + 一组输出端口
        - 三种交换方式
            - 通过存储器进行交换
            - 通过总线进行交互
            - 通过互联网络进行交互
- 路由表与路由转发
  - 路由表是根据路由选择算法得出的，主要用途是路由选择
  - *路由表的组成 = 目的网络的IP地址 + 子网掩码 + 下一跳IP地址 + 接口*
  - **路由表总是用软件实现**，**转发表可以用软件也可以用硬件实现**
  - 路由表不等于转发表，**分组的实际转发是靠直接查找转发表**，而不是直接查找路由表
    - 路由表中默认路由的目的地址和子网掩码都是0.0.0.0

路由算法分类：
- 按照能否随网络的通信量或拓扑自适应地进行调整变化来划分：
    - 静态路由选择
        - 由人工配置的网络路由、默认路由、特定主机路由、黑洞路由等都属于静态路由
        - 这种人工配置方式简单、开销小，但不能及时适应网络状态（流量、拓扑等）的变化
        - 一般只在小规模网络中采用
    - 动态路由选择
        - 路由器通过路由选择协议自动获取路由信息
        - 比较复杂、开销比较大，但能较好地适应网络状态的变化
        - 适用于大规模网络
        - 常用的有**距离-向量路由算法**和**链路状态路由算法**
- 按层次划分：
    - 自治系统（AS）内部：内部网关协议（IGP）
    - 自治系统外部：外部网关协议（EGP）

IP数据报的发送和转发过程：
- 主机发送IP数据报
  - 判断目的主机是否与自己在同一个网络
    - 若在同一个网络，**直接交付**
    - 若不在同一个网络，数据**间接交付**，传输给主机所在网络的默认网关（路由器），由默认网关帮忙转发
- 路由器转发IP数据报
  - 检查IP数据报首部是否出错
    - 若出错，则直接丢弃该IP数据报并通告源主机
    - 若没有出错，则进行转发
  - 根据IP数据报的目的地址在路由表中查找匹配的条目
    - 若找到匹配的条目，则转发给条目中指示的下一跳
    - 若找不到，则丢弃该IP数据报并通告源主机
- 静态路由配置及其可能产生的路由环路问题：
    - 配置错误导致路由环路：在IP数据报首部设生存时间TTL字段
    - 聚合不存在的网络而导致的路由环路：用黑洞路由条目配置解决
    - 网络故障而导致的路由环路：用黑洞路由条目配置解决

**距离向量路由算法及RIP协议：**
- 基本概念：
    - RIP使用**跳数**(Hop Count)作为度量(Metric)来衡量到达目的网络的距离。
    - **路由器到直连网络的距离定义为1，到非直连网络的距离定义为所经过的路由器数加1**
    - 允许一条路径最多只能包含15个路由器。**距离等于16时相当于不可达**。因此,RIP只适用于小型互联网
    - RIP是***应用层协议***，端口为520
- 距离-向量算法
    1. 修改邻居路由器发过来的路由表：距离字段加1（原因显然）
    2. 利用邻居路由表，更新自己的路由表
    3. 如果180秒还没有收到邻居路由表，就把邻居设为不可达路由器，距离设置为16
- RIP协议的特点
    1. 仅和**相邻路由器**交换信息（Who）
    2. 路由器交换的信息是当前路由器所知道的**全部信息**，即自己的路由表（What）
    3. 按**固定的时间间隔**交换路由信息，如每隔30秒（When）
- RIP协议的优点：实现简单、开销小、收敛过程较快
- RIP协议的缺点：“坏消息传得慢”

链路状态路由算法及OSPF协议：
- 基本概念、特点：
    - 使用了Dijkstra提出的最短路径算法SPF
    - OSPF是基于**链路状态**的，而不像RIP那样是基于距离向量的（What，区别1）
    - OSPF采用SPF算法计算路由，从**算法上保证了不会产生路由环路**（区别2）
    - OSPF**不限制网络规模**，更新效率高，收敛速度快（区别3）
    - 链路状态是指本路由器都和哪些路由器相邻，以及相应链路的“代价”(cost)。“代价”用来表示费用、距离、时延、带宽，等等，这些都由网络管理人员来决定
    - **只有当链路状态发生变化时**，路由器才用**洪泛法**向所有路由器发送此信息，且没有“坏消息传得慢”的问题（When，Who，区别4、区别5）
    - OSPF有以下五种分组类型
        - 问候(Hello)分组
        - 数据库描述(Database Description)分组
        - 链路状态请求(Link State Request)分组
        - 链路状态更新(Link State Update)分组
        - 链路状态确认(Link State Acknowledgment)分组
    - 为了使OSPF能够用于规模很大的网络，OSPF把一个自治系统再划分为若干个更小的范围，叫做区域(Area)
- 链路状态路由算法(Dijkstra算法)
    1. dist[1] = 0, dist[i] = +∞
    2. for i : 1 ~ n
        - s: 一个点的集合，1号点到该集合的点的最短路径暂时确定
        - t: **离这个集合距离最近的点**
        - 反复加入新的t，并更新可能发生变化的最短路径

BGP基本原理：
- 基本概念
    - 自治系统之间的路由选择必须考虑相关策略（政治，经济，安全等），BGP只能是力求寻找一条能够到达目的网络且比较好的路由（不能兜圈子），**而并非要寻找一条最佳路由**
    - 网络可达性信息：要到达某个网络所要结果的一系列自治系统/路径
    - 在配置BGP时，每个自治系统的管理员要选择至少一个路由器作为该自治系统的“BGP发言人”。BGP发言人要交换网络可达性信息，并根据所采用的策略从收到的路由信息中找出到达各自治系统的较好的路由
    - BGP是基于TCP的**应用层协议**
    - BGP-4有以下四种报文
        - OPEN（打开）报文：用来与相邻的另一个BGP发言人建立关系，使通信初始化
        - UPDATE（更新）报文：用来通告某一路由的信息，以及列出要撤销的多条路由
        - KEEPALIVE（保活）报文：用来周期性地证实邻站的连通性
        - NOTIFICATION（通知）报文：用来发送检测到的差错

三种路由协议的比较：
协议|RIP|OSPF|BGP
-|-|-|-
类型|内部|内部|外部
路由算法|距离-向量|链路状态|路径-向量
传递协议|UDP|IP|TCP
路径选择|跳数最少|代价最低|较好，非最佳
交换节点|和本节点相邻的路由器|网络中的所有路由器|和本节点相邻的路由器
交换内容|当前本路由器知道的全部信息，即自己的路由表。RIP不知道全网的拓扑结构|本路由器和相邻所有路由器的链路状态。任何一个路由器都知道自己所在**区域**的拓扑结构|首次：邻居的整个路由表；非首次：有变化的部分

**王道习题：**

二轮重做：3 6 7 10；8 12 15(好题) 16(好题)

大题：
1.
- 答：
    - RIP处于UDP的上层，RIP所接收的路由信息都封装在UDP的数据报中
    - OSPF的位置位于网络层，由于要交换的信息量较大，因此应使报文的长度尽量短，因此采用IP
    - BGP要在不同的自治系统之间交换路由信息，由于网络环境复杂，需要保证可靠的传输，所以选择TCP
    - 内部网关协议主要设法使数据报在一个自治系统中尽可能有效地从源站传送到目的站，在一个自治系统内部并不需要考虑其他方面的策略，然而BGP使用的环境却不同。主要有以下三个原因：
        - 第一，**因特网规模太大**，使得自治系统之间的路由选择非常困难
        - 第二，对于自治系统之间的路由选择，**要寻找最佳路由是不现实的**
        - 第三，自治系统之间的路由选择必须考虑有关策略。
        - 由于上述情况，BGP只能力求寻找一条能够到达目的网络且较好的路由，而并非寻找一条最佳路由，所以BGP不需要像RIP那样周期性地和邻站交换路由信息

2.
- 解：
    1. 略
    2. 在更新后的路由表中，路由器B到N2的距离为16(网络拓扑结构变化导致)，这意味着N2网络不可达，这时路由器B应该丢弃该IP分组并向源主机报告目的不可达

3.
- 解：加入结点次序：R6, R5, R3, N3, R4, R1, R2, N4, N1, N2
    - N1: 10 , R3
    - N2: 10, R3
    - N3: 7, R3
    - N4: 8, R3

4.
- 不做了

错题总结：
- 在距离-向量路由协议中，“慢收敛”是导致发生路由回路的根本原因
- 间接交付的最后一个路由器肯定直接交付，而**直接交付在同一个网段内，不涉及路由器**
- 在路由器互联的多个局域网的结构中，要求每个局域网的物理层、数据链路层、网络层协议可以不同，而网络层以上的高层协议必须相同
- OSPF规定Area0是主干区域

#### (6)IP组播基本原理、特点及用途

IP组播基本原理、特点及用途：
- 基本概念：
    - 也叫多播，多点广播或群播
    - **一定仅应用于UDP**
    - 主机使用IGMP加入组播组，能运行组播协议的路由器称为组播路由器
    - 组播数据报和一般的IP数据报的区别是，前者使用D类IP地址作为目的地址（注意，**组播地址只能用于目的地址**），并且首部中的协议字段值是2，表明使用IGMP
- 转发过程：
    - 一个组播地址可以标识一组地址，源主机只需将**一份数据**发给组播地址，之后网络会将**这个分组的副本**投递给该组中的每台主机
    - 在IPv4中，组播地址在D类地址空间中分配，IPv6中也有一部分地址空间保留给组播组
    - 对于IPv4，32位组播地址里**只有后23位**会被映射到48位的硬件组播地址，IANA（internet assigned number authority）规定，IPv4组播MAC地址的高24位为0x01005E，第25位为0，后23位就是前文提到的映射内容
    - 因此，组播IP地址与以太网硬件地址的**映射关系不是唯一**的，收到组播数据报的主机，还要在IP层利用软件进行过滤，把不是本主机要接收的数据报丢弃
- IGMP与组播路由算法
    - IGMP让连接到本地局域网上的组播路由器知道本局域网上是否有主机参加或退出了某个组播组，IGMP应视为网际协议IP的一个组成部分，其工作可分为两个阶段：
        1. 当某台主机加入新的组播组时，该主机应向组播组的组播地址发送一个IGMP报文，声明自己要成为该组的成员。本地的组播路由器收到IGMP报文后，将组成员关系转发给因特网上的其他组播路由器
        2. 本地组播路由器要**周期性地探询**本地局域网上的主机，以便知道这些主机是否仍继续是组的成员
    - 组播路由选择实际上就是要找出以源主机为根结点的组播转发树，其中每个分组**在每条链路上只传送一次**
    - 在许多由路由器互联的支持硬件多点传送的网络上实现因特网组播时，主要有三种路由算法：
        1. 基于链路状态的路由选择
        2. 基于距离-向量的路由选择
        3. 可以建立在任何路由器协议之上，因此称为**协议无关的组播**（PIM）

**王道习题：**

二轮重做：2 3

错题总结：
- 由于树具有不存在环路的特性，因此构造一个组播转发树，通过该转发树既能将主播分组传送到组内的每台主机，又能避免环路。水平分割用于避免距离-向量路由算法中的无穷计数问题。TTL字段用于防止IP分组由于环路而在网络中无限循环

#### (7)网络地址转换NAT原理

私有地址（专用地址）：
- 1个A类：10.0.0.0 ~ 10.255.255.255
- 16个B类：172.16.0.0 ~ 172.31.255.255
- 256个C类：192.168.0.0 ~ 192.168.255.255

网络地址转换NAT原理：
- 一句话解释NAT：**不同专用地址**对应**同一公有地址**，对应**不同端口**（从底层实现上讲, NAT至少是工作在网络层）
- 这种将端口号和IP地址一起进行转换的技术叫作网络地址与端口号转换NAPT(Network Address and Port Translation)

#### (8)IPv6基本知识，包括：IPv6特点、地址、包结构等

IPV6基本知识：
- IPv6 地址的标识方法
  - IPv6 地址长度是 128 位，是以每 16 位作为一组
  - 每组用冒号 「:」 隔开。
  - 如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开
    - 但是，一个 IP 地址中只允许出现一次两个连续的冒号
- IPv6 地址的结构
  - 单播地址，用于一对一的通信
  - 组播地址，用于一对多的通信
  - **任播地址，用于通信最近的节点**，最近的节点是由路由协议决定
- IPv6 的亮点
  - IPv6 可自动配置【即插即用】
  - IPv6 首部长度采用固定的值 40 字节，去掉了校验和
  - IPv6安全性提高了
- IPv6 相比 IPv4 的首部改进
  - **取消了首部校验和字段**
    - 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验
  - **取消了分片/重新组装相关字段**
    - 分片与重组是耗时的过程，IPv6 不允许在**中间路由器**进行分片与重组（这种操作只能在源与目标主机，这将大大提高了路由器转发的速度）
  - **取消选项字段**
    - 选项字段不再是标准 IP 首部的一部分了。但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上
    - 删除该选项字段使的 IPv6 的首部成为**固定长度的 40 字节**
        - 📈![img](https://files.catbox.moe/36ctyz.png)
- IPv4 到 IPv6 的过渡
    - 双协议栈
    - 隧道技术

**王道习题：**

二轮重做：5

错题总结：
- IPv6不允许分片，IPv6不首部校验

#### (9)其他

SDN的基本概念：
- 软件定义网络SDN采用**集中式的控制层面**和**分布式的数据层面**来控制网络
- 北向接口：SDN提供的编程接口
- 南向接口：SDN控制器和转发设备建立双向会话的接口（使用南向接口协议，如openflow）
- 东西向接口：SDN控制器集群内部控制器之间的通信接口

DHCP协议【动态主机配置协议】（基于**UDP的应用层协议**）：
- 客户：DHCP发现！（广播）
- 服务器：DHCP提供！（广播）（使用ARP确保所选IP地址未被网络中其他主机占用）
- 客户：DHCP请求！（广播）
- 服务器：DHCP确认！（广播）
    - 使用ARP检测所分配到的IP地址是否已被网络中其他主机占用：
        - 若被占用：给DHCP服务器发送“DHCP拒绝”报文撤销IP地址租约,并重新发送“DHCP发现”报文
        - 若未被占用：可以使用租约中的IP地址与网络中其他主机通信
- 特点：IP动态分配，即插即用

移动IP：
- 接收：本地代理/归属代理 → 转交地址/辅地址 → 移动结点/主地址（通俗易懂的解释：就好比你搬家了，你原来的邻居为你代收邮件，然后转寄给你）
- 移动结点 → 外埠代理/外部代理

虚拟专用网VPN：
- **利用公用的因特网作为本机构各专用网之间的通信载体**，这样的专用网又称为虚拟专用网
- 同一机构内不同部门的内部网络所构成的虚拟专用网VPN又称为**内联网VPN**
- VPN要保证传输数据的安全性，会将原始的内部数据报进行**加密**，然后再将其封装成为在因特网上发送到的外部数据
- 有时一个机构的VPN需要有某些外部机构（通常就是合作伙伴）参加进来。这样的VPN就称为**外联网VPN**
- 在外地工作的员工需要访问公司内部的专用网络时，只要在任何地点接入到因特网，运行驻留在员工PC中的VPN软件，在员工的PC和公司的主机之间建立VPN隧道，即可访问专用网络中的资源。这种VPN称为**远程接入VPN**

**王道习题：**

二轮重做：1 4

大题：

错题总结：

#### 本章小结

- 解决“IP地址耗尽”问题的措施有哪几种？
    1. 采用无类别编址CIDR，使IP地址的分配更加合理
    2. 采用网络地址转换NAT方法以节省全球IP地址
    3. 采用具有更大地址空间的新版本的IPv6（从根本上解决了IP地址的耗尽问题）
- “尽最大努力交付”有哪些含义?
    1. 不保证源主机发送的IP数据报**一定无差错**地交付到目的主机
    2. 不保证源主机发送的IP数据报都在**某一规定的时间内**交付到目的主机
    3. 不保证源主机发送的IP数据报**一定按发送时的顺序**交付到目的主机
    4. 不保证源主机发送的IP数据报**不会重复**交付给目的主机。
    5. 不**故意**丢弃IP数据报。
    6. **凡向上交付的IP数据报，都是IP首部没有差错的，或没有检测出差错的**
- IP有分片的功能，但**广域网中的分组**则不必分片，这是为什么?
    - IP数据报可能要经过多个局域网，而源结点事先并不知道数据报后面要经过的这些网络**所能通过的分组的最大长度**是多少。等到IP数据报转发到某个网络时，中间结点可能才发现数据报太长了，因此在这时就必须进行分片
    - 而*广域网能够通过的分组的最大长度是该广域网中所有结点都事先知道的*，源结点不可能发送网络不支持的过长分组。因此广域网没有必要将已经发送出的分组再进行分片
- 数据链路层广播和IP广播有何区别?
    - 数据链路层广播是用数据链路层协议（第二层）在一个以太网上实现的对该局域网上的所有主机进行广播MAC帧
    - IP广播则是用IP通过因特网实现的对一个网络（即目的网络）上的所有主机进行广播IP数据报
- 主机在接收一个广播帧或组播帧时，其**CPU**所要做的事情有何区别？
    - 在接收广播帧时，主机通过其网卡(NIC)接收每个广播帧，然后将其传递给操作系统。**CPU执行协议软件**，并界定是否接受和处理该帧
    - 在接受组播帧时，NIC根据特定的组播地址表来接收帧。凡与此**组播地址表**不匹配的帧都将被NIC丢弃。因此在组播的情况下，是适配器NIC而不是CPU决定是否接收一个帧

### <a name="21">（五）传输层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)传输层功能及提供的服务

功能及提供的服务：
  - 传输层概述：
    - 传输层是**主机才有的层次**，路由器最多能够到达网络层
    - 传输层，为运行在不同主机上的进程之间提供了逻辑通信（端到端），网络层提供主机之间的逻辑通信
    - 只有主机的协议栈才有传输层和应用层
- 传输层的功能：网络层为主机提供逻辑通信，传输层为主机上的进程提供端到端的逻辑通信
- 复用和分用
  - 复用：发送方不同的应用进程都可用同一个传输层协议传送数据（传输数据）
  - 分用：接收方的传输层在剥去报文的首部后能够把这些数据正确交付到目的应用进程（交付数据）
- 差错检测
  - 网络层中，只校验首部是否出差错而不检查数据部分
  - 传输层**需要对收到的报文进行差错检测**
- 提供两种不同的传输协议
  - 面向连接的TCP协议
  - 无连接的UDP协议
- 传输层的寻址和端口
  - 传输层使用端口来标识主机中的应用进程
  - 端口值具有本地意义，只是为了标志本计算机应用层中各个进程在和传输层交互时的层间接口
  - 不同计算机的相同端口是没有联系的
  - 端口号长度16bit，能标识65534个不同的端口号
  - 端口的分类
    - 服务器端使用的端口号
      - 熟知端口号（0-1023）
      - 登记端口号（1024-49151）
    - 客户端使用的端口号（49152-65535）

缩写|FTP|TELNET|SMTP|DNS|TFTP|HTTP|SNMP
-|-|-|-|-|-|-|-
~|**21**|23|25|**53**|69|**80**|161

- 套接字
  - 套接字Socket=（IP地址：端口号）
  - 套接字唯一地标识网络中的一台主机和其上的一个应用（进程）

**王道习题：**

二轮重做：

错题总结：

#### (2)UDP协议

UDP协议：用户数据报协议UDP = IP的数据报服务 + （复用，分用，差错检测）
- 特点
    - UDP是无连接的
    - UDP使用尽最大努力交付，不保证可靠交付
    - UDP没有拥塞控制，有利于实时应用（视频，语音）
    - UDP分组首部开销小，TCP有20B的首部开销，UDP仅有8B的开销
    - UDP是面向报文的，报文是UDP数据报处理的最小单位
    - UDP校验和校验出UDP数据报错误时，可以丢弃，也可以交付给上层，但是要附上错误报告
- UDP首部格式
    - 用户数据报UDP有两个字段：数据字段和首部字段。
    - 首部字段只有8个字节，由四个字段组成，每个字段长度都是两个字节
    - 源端口：不是必须的，只有在需要对方回信时选用，不需要时可用全0
    - 目的端口：在终点交付报文时必须使用
    - 长度：UDP数据报的长度，首部和数据部分长度之和，其最小值是8
    - 校验和：检测UDP在传输中是否出错，如果有错就丢弃
- UDP基于端口的分用步骤
    - 当运输层IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口交付给上层应用进程
    - 如果接收方UDP发现收到的报文的目的端口号不正确（即不存在对应于该端口号的应用进程），即丢弃该报文
    - 然后由网际控制报文协议ICMP发送“端口不可达”差错报文（终点不可达）给发送方
- UDP校验
    - UDP检验和提供差错检测功能。在计算校验和时，要在UDP用户数据报之前增加12字节的伪首部
    - 伪首部既不向下传送也不向上递交，只是为了计算校验和：
        - 源IP地址和目的IP地址：和IP数据一样，各占4个字节。
        - 伪首部第3个字段是0，占1字节
        - 协议字段：UDP协议的协议字段值是17，占1字节
        - UDP长度：UDP用户数据报长度，首部长度和数据部分长度之和，占2字节
- 校验和过程
    - 将校验和字段置位0
    - 将伪首部和UDP用户数据报（首部和数据部分）看成是以16位为单位的二进制组成，依次进行二进制反码求和（从低到高位逐列进行计算。0和0加得0,0和1加得1,1和1加得0但要产生一个进位1，加到下一列。若最高位产生了进位，则**最后得到的结果要加1**）
    - 将求和的结果的反码写入校验和字段

**王道习题：**

二轮重做：

大题：

错题总结：

#### (3)TCP协议，包括：报文段格式、可靠传输、流量控制、拥塞控制和连接管理。

TCP协议：
- TCP特点
    - TCP是面向连接的传输层协议
    - TCP连接是一条虚电路（逻辑连接），不是一条真正的物理连接
    - 每条TCP连接只能有两个端点，每条TCP连接只能是点对点的
        - TCP连接的端点叫做套接字(socket)或插口
        - 套接字Socket =（IP地址：端口号）
        - TCP连接 = {socket1,socket2} = {（IP1 : prot1）,（IP2 : prot2）}
    - TCP提供可靠交付的服务，保证数据无差错，不丢失，不重复，并且按序到达
    - TCP提供全双工通信
        - 发送缓存：用于存放准备发送的数据和已发送但未收到确认的数据
        - 接受缓存：用于存放按序到达但尚未被接受应用程序读取的数据和不按序到达的数据
    - TCP面向**字节流**，TCP把应用程序交下来的数据仅视作一连串的无结构的字节流
- TCP**报文段**
    - 一个TCP报文段 = 首部 + 数据部分
    - 首部的前20个字节是固定的
    - 后面有4n字节是根据需要而增加的选项
    - TCP首部的最小字节是20字节
    - 各字段含义：
        - 源端口和目的端口：TCP分用功能的实现
        - 序号：报文段所发送的数据的第一个字节的序号
        - 确认号：期望收到下个报文段第一个数据字节的序号
        - 数据偏移/首部长度：TCP首部的长度，单位是4B，由于4位能表示最大值是15，所以首部最大长度为60B
        - 保留：占6位，保留为今后使用
        - 紧急位URG：表明报文段中有紧急数据
        - **确认位ACK：仅当ACK=1确认号才有效**
        - 推送位PSH：实际很少使用
        - 复位位RST：TCP连接出现差错，需释放连接重新建立
        - **同步位SYN：在连接建立时用来同步序号**
        - **终止位FIN：用来释放一个连接**，FIN = 1表明报文段的发送方数据已发送完毕，并要求释放运输连接
        - 窗口：作为接收方让发送方设置其发送窗口的依据
        - 校验和：校验首部和数据部分，需要伪首部，格式和UDP一致，但协议从17改成6
        - 紧急指针：URG = 1时表示报文段中紧急数据的字节数
        - 选项：最大报文长度MSS：TCP报文段数据部分的长度；扩大窗口；时间戳
        - 填充：可变部分
- TCP连接（三次握手）
    - 第一次握手
        - 客户端向服务端发送请求，首部同步位SYN=1，选择一个初始序号seq=x
        - SYN报文段不携带数据，序号消耗一个序号
        - **客户端**进入**SYN-SENT**（同步已发送）状态
    - 第二次握手
        - 服务器收到SYN报文--->同意连接---->服务器为TCP连接分配缓存和变量---->向客户端返回确认报文段
        - 同步位SYN=1，确认位ACK=1，去确认号ack=x+1，为自己选择一个初始序号seq=y
        - 确认报文段不能携带数据，需要消耗一个序号
        - **服务器**进程进入**SYN-RCVD**（同步收到）状态
    - 第三次握手
        - 客户进程收到服务器进程的确认报文--->客户端为TCP连接分配缓存和变量
        - 向服务器端返回一个报文段，对服务器确认报文进行确认
        - 报文中ACK=1，确认号seq=y+1，自己序号seq=x+1
        - **客户端**进入**ESTABLISHED**（已建立连接）状态
        - 此时TCP连接已经建立，**服务器**收到客户端的确认后，进入**ESTABLISHED**状态
- TCP连接释放（四次挥手）
  - 第一次挥手
  - 客户端向服务端发出连接释放报文段----->停止发送数据，主动关闭连接
  - 报文中终止控制FIN=1，序号seq=u（值等于前面已传送的数据的最后一个字节的序号+1）
  - **客户端**进入**FIN-WAIT-1**（终止等待1状态）
  - 第二次挥手
  - 服务器收到连接释放报文段后发出确认
  - 确认位ACK=1，确认号ACK=u+1，序号seq=v（值等于服务器前面已传送过的数据最后一个字节的序号+1）
  - **服务器**进入**CLOSE-WAIT**（关闭等待）状态
  - 此时TCP连接处于半关闭状态，客户端到数据段的连接释放，但是服务器还可以向客户端发送文件，且客户端需接受
  - **客户端**收到服务器的确认---->进入**FIN-WAIT-2**（终止等待2）状态，等待服务器发出的连接释放报文段
  - 第三次挥手
  - 服务器发出连接释放报文段，FIN=1，报文序号seq=w（在半关闭状态下服务器可能又发送了一些数据）
  - 服务器重复上次已发送到确认号ack=u+1
  - **服务器**进入**LAST-ACK**（最后确认状态），等待客户端的确认
  - 第四次挥手
  - 客户端收到服务器端发出的连接释放报文----->对此发出确认，将确认位ACK置为1，确认号ack=w+1，序号seq=u+1
  - **客户端**进入**TIME-WAIT**（时间等待状态）
  - 在经过时间等待计时器设置的时间**2MSL**（最大报文段寿命）后，客户端进入**CLOSE**（关闭）状态
  - 服务器收到确认后也进入**CLOSE**状态
- 三次握手、四次挥手：牢记前者的2 + 2状态，后者的3 + 3状态
- TCP可靠传输
  - TCP提供的可靠数据传输保证接收方进程从缓存区读出的字节流与发送方发出的字节流完全一样
  - TCP使用校验（与UDP一致），序号，确认，重传来达到这个目的
  - 序号
    - TCP首部的序号字段用来保证数据能有序提交给应用层
    - TCP把数据视作一个无结构但有序的字节流
    - 序号建立在传送的字节流之上，而不建立在报文段之上
    - 序号字段的值是指本报文段所发送的数据的第一个字节的序号
  - 确认	
    - TCP首部的确认号是期望收到对方的下一个报文段的数据的第一个字节的序号
    - TCP使用默认累计
  - 重传
    - 超时
        - 计时器设置的重传时间到期但还未收到确认时，就要重传这一报文段
        - 发出事件和收到确认时间之差 = 报文段的往返时间RTT
        - 超时存在的问题：超时周期太长
    - 冗余ACK
        - 冗余ACK就是再次确认某个报文段的ACK，而发送方先前已经收到过该报文段的确认
        - TCP规定每当**比期望序号大的失序报文**到达时，就发送一个冗余ACK，指明下一个期待字节的序号
        - TCP规定当发送方收到对同一个报文段的3个冗余ACK时，就可以认为跟在这个被确认报文段之后的报文段已经丢失
        - 快速重传：只要某个报文段丢失，就立即重传
- TCP流量控制
  - 流量控制的目的：使发送方的发送速率与接收方应用程序的读取速率相匹配
  - 判断网络拥塞的依据就是超时
  - TCP利用滑动窗口机制实现对发送方的流量控制
  - TCP的窗口单位是字节
  - 接收窗口rwnd：接收方根据自己接收缓存的大小，动态地调整发送方的发送窗口大小
- TCP拥塞控制算法
  - 拥塞控制是指防止过多的数据注入网络，保证网络中的路由器或链路不致过载
  - 拥塞往往表现为通信时延的增加
  - 拥塞窗口cwnd：发送方根据当前网络拥塞程度估计而确认的窗口值
  - 发送窗口的上限值 = min[rwnd, cwnd]
  - 慢开始
    - cwnd < ssthresh时，使用慢开始算法
    - 在达到慢开始门限ssthresh前，cwnd成**指数增长**
    - cwnd不能跃过ssthresh
  - 拥塞避免		
    - cwnd > ssthresh时，使用拥塞避免算法
    - **cwnd每次增加1**
    - 出现网络拥塞时，ssthresh设置为当前cwnd的一半（乘法减小），cwnd设置为1，然后重新慢开始（TCP Tahoe版本，已废弃）
  - 快重传
    - 当发送方连续收到3个重复的ack报文时，直接重传对方尚未收到的报文段
    - 不必等待那个报文段设置的重传计时器超时
  - 快恢复（TCP Reno版本）
    - 当发送方连续收到3个冗余ack时，**执行“乘法减小”算法**
    - 把ssthresh设置为当前cwnd的一半，然后cwnd从ssthresh开始使用拥塞避免算法
  - 总结：

```
    慢开始直至ssthresh;
    while(1)
    {
        加法增大;
        if(拥塞) 慢开始;
        if(3 ACKs) 快恢复;
    }
```

**王道习题：**

二轮重做：

大题：

1.
- 待做

错题总结：

#### 本章小结

### <a name="22">（六）应用层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

- 本章全部模型都是C/S模型，而不是P2P模型

#### (1)套接字编程接口及端口概念

- 待补充

**王道习题：**

二轮重做：

错题总结：

#### (2)域名系统DNS

域名系统DNS：
- DNS作用：把域名转换为IP地址
- DNS采用C/S模型
- DNS协议运行在UDP上，使用53端口

DNS组成部分：
- 层次域名空间
    - 顶级域名（.com）
    - 二级域名（server.com）
    - 三级域名（www.server.com）
    - 多个标号组成的完整域名总共不超过255个字符
- 域名服务器
    - 种类
        - 根域名服务器（.）
        - 顶级域名服务器（.com）
        - 授权/权限域名服务器（baidu.com）
        - 本地域名服务器
    - 一定能在授权服务器找到对应的IP号
    - 域名服务器被设计为一种联机的分布式数据库系统，采用C/S模型
- 高速缓存（DNS缓存）
    - 在域名服务器中使用DNS缓存的目的
        - 为了提高DNS查询效率
        - 减轻根域名服务器的负荷和减少互联网上的DNS查询报文数量
    - DNS服务器将在一段时间后丢弃高速缓存中的信息
- 域名解析过程
    - 递归查询
    - 递归迭代查询

**王道习题：**

二轮重做：

错题总结：

#### (3)文件传送协议

文件传输协议FTP：
- FTP使用TCP可靠的传输服务
- FTP必须在整个会话期间保留用户的状态信息
- 服务器必须追踪用户在远程目录树上的当前位置
- FTP特点
    - 提供交互式访问
    - 运行客户指明文件的类型与格式，运行文件具有存取权限
    - 适合在异构网络中的任意计算机之间传送文件
- FTP功能
    - 提供不同种类主机系统（软硬件都可）之间的文件传输能力
    - 以用户权限管理的方式提供用户对远程FTP服务器的文件管理能力
    - 以匿名FTP的方式提供公用文件共享的能力，使用anonymous作为用户名
- FTP组成
    - 一个主进程，负责接收新的请求
    - 若干个从属进程，负责处理单个请求
- 主进程步骤
    - 服务端打开21端口，使客户进程能够连接上
    - 等待客户进程发出连接请求
    - 启动从属进程处理客户进程发来的请求。主进程与从属进程并发执行，从属进程对客户进程的请求处理完毕后即终止
    - 回到等待状态，继续接受其他客户进程发来的请求

**王道习题：**

二轮重做：

错题总结：

#### (4)万维网WWW原理及HTTP协议

万维网：
- WWW是一个分布式，联机式的信息存储空间
- 组成部分
    - 统一资源定位符URL-----------怎么标志分布在整个互联网上的万维网文档
    - 超文本传送协议HTTP---------用什么样的协议实现WWW上的各种连接
    - 超文本标记语言HTML--------怎么使不同风格的文档在互联网上的主机上显示
- URL的形式
    - <协议>://<主机>:<端口>/<路径>，如https://127.0.0.1:7860/login
- 原理：
    1. 当你想进入万维网上一个网页，或者其他网络资源的时候，通常你要首先在你的浏览器上输入你想访问网页的URL，或者通过超链接方式链接到那个网页或网络资源
    2. 这之后的工作首先是URL的服务器名部分被DNS解析，并根据解析结果决定进入哪一个IP地址
    3. 接下来的步骤是为所要访问的网页，向在那个IP地址工作的服务器发送一个HTTP请求。在通常情况下，HTML文本、图片和构成该网页的一切其他文件很快会被逐一请求并发送回用户
    4. 网络浏览器接下来的工作是把HTML、CSS和其他接收到的文件所描述的内容，加上图像、链接和其他必需的资源，显示给用户
    5. 这些就构成了你所看到的“网页”

HTTP协议：
- 定义了浏览器想服务器请求web页面的方式，以及服务器向浏览器传送页面的方式
- HTTP特点
    - HTTP使用面向连接的TCP作为传输层协议，保证了数据的可靠传输
    - HTTP协议本身是无连接的
    - HTTP协议是无状态的
    - 不需要保存客户的状态信息，可以减少服务器的CPU及内存的消耗
- Cookie
    - Cookie是网站为了辨别用户身份，进行会话跟踪而存储在**客户端**上的数据
    - Cookie的位置
        - 在HTTP响应报文中有一个cookie首部行
        - 在HTTP请求报文中有一个cookie首部行
        - 在用户端系统中保留一个cookie文件，由用户的浏览器进行管理
        - 位于Web站点的一个后端数据库
- 常见的HTTP响应状态码和短语   
    - 1xx表示通知信息的，如请求收到了或正在处理
    - 2xx表示成功，如接受或知道了
        - 200 OK：请求成功,被请求的对象在报文中
    - 3xx表示重定向，如要完成请求还必须采取进一步的行动
        - 301 Moved Permanently：被请求的对象被移动过，新的位置在报文中有说明
    - 4xx表示客户的差错，如请求中有错误的语法或不能完成
        - 400 Bad Request：服务器不懂请求报文
        - 404 Not Found：服务器上找不到请求的对象服务器不支持请求报文
    - 5xx表示服务器的差错，如服务器失效无法完成请求
- HTTP的报文结构
	- 两类HTTP报文
		- 请求报文
		- 响应报文
	- 报文的组成
		- 开始行【请求报文为请求行】【响应报文为状态行】
		- 首部行
		- 实体主体
	- 请求报文采用的方法
		- GET【请求】
		- HEAD【读取URL表示的信息的首部，无response】
		- POST【上传信息】
        - CONNECT【代理服务器】
- 持久连接和非持久连接
    - 待补充

**王道习题：**

二轮重做：

大题：

1.
- 待做

错题总结：

#### (5)电子邮件系统构成与协议

电子邮件系统：
- 电子邮件系统是一种异步通信方式
- 基于WWW的电子邮件
    - 用户浏览器与Gmail的邮件服务器用HTTP发送或接收邮件
    - 不同邮件服务器之间传送用SMTP
- 三个组成部分
    - 用户代理，用户与电子邮件系统的接口。如Outlook，Foxmail
    - 邮件服务器，用来发送和接收邮件。
    - 邮件发送协议SMTP【类似于Push】和读取协议pop3【类似于Pull】

发送协议和读取协议：
- SMTP：一种提供可靠且有效的电子邮件传输协议
- POP3：一种非常简单但功能有限的邮件读取协议
- IMAP：因特网报文存取协议

**王道习题：**

二轮重做：

错题总结：

#### 本章小结

## <a name="23">附录：各种名词缩写及含义</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

**计算机组成原理：**

英文|缩写|补充说明
:-:|:-:|-
Central Processing Unit|CPU|略
Memory Address Register|MAR|地址寄存器
Memory Data Register|MDR|数据寄存器
Clock cycle Per Instruction|CPI|执行每条指令所需的平均时钟周期数
Million Instructions Per Second|MIPS|每秒执行多少百万条指令数量
Mega Floating-Point Operations Per Second|MFLOPS|每秒执行多少百万条指令数量
Arithmetic Logic Unit|ALU|算术逻辑单元
Solid State Drives|SSD|固态硬盘
Read-Only Memory|ROM|只读存储器
Static Random Access Memory|SRAM|静态随机存取存储器
Dynamic Random Access Memory|DRAM|动态随机存取存储器
Row Address Strobe|RAS|行选通信号，低电平有效
Column Address Strobe|CAS|列选通信号，低电平有效
~|WE|读**写**控制信号，读周期为高电平
~|CS|片选信号，低电平有效
write-through|~|全写法/写直通法
write-back|~|回写法
write-allocate|~|写分配法
not-write-allocate|~|非写分配法
First In First Out|FIFO|先进先出算法
Least Recently Used|LRU|最近最久未使用算法
Least Frequently Used|LFU|最近最少使用算法
Reduced Instruction Set Computer|RISC|精简指令集计算机
Complex Instruction Set Computer|CISC|复杂指令集计算机
Microprocessor without Interlocked Pipeline Stages|MIPS|没有互锁流水线的微处理器
Instruction Fetch|IF|取指令
Instruction Decode|ID|指令译码
Execution|EX|执行运算
Memory|MEM|访存阶段
Write Back|WB|结果写回

**操作系统：**

英文|缩写|补充说明
:-:|:-:|-
Basic Input Output System|BIOS|一组固化到计算机内主板上一个ROM芯片上的程序，保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序
Master Boot Record|MBR|主引导记录
Process Control Block|PCB|使参与并发执行的每个程序（含数据）能够独立运行的专门的数据结构
Thread Control Block|TCB|线程控制块
User-Level Thread|ULT|用户级线程
Kernel-Level Thread|KLT|内核级线程
First Come First Serve|FCFS|先来先服务
Shortest Job First|SJF|短进程优先
Round-Robin|RR|轮询调度
Memory Manage Unit|MMU|内存管理部件
Page Table Register|PTR|页表寄存器
Translation Lookaside Buffer|TLB|快表，转址旁路缓存，MMU用来完成地址转换和TLb的访问与交互
Virtual Page Number|VPN|页号
Physical Page Number|PPN|物理页号/页框号
Page Table Entry|PTE|页表项
File Control Block|FCB|文件控制块
Access-Control List|ACL|访问控制列表
File Allocation Table|FAT|文件分配表
Main File Directory|MFD|主文件目录
User File Directory|UFD|用户文件目录
Directed Acyclic Graph|DAG|有向无环图
Virtual File System|VFS|虚拟文件系统
Direct Memory Access|DMA|直接存储器存取
Shortest Seek Time First|SSTF|最短寻找时间优先
Scan|SCAN|扫描算法
Redundant Array of Independent Disks|RAID|独立磁盘冗余磁盘阵列


**计算机网络：**

英文|缩写|补充说明
:-:|:-:|-
~|Repeater|中继器/转发器/放大器
~|Hub|集线器
~|Bridge|网桥
~|Switch|交换机
~|Routers|路由器
~|Gateway|网关/协议转换器
~|Brouter|桥接路由器，可以工作在数据链路层和网络层
Network Interface Card|NIC|网卡，工作在数据链路层和物理层，进行数据的串并转换
Wide Area Network|WAN|广域网
Metropolitan Area Network|MAN|城域网
Local Area Network|LAN|局域网
Personal Area Network|PAN|个人区域网
Internet Service Provider|ISP|网络业务提供商
Round-Trip Time|RTT|往返时延
Service Data Unit|SDU|服务数据单元，物理层的服务数据单元就是1-SDU
Protocol Control Information|PCI|控制协议操作的信息，链路层的协议控制信息就是2-PCI
Protocol Data Unit|PDU|对等层次之间传送的数据单位称为该层的PDU，物理层的PDU称为比特流，数据链路层的称为帧，网络层为分组/IP数据报，传输层为报文段
Service Access Point|SAP|逻辑接口，是一个层次系统的上下层之间进行通信的接口，和硬件接口有所不同
International Standardization Organization|ISO|国际标准化组织
Open System Interconnection reference model|OSI/RM|开放系统互连参考模型
Return to zero|RZ|归零编码
Non return to zero|NRZ|非归零编码
Non return to zero, inverted|NRZI|反向非归零编码
Amplitude Shift Keying|ASK|幅移键控
Frequency Shift Keying|FSK|频移键控
Phase Shift Keying|PSK|相移键控
Quadrature Amplitude Modulation|QAM|正交振幅调制
Shielded Twisted Pair|STP|屏蔽双绞线
Unshielded Twisted Pair|UTP|无屏蔽双绞线
Pulse-Code Modulation|PCM|脉冲编码调制
Asymmetric Digital Subscriber Line|ADSL|非对称数字用户线
Hybrid Fiber Coax|HFC|光纤同轴混合网
fiber to the...|FTTx|光纤到……
Maximum Transmission Unit|MTU|最大传送单元
Cyclic Redundancy Check|CRC|循环冗余校验
Automatic Repeat reQuest|ARQ|自动重传请求
Stop-and-Wait|SW|停止-等待协议
Go-back-N|GBN|后退N帧协议
Selective Repeat|SR|选择重传协议
Medium Access Control|MAC|介质访问控制/媒体接入控制/介质接入控制/媒体访问控制，当然，媒体还能替换成媒介，总之翻译方式极多
Logical Link Control|LLC|逻辑链路控制
Point-to-Point Protocol|PPP|点对点协议
Link Control Protocol|LCP|链路控制协议
Network Control Protocol|NCP|网络控制协议
Password Authentication Protocol|PAP|口令鉴别协议
Challenge-Handshake Authentication Protocol|CHAP|口令握手鉴别协议
Frequency-Division Multiplexing|FDM|频分多路复用
Time-Division Multiplexing|TDM|时分多路复用
Statistical Time-Division Multiplexing|STDM|异步时分多路复用
Wave-Division Multiplexing|WDM|波分多路复用
Code-Division Multiplexing|CDM|码分多路复用
Code Division Multiple Access|CDMA|码分多址，注意与CSMA做区分
Additive Link On-line HAwaii system|ALOHA|ALOHA协议
Carrier Sense Multiple Access|CSMA|载波侦听多点访问协议
Carrier Sense Multiple Access with Collision Detection|CSMA/CD|载波侦听多点访问/碰撞检测协议
Carrier Sense Multiple Access with Collision Avoidance|CSMA/CA|载波侦听多点访问/碰撞避免协议
InterFrame Space|IFS|帧间间隔
Short InterFrame Space|SIFS|短IFS，用来分隔属于一次对话的各帧
PCF interframe space|PIFS|点协调IFS，中等长度的IFS，在PCF操作中使用
DCF interframe space|DIFS|分布式协调IFS，最长的IFS，用于异步帧竞争访问的时延
Access Point|AP|接入点
Basic Service Set|BSS|基本服务集
Basic Service Area|BSA|基本服务区
Distribution System|DS|分配系统
Extended Service Set|ESS|扩展服务集
Service Set IDentifier|SSID|服务集标识符
Request To Send|RTS|请求发送
Clear To Send|CTS|允许发送
Software Defined Networking|SDN|软件定义网络
Don't Fragment|DF|不要分片（也就是说，DF = 0就是可以）
More Fragments|MF|更多分片（也就是说，MF = 1就是后面还有）
Address Resolution Protocol|ARP|地址解析协议
Classless Inter-Domain Routing|CIDR|无分类域间路由选择
Dynamic Host Configuration Protocol|DHCP|动态主机配置协议
Internet Control Message Protocol|ICMP|网际控制报文协议
Autonomous System|AS|自治系统
Interior Gateway Protocol|IGP|内部网关协议
Exterior Gateway Protocol|EGP|外部网关协议
Routing Information Protocol|RIP|路由信息协议
Open Shortest Path First|OSPF|开放（开源）最短路径优先
Border Gateway Protocol|BGP|边界网关协议
Internet Group Management Protocol|IGMP|因特网组管理协议
Virtual Private Network|VPN|虚拟专用网络
Network Address Translation|NAT|网络地址转换
User Datagram Protocol|UDP|用户数据报协议
Maximum Segment Lifetime|MSL|最长报文段寿命
Maximum Segment Size|MSS|最大报文段长度
Domain Name System|DNS|域名系统
File Transfer Protocol|FTP|文件传输协议
World Wide Web|WWW|万维网
Uniform Resource Locator|URL|统一资源定位系统
Hyper Text Transfer Protocol|HTTP|超文本传输协议
Hyper Text Markup Language|HTML|超文本标记语言
Cascading Style Sheets|CSS|层叠样式表