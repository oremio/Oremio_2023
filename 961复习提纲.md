# 961复习提纲

使用教辅：王道四件套、天勤四件套

注：难题、综合题要及时加入改错本，并做足注释！！

## <a name="index">**目录**</a>

&emsp;<a href="#1">2023年硕士研究生入学考试专业课961考研大纲</a>  
&emsp;<a href="#2">复习提纲</a>  
&emsp;<a href="#3">计算机组成原理（60分）</a>  
&emsp;&emsp;<a href="#4">（一）计算机系统概述</a>  
&emsp;&emsp;<a href="#5">（二）数据的表示和运算</a>  
&emsp;&emsp;<a href="#6">（三）存储器层次结构</a>  
&emsp;&emsp;<a href="#7">（四）MIPS指令系统及汇编语言</a>  
&emsp;&emsp;<a href="#8">（五）MIPS处理器</a>  
&emsp;&emsp;<a href="#9">（六）总线与输入输出(I/O)系统</a>  
&emsp;<a href="#10">操作系统（50分）</a>  
&emsp;&emsp;<a href="#11">（一）操作系统概述</a>  
&emsp;&emsp;<a href="#12">（二）进程管理</a>  
&emsp;&emsp;<a href="#13">（三）内存管理</a>  
&emsp;&emsp;<a href="#14">（四）设备管理</a>  
&emsp;&emsp;<a href="#15">（五）文件系统</a>  
&emsp;<a href="#16">计算机网络（40分）</a>  
&emsp;&emsp;<a href="#17">（一）计算机网络概述</a>  
&emsp;&emsp;<a href="#18">（二）物理层</a>  
&emsp;&emsp;<a href="#19">（三）数据链路层</a>  
&emsp;&emsp;<a href="#20">（四）网络层</a>  
&emsp;&emsp;<a href="#21">（五）传输层</a>  
&emsp;&emsp;<a href="#22">（六）应用层</a>  
&emsp;<a href="#23">附录：各种名词缩写及含义</a>  

## <a name="1">2023年硕士研究生入学考试专业课961考研大纲</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>
一、考试组成

961计算机基础综合共包括三门课程的内容：计算机组成原理、操作系统、计算机网络技术，分别占60分，50分、40分。所有课程均不指定参考书。

二、计算机组成原理部分的考试大纲（60分）

<一>、整体要求

（一）理解单处理器计算机系统中各部件的内部工作原理、组成结构以及相互连接方式，具有完整的计算机系统的整机概念；

（二）理解计算机系统层次化结构概念，掌握以MIPS为代表的RISC指令集体系结构的基本知识，能对MIPS汇编程序设计语言的相关问题进行分析；

（三）理解计算机存储系统的层次化结构，掌握层次化存储系统的设计、分析和性能计算；

（四）能根据指令语义进行单周期、多周期或流水线MIPS处理器的数据通路及其控制器的分析和简单设计；

（五）理解并掌握输入输出系统的基本知识。

<二>、知识要点

（一）计算机系统概述

（1）计算机系统的基本组成与层次结构

（2）计算机系统的性能指标：吞吐量、响应时间、带宽、延迟；CPU时钟周期、主频、CPI、CPU执行时间；MIPS、MFLOPS、GFLOPS、TFLOPS、PFLOPS。

（二）数据的表示和运算

（1）数制与编码

（2）定点数和浮点数的表示和运算

（3）算术逻辑单元ALU

1）串行加法器和并行加法器

2）算术逻辑单元ALU的功能和结构

（三）存储器层次结构

（1）存储器的层次化结构

（2）主存储器与CPU的连接

（3）高速缓冲存储器(Cache)

1）Cache的基本工作原理

2）Cach和主存之间的映射方式

3）Cache中主存块的替换算法与写策略

4）多层次Cache性能计算

（4）虚拟存储器

1）虚拟存储器的基本概念

2）页式虚拟存储器

3）TLB(快表)

（四）MIPS指令系统及汇编语言

（1）指令系统的基本知识（指令格式、寻址方式）

（2）MIPS汇编语言

（五）MIPS处理器

（1）CPU的功能和基本结构

（2）单周期、多周期MIPS处理器数据通路的功能和基本结构

（3）硬布线控制器的功能和工作原理

1）单周期处理器控制器

2）多周期处理器控制器

（4）指令流水线

1）指令流水线的基本概念

2）流水线冒险及处理策略

3）指令流水线的基本实现

（六）总线与输入输出(I/O)系统

（1）总线的基本概念

（2）磁盘存储器

（3）I/O控制器

1）I/O控制器的功能和基本结构

2）存储映射I/O编址

（4）基本I/O方式

1）程序查询方式

2）程序中断方式：中断的基本概念，中断响应过程，中断处理过程，多重中断和中断屏蔽的概念；

3）DMA方式，DMA控制器组成，DMA传送过程，设备传输性能计算。

三、操作系统部分的考试大纲（50分）

（一） 可参考书目

1.操作系统实用教程（第三版），任爱华，清华大学出版社。

2.现代操作系统(Modern Operating System) (The 3rd Edition),陈向群,马洪兵等译,Andrew S. Tanenbaum著,机械工业出版社。

（二） 复习内容

1.操作系统概述

a)操作系统的基本概念；内核态与用户态、中断、异常和系统调用。

2.进程管理

a)进程、线程的基本概念以及两者的区别；

b)进程控制块、进程的状态与转换；

c)进程同步的基本概念；实现临界区互斥的基本方法；信号量机制及P、V操作；了解经典同步问题，并通过信号量机制解决进程同步问题。

d)进程间通信，包括共享存储系统、消息传递系统、管道。

e)进程调度的基本准则；典型调度算法：先来先服务调度算法、短作业(短进程、短线程)优先调度算法、时间片轮转调度算法、优先级调度算法。

f)死锁的形成原因与必要条件；死锁预防、死锁避免、死锁检测和解除。

3.内存管理

a)程序装入与链接；逻辑地址与物理地址空间；重定位；内存保护。

b)分区管理；交换与覆盖技术。

c)分页管理方式；分段管理方式；段页式管理方式。

d)虚拟内存基本概念和局部性原理；缺页中断；地址变换过程。

e)页面置换算法：最佳置换算法(OPT)、先进先出置换算法(FIFO)、最近最少使用置换算法(LRU)、时钟置换算法(CLOCK)；工作集模型。

4.设备管理

a) I/O控制方式：程序控制、中断、DMA、通道；缓冲技术；假脱机技术(SPOOLing)。

5.文件系统

a)文件与文件系统的基本概念；组织方式；文件控制块；目录结构；文件存取控制；文件系统层次结构。

b）磁盘的结构；磁盘调度算法；廉价冗余磁盘阵列。

四、计算机网络部分的考试大纲（40分）

（一）可参考书目《计算机网络》(第8版)，谢希仁编著，电子工业出版社，2021

（二）复习内容

1、计算机网络概述

(1)计算机网络定义与分类

(2)计算机网络体系结构

2、物理层

(1)物理层的基本概念

(2)数据通信的基础知识

(3)传输介质及其特性

(4)信道复用技术

(5)数字传输系统

(6)宽带接入技术

3、数据链路层

(1)数据链路层功能和设计要点

(2)错误检测和纠正

(3)基本数据链路协议，包括：停止-等待协议、后退N帧协议和选择重传协议；

(4)滑动窗口协议

(5)点对点协议PPP

(6)介质访问控制协议，包括介质访问控制基本概念、协议分类、CSMA/CD协议；

(7)以太网，包括MAC地址、IEEE局域网标准、以太网、高速以太网技术；

(8)局域网互连技术，包括物理层及数据链路层互连技术、网桥概念和工作原理、局域网交换机工作原理；

(9)无线局域网(IEEE802.11)基本知识，包括CSMA/CA协议原理等。

4、网络层

(1)网络层提供的数据报和虚电路服务

(2)IP协议及ARP协议

(3)划分子网和构造超网

(4)ICMP协议

(5)路由算法及协议，包括路由表及路由转发、路由算法分类、距离向量路由算法及RIP协议、链路状态路由算法及OSPF协议、BGP基本原理；

(6)IP组播基本原理、特点及用途

(7)网络地址转换NAT原理

(8)IPv6基本知识，包括：IPv6特点、地址、包结构等

5、传输层

(1)传输层功能及提供的服务

(2)UDP协议

(3)TCP协议，包括：报文段格式、可靠传输、流量控制、拥塞控制和连接管理。

6、应用层

(1)套接字编程接口及端口概念

(2)域名系统DNS

(3)文件传送协议

(4)万维网WWW原理及HTTP协议

(5)电子邮件系统构成与协议

## <a name="2">复习提纲</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

## <a name="3">计算机组成原理</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

### <a name="4">（一）计算机系统概述</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）计算机系统的基本组成与层次结构

**计算机系统的基本组成：**

硬件系统：看得见的物理实体，电子线路和电子元件等

软件系统：解决问题的思想、方法，包括程序和数据

固件：固化的软件，firmware，本质是软件

**计算机硬件的基本组成：**

冯·诺依曼结构：
- 输入设备：将信息输入到计算机的外部设备，如键盘、鼠标等
- 输出设备：输出计算机处理结果的外部设备，如显示器、打印机等
- 存储器：存放程序和数据，按地址访问
- 运算器：执行算术运算和逻辑运算，必备寄存器：累加器（ACC）、乘商寄存器（MQ）、操作数寄存器（X）、程序状态寄存器/标志寄存器（PSW）
- 控制器：由程序计数器（PC）、指令寄存器（IR）、控制单元（CU）组成，根据指令的操作码、指令执行过程中的条件状态、时序系统等三方面的因素来产生指令执行过程中所需要的控制信号，控制指令的执行

*重要概念——存储字长：存储单元中的二进制代码位数，“等于数据线的数量，等于MDR的位数”（这条划掉。详见知乎：https://www.zhihu.com/question/293885327）（顺便：MAR的位数是log2存储单元个数，与PC长度相等），一般小于等于机器字长，是1字节的偶数倍。*

*重要概念——CPU：图示见王道p4。CPU包含{ALU、通用寄存器组GPRs、标志寄存器}、{CU、IR、PC}、MAR、MDR。*

冯·诺依曼计算机特点：（真题2019）

组成：运算器、控制器、存储器、输入和输出设备

存储程序：
- 指令和数据以**二进制**形式存放在存储器中
- 指令顺序存放，存储器按地址访问

程序控制：
- 程序运行时，控制器逐条从主存中取出指令，控制全机相关部件执行相应操作，完成指令的功能直至完成程序的功能
- 由指令控制计算机的运行
- 由控制器来控制数据的存取及程序的执行
- 程序顺序执行，遇到分支指令可能改变顺序

**计算机软件系统分类:**

应用软件:解决应用问题的程序集合，如各种科学计算类程序、工程设计类程序、数据统计与处理程序、情报检索程序等

系统软件：管理和调度计算机，方便用户使用计算机并提高使用效率的程序的集合
- 操作系统（OS）、数据库管理系统（DBMS)
- 分布式软件系统、网络软件系统、标准库程序
- 语言处理程序：
    - 编译器：将高级语言转换成汇编语言
    - 汇编器：将汇编语言转换成机器指令
    - 解释器：将高级语言直接翻译成机器指令，如JAVA

软硬件功能逻辑等效：
- 同一功能即可软件实现，也可以硬件实现
- 软件灵活性高，性能差，成本低
- 硬件效率高，成本高
- 功能划分要折中考虑

**计算机系统的层次结构：**

软件层（虚拟计算机）：
- 高级语言层 
- 汇编语言层    
- 操作系统层（由操作系统程序实现，由机器指令和广义指令组成，因此也被称为混合层）

硬件层：
- 指令集架构层（传统机器语言层）（组原讨论对象）
- 微代码层（可选）（微程序解释机器指令）（组原讨论对象）
- 逻辑门层（实体硬件）

![](https://api2.mubu.com/v3/document_image/e582b4cf-04cd-44ed-a905-f5cac0e939be-329792.jpg)

**计算机系统的工作过程：（真题2015、2016）**

- 1.“存储程序”工作方式
- 2.从源程序到可执行文件：hello.c->(预处理器cpp)->hello.i->(编译器ccl)->hello.s->(汇编器as)->hello.o+prinf.o->(链接器ld)->hello
- 3.程序的执行过程：数据在CPU、主存储器和I/O设备之间流动，通过总线、I/O接口进行
- 4.指令的执行过程：略

**王道习题：**

一轮标记题：2 7 9 14 19 20 22 23

二轮重做：2 5 9 14 19 23 24

大题：

01.
- 解：略
- 答：存储程序是指将指令以代码的形式事先输入计算机主存，然后按其在存储器中的首地址执行程序的第一条指令，以后就按该程序的规定顺序执行其他指令，直至程序执行结束。计算机按照此原理应该具有5大功能：数据传送功能、数据存储功能、数据处理功能、操作控制功能、操作判断功能


错题总结：
- 冯·诺依曼机的基本工作方式是控制流驱动方式
- 编译程序（编译器）既能输出汇编语言，也能输出机器语言，**现代编译器主要采用生成汇编代码（assembly code）的策略，而不直接生成二进制的目标代码（binary object code）**
- 硬件描述语言（英文：Hardware Description Language，简称：HDL）是电子系统硬件行为描述、结构描述、数据流描述的语言。利用这种语言，数字电路系统的设计可以从顶层到底层（从抽象到具体）逐层描述自己的设计思想，用一系列分层次的模块来表示极其复杂的数字系统。然后，利用电子设计自动化（EDA）工具，逐层进行仿真验证，再把其中需要变为实际电路的模块组合，经过自动综合工具转换到门级电路网表。接下去，再用专用集成电路 ASIC 或现场可编程门阵列 FPGA 自动布局布线工具，把网表转换为要实现的具体电路布线结构。**这是一个很容易望文生义的专业词汇**

#### （2）计算机系统的性能指标：吞吐量、响应时间、带宽、延迟；CPU时钟周期、主频、CPI、CPU执行时间；MIPS、MFLOPS、GFLOPS、TFLOPS、PFLOPS

**静态性能指标：**
- 机器字长：CPU一次处理的数据位数；与寄存器、运算器、数据总线的位宽相等；决定数据表示范围和精度
- 带宽：数据总线一次所能并行传送信息的位数，这里指外部总线的宽度。
- 主存容量：主存储器所能存储信息的最大容量。

**时间相关性能指标：（背30）**
- 吞吐量：指系统单位时间内处理请求的数量，主要取决于主存的存取周期。
- 响应时间：用户向计算机发送一个请求，到系统对该请求做出相应并获得结果所用的时间。响应时间越短，吞吐率越大。程序执行时间 = CPU时间 + 等待时间（磁盘、存储器访问、I/O操作、OS开销）
- 延迟：内存延迟是从开始请求内存中的字节或字，到处理器检索到它之间的时间。如果数据不在处理器的缓存中，则获取它们需要更长的时间，因为处理器必须与外部存储单元通信。因此，延迟是衡量内存速度的基本指标：延迟越少，读取操作就越快。延迟不应与衡量内存吞吐量的内存带宽混淆。延迟可以用时钟周期或以纳秒为单位测量的时间来表示
- CPU时钟周期：时钟频率的倒数，是处理操作最基本的时间单位
- 主频：时钟周期的倒数，同等条件下，频率越高，性能越好。但频率不可能无限提升，存在散热问题，串扰问题等，单位赫兹Hz
- CPI：执行每条指令所需的平均时钟周期数，Clock cycle Per Instruction
- CPU执行时间：程序执行期间真正消耗CPU的时间，**取决于①主频、②CPI、③指令条数（指令集）三要素**
- MIPS：每秒执行多少百万条指令数量，Million Instructions Per Second
- MFLOPS:
    - **每秒执行多少百万次浮点操作，Mega Floating-Point Operations Per Second，用于衡量科学计算性能**
    - 更小单位：kFLOPS，k小写
    - 更大单位：**GFLOPS、TFLOPS、PFLOPS**、EFLOPS、ZFLOPS，**Giga、Tera、Peta**、Exa、Zetta，每个单位相差1000倍
    - 还有一些常用的英文前缀：kilo(3)、hecto、deca、deci、centi、milli(-3)、micro(-6)、nano(-6)、pico(-9)
- 基准程序：专门用来进行性能评价的一组程序，但也存在缺陷（比如硬件设计人员根据benchmark代码进行特别优化）

**王道习题：**

一轮标记题：10 13 14

二轮重做：13 22 

大题：1 3

1.
- 解：MDR：32位，MAR：16位，IR：32位，PC：16位，X = ACC = MQ = 32位；信息通路：嗯……
- 答：信息通路：PC->MAR, Ad(IR)->MAR, MDR->IR, MDR->ACC（取数）, ACC->MDR（存数）, MDR->X

2.
- 解：CPI = 0.6 * 1 + 0.18 * 2 + 0.12 * 4 + 0.1 * 8 = 2.24; CPU时间 = I * CPI / f = 5.6 * 10 ^ -8; MIPS = f / (CPI * 10 ^ 6) = 17.86
- 答：解答正确，注意CPU执行时间的单位是秒

3.
- 解：
    - 1) T = 1 / f = 1.25 * 10 ^ -7秒
    - 2) T = 1 / 0.4MIPS =  2.5 * 10 ^ -6秒
    - 3) 0.4MIPS = f / CPI * 10 ^ -6, 解得CPI = 20; 平均指令执行速度 = 1 / (CPI * T) = 12 * 10 ^ 6 / 20 = 6 * 10 ^ 5
- 答：解答正确。所谓“平均指令执行速度”，其实就是在说MIPS，最后的写法也建议写成MIPS的形式

4.
- 解：老CPI：1.57；新指令总数：0.79M + 0.21M * 0.75 = 0.9475M, CPI = ...
- 答：新指令总数算错了。算术逻辑和Load指令都是减去0.43 * 0.25M，新增的新算术逻辑指令也是0.43 * 0.25M

错题总结：
- 兼容指计算机软件**或**硬件的通用性
- 单片机（Single-Chip Microcomputer）是一种集成电路芯片，是采用超大规模集成电路技术把具有数据处理能力的中央处理器CPU、随机存储器RAM、只读存储器ROM、多种I/O口和中断系统、定时器/计数器等功能（可能还包括显示驱动电路、脉宽调制电路、模拟多路转换器、A/D转换器等电路）集成到一块硅片上构成的一个小而完善的微型计算机系统，在工业控制领域广泛应用

#### 本章小结

- 机器语言和汇编语言与机器指令对应，而高级语言不与指令直接对应，具有较好的可移植性。其中机器语言可以被硬件直接执行
- 翻译程序分为编译程序和解释程序，汇编程序则是特指从汇编语言翻译到机器语言的程序
- *字长 = 机器字长，指令字长 = 一个指令字中包含的二进制代码的位数，存储字长：一个存储单元存储的二进制代码的位数，若指令字长是存储字长的2倍，则需要两个访存周期来取出一条指令（这条划掉。详见知乎：https://www.zhihu.com/question/293885327）*
- 两台机器指令系统相同时，只能认为它们具有相同的结构，至于这两台机器**如何实现其指令**，完全可以不同，即可以认为它们的组成方式是不同的。例如，一台机器是否具备乘法指令是一个**结构**的问题，但实现乘法指令采用什么方式则是一个**组成**的问题。许多计算机厂商提供一系列体系结构相同的计算机，而它们的组成却有相当大的差别，即使是同一系列的不同型号机器，其性能和价格差异也很大

### <a name="5">（二）数据的表示和运算</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）数制与编码

进位制数及其相互转换:
- 二进制编码：两种状态，容易与物理状态对应；位数有限时不能表示循环小数；运算规则简单，适合用布尔代数设计电路，制造成本低
- 数制转换
    - 二进制转十进制：加权展开
    - 十进制到二进制：整数除2取余，先余为低；小数乘2取整，先整为高
    - 二进制转8进制或16进制：从小数点向左右3/4位一分组

BCD码：
- 8421码：1010到1111是无效码，要加6修正
- 余3码：8421码的基础上每种编码加3
- 2421码：也是一种有权码，权值由高到低分别为2,4,2,1，特点是大于等于5的4位二进制数中最高位为1，小于5的最高位为0

机器码：**在现代计算机中，通常用定点补码整数表示整数，用定点原码小数表示浮点数的尾数部分，用移码表示浮点数的阶码部分。补码是重点，会结合代码，指令格式（立即数，相对寻址）进行考察！**
- 原码：存在正零和负零两个零
- 反码：当真值为正数时，反码和原码相同；当真值为负数时，数值部分要逐位取反。也存在正零和负零两个零。主要用于求补
- 💎补码：*数据表示建立在“模”的概念基础上，模的值即为符号位进位的权值*
    - 模2的补码：定点小数模值为2，定点整数模值为2 ^ ( n + 1 )
    - 模4的补码：变形补码，定点小数模值为4，定点整数模值为2 ^ ( n + 2 )，其中**n为数值位位数**
    - 当真值为负数时，补码等于真值加上模
    - 在数轴上的表示区间不对称：机器零唯一，最左侧比原码、反码多表示一个最小负数
    - 补码符号位可以直接参与加减运算，运算电路实现方便，因此计算机中整数采用补码进行存储、表示和运算
    - 补码和真值之间的转换：正数与原码一致，**负数都遵循“数值位逐位取反、末尾加一”的规则**
- 移码：
    - 只用于表示整数，也称偏移码，真值 + 常量
    - 方便比较大小，数字越大，真值越大
    - **移码和补码的符号位相反，数值位相同**
    - 用于表示浮点数的阶码
- 机器码表示范围（只需记住补码公式，加模数）：
![](https://api2.mubu.com/v3/document_image/8274186f-11f0-4065-8723-aafe9a0220e4-329792.jpg)
- 机器码在数轴上的表示（对比理解）：
![](https://api2.mubu.com/v3/document_image/d971313c-94f7-483b-ad4f-a9f500063e43-329792.jpg)

**王道习题：**

一轮标记题：1 3 4 7 13 14 17 25 26 28 29 30

二轮重做：17

错题总结：
- 使用补码表示时，若符号位相同，则数值位越大码值越大

#### （2）定点数和浮点数的表示和运算

定点数的表示：
- 定点数概念：小数点位置固定的数
- 定点数分类
    - 有符号数、无符号数：机器码到底有无符号取决于输出形式。C语言中printf中%d输出，%u表示无符号
    - 定点整数和定点小数：
        - 定点小数：小数点隐含在符号位之后，有效数值部分最高位之前
        - 定点整数：小数点在有效数值部分最低位之后
    - 溢出问题：
        - 定点整数存在上溢问题（超出表示范围）
        - 定点小数存在精度溢出问题（超出表示精度）

**定点数的移位运算：**
- 算术移位：**符号位保持不变**

符号|码制|添补代码
:-:|:-:|:-:
正数|原码、补码、反码|0
负数|原码|0
负数|补码左移|0
负数|补码右移|1
负数|反码|1

- 逻辑移位：将操作数视为无符号数，不管左移还是右移，都补0
- 循环移位：
    - 带进位标志位CF（大循环）：CF参与循环
    - 不带CF（小循环）：CF存储最新移出的数字的副本

原码定点数的加减运算（没考过）：
- 符号位不能直接参与运算
- 加法运算需要“同号求和，异号求差”
- 减法运算需要“异号求和，同号求差”
- 求差时还需要先比较大小，然后用大数减去小数
- 结果的符号选择也相对复杂，运算复杂

**补码定点数的加减运算：**
- 运算公式：设机器字长为n + 1：
    - [A + B]补 = [A]补 + [B]补 (mod 2 ^ (n + 1))
    - [A - B]补 = [A]补 + [-B]补 (mod 2 ^ (n + 1))
- 运算规则：
    - 操作数采用补码表示，符号位参加运算
    - 运算的结果为补码，符号位的进位位（模）直接丢弃

定点数的乘法运算（几乎没考）：
- 原码乘法运算：
    - 运算过程见改错本p1
    - 符号位单独运算
    - 被乘数取双符号位，右移n次，加n次
- 补码乘法运算（Booth算法）：
    - 运算过程见改错本p1
    - 符号位参与运算
    - 被乘数取双符号位，乘数取单符号位，末尾增加一附加位，右移n次，加n + 1次
- 原码除法运算（恢复余数法）：
    - 循环次数不固定，不利于机器控制
- 原码除法运算（不恢复余数法）：
    - 运算过程见改错本p2
    - 符号位单独运算
    - 被除数（余数）和商均为单符号位，左移n次，加n + 1次
    - 第n + 1步的余数为负时，需要加上|Y|得到正确的余数
- 补码除法运算（加减交替法）：
    - 运算过程见改错本p3
    - 符号位参与运算
    - 被乘数取双符号位，乘数取单符号位，左移n次，加n + 1次
    - 若对商的精度没有特殊要求，则一般采用“末位恒置1”法

💎**溢出的概念和判别法**：*仅当两个符号相同的数相加或两个符号相异的数相减才可能产生溢出（可用来快速判断）*
- 采用一位符号位：由于减法运算是用加法器实现的，因此只需遵循加法的溢出规则“正正得负，负负得正”即可：
![](https://api2.mubu.com/v3/document_image/eb154771-892b-493a-af75-e7b4c4a8cfaa-329792.jpg)
- 采用双符号位：00正数，01正溢出，10负溢出，11负数。主要用于手工计算，方便肉眼识别，计算机因为成本问题不采用
- 采用一位符号位根据数据位的进位情况判断溢出：若符号位的进位Cn和最高数位的进位Cn-1相同，则说明没有溢出，否则表示发生溢出，即：OF = Cn ⊕ Cn-1

**王道习题：**

一轮标记题：4 10 11 14 15 19 22 25 26 27 31 33 35 38 43

二轮重做：14 26 27 38 41 43(溢出、进位/借位的快速判断?)

大题：1 2 8
1.（加入改错本）
- 解：全部算错！32位数是-2147483648 ~ 2147483647！
- 答：
    - 1) 2 ^ 31 + 2 ^ 2; 2 ^ 30 + 2; 4000 0002H; **2 ^ 32 + 2 ^ 3, 发生溢出**; 0000 0008H
    - 2) -(2 ^ 31 - 2 ^ 2); -(2 ^ 30 - 2); C000 0004H; **(2 ^ 32 - 2 ^ 3), 发生溢出**; 0000 0008H

2.
- 解：
    - 1) 86H; 90H; 7CH;
    - 2) -122; -112
    - 4) 最后一条语句执行时会发生溢出，理由略
- 答：
    - 3) 能。n位加法器实现的是模2^n无符号整数加法运算。对于无符号整数a和b，a + b可以直接用加法器实现，而a-b可用a加b的补数实现，所以n位无符号整数加减运算都可在n位加法器中实现；由于有符号整数用补码表示，补码加减运算公式为[a + b]补 = [a]补 + [b]补 (mod 2 ^ n)，[a - b]补 = [a]补 + [-b]补 (mod 2 ^ n)，所以n位有符号整数加减运算都可在n位加法器中实现

3.
- 解：0.1001; 0.1101

4.（加入改错本）
- 证明：采用定点小数表示，条件为|X<1|，|Y<1|，|X+Y<1|，所以要分4种情况证明
- 解析：**本题考查定点小数补码的定义，需牢记！**

5.
- 解：0010

6.
- 解：0.1110

7.
- 解：
    - 1) BCH, B0H;
    - 2) 6CH, OF = 1, SF = 0
    - 3) 0CH, OF = 0, SF = 0

8.（不加入改错本，但要复习！）
- 解：
    - 1) 乘法指令可以通过Booth算法利用加减和位移等指令实现
    - 4) 带符号和无符号均为: FF FF FF FEH; umul()没有溢出，mul()溢出
- 答：
    - 1) 乘法运算可以通过加法和移位来实现。编译器可以将乘法运算转换为一个循环代码段，在循环代码段中通过比较、加法和移位等指令实现乘法运算
    - 2) 控制逻辑的作用是控制循环次数，控制加法和移位操作
    - 3) **a)最长，c)最短。对于a)，需要用循环代码段（即软件）实现乘法操作，因而需要反复执行很多条指令，而每条指令都需要取指令、译码、取数、执行并保存结果，所以执行时间很长；对于b)和c)，都只需用一条乘法指令实现乘法操作，不过b)中的乘法指令需要多个时钟周期才能完成，而c)中的乘法指令可在一个时钟周期内完成，所以c)的执行时间最短**
    - 4) 应该是00 00 00 00 FF FF FF FEH。umul()没有溢出，mul()溢出。对于无符号整数乘法运算，高n位全为0就足以说明运算结果没有溢出，否则溢出，理由略

错题总结：
- 三种溢出判别方法，均须有溢出判别电路，可用“异或”门来实现
- 存储模4补码仅需一个符号位，因为任何一个正确的数值，模4补码的两个符号位总是相同的。只在把两个模4补码的数送往ALU完成加减运算时，才把每个数的符号位的值冏时送到ALU的双符号位中，即只在ALU中采用双符号位
- 来自26题的B选项，非常复杂，三轮可以直接跳过，只记结论：**对于补码的不恢复余数除法，同号相除时**，那就和符号位不参与运算的原码不恢复余数法没有区别，也就是说，**够减（余数为正）商1，不够减（余数为负）商0；异号相除时**，则相反，**够减商0，不够减商1**。好奇推理过程，可参考：https://blog.csdn.net/H_define/article/details/125877290
- 补码表示时，正数的符号位为0，左移最高位为0时，数据不会丢失；负数的符号位为1，左移最高位为1时，数据也不会丢失。也就是说，左移移走的最高位要与符号位相同（才不会溢出）
- 大题第1题：网友-Jjonak：王道写的真误导人啊，讲课也没讲明白，直接就是一句符号位不动，数值位移动，做题目发现不对劲，查了查发现是**符号位也移动，只是没溢出的情况下符号位就好像没移动的意思**

**浮点数的表示：**
- 表示方法：N = ((-1) ^ S) × (R ^ E) × M
    - 数符 S：取值0或1，用来决定浮点数的符号
    - 阶码/指数 E：一个二进制定点整数，用移码表示
    - 尾数 M：一个二进制定点小数，一般用定点原码小数表示
        数符：浮点数的符号
        尾数：尾数数字部分
    - 基数（隐含） R：可以约定为2、4、16等
    - 阶码的值反映浮点数的小数点的实际位置，阶码的位数反映浮点数的表示范围，尾数的位数反映浮点数的精度
    - **浮点数的表示法也不止上面这一种，比如阶码也可以用原码表示，但比较统一的一点是，阶码往往在尾数的前面**
- 溢出问题：
    - 存在正上溢和负上溢（统称为上溢）问题（此时计算机必须进行中断处理）
    - 存在正下溢和负下溢（统称为下溢）问题（此时浮点数值趋于零，计算机仅将其当作机器零处理）
    - 也存在精度溢出问题（无法精确表示，只能舍入处理）
- 尾数规格化：调整尾数和阶码，保证尾数最高位是有效值1，这样可以提高运算精度，充分利用尾数有效位
    - 左规：尾数左边无效位太多，往左移，左规可多位。阶码减少，尾数增大
    - 右规：尾数运算溢出时要进行右规，右规最多一位。阶码增加，尾数减小
    - 原码规格化数（绝对值大于等于0.5）
        - 正数：0.1xxx
        - 负数：1.1xxx
        - 尾数最高位为1
    - 补码规格化数
        - 正数：0.1xxx
        - 负数：1.0xxx（注意：补码的-0.5不是规格化数，且补码下限可以为-1）
        - 符号位和尾数最高位相反
        - **大多数题目在规格化时都是IEEE754浮点数，但某些题目可能会指定尾数或阶码采用补码表示。通常采用双符号位，当尾数求和结果溢出（如尾数为10.××···×或01.××···×）时，需右规一次；当结果出现00.0××···×或11.1××···×时，需要左规，直到尾数变成00.1××···×或11.0××···×**
    - *基数不同，浮点数的规格化形式也不同。浮点数尾数的基数为2时，原码规格化数的尾数最高位一定是1。基数为4时，原码规格化形式的尾数最高两位不全为0*
- 浮点数在数轴上的分布：
    - 刻度并不均匀，越往右，浮点数越稀疏
![](https://api2.mubu.com/v3/document_image/95e59a35-5996-4253-b34e-dba717048f00-329792.jpg)
- 浮点运算不满足结合律：
    - 小数a + 大数b = 大数b（有可能）
    - 编程时浮点数比较要小心

**💎IEEE754标准：**
- 二进制浮点数
    - 数符S、阶码E和尾数M
    - 阶码采用移码表示
    - 尾数采用原码数据表示：隐藏高位1，运算时还原成1.M形式
    - 二进制浮点数无法精确表示一些十进制小数（0.1 0.2 0.4等转换成二进制都是循环小数）
    - 对32位单精度格式而言：S为1位，E为8位，采用偏移值为127的移码，M为23位
![](https://api2.mubu.com/v3/document_image/91eaba8b-3da0-4775-8fb7-ef9e3d1b9949-329792.jpg)
- 十进制浮点数
    - 可精确表示十进制浮点数，保证运算精度
    - 解决二进制浮点运算引起的误差问题
    - IEEE-754 2008标准中有定义
- IEEE754表示范围
    - **阶码为全1时，表示无穷大或非数，即：浮点数除零不会异常**
    - **阶码和尾码全零时表示机器零**
    - *阶码为零，尾数不为零时表示非规格化数*
    - *其他表示区间为规格化数*
    - 各类区间及浮点数的最大值、最小值问题：注意，0.111···1 = 1 - 2 ^ 23（常考）；注意，单精度非规格化是-126
![](https://api2.mubu.com/v3/document_image/d5bcad7b-9e5e-4969-921e-a55562f4106f-329792.jpg)
![](https://api2.mubu.com/v3/document_image/b0ed425c-8d6f-4e13-bbad-3b76df3ed2db-329792.jpg)

**💎浮点数加减运算（难）：**
- 对阶
    - 小阶向大阶看齐
    - 阶码增加，尾数右移
- 尾数运算
- 规格化
    - 尾数运算上溢：右归最多一位
    - 尾数规格化下溢：左归处理，可以多位
- 舍入处理
    - 0舍1入：舍去位最高位为1，尾数最低位加1，否则舍去。这样可能会使尾数溢出，此时需要再做一次右规
    - 恒置1法：舍去中有一位是1，尾数最低位置1
    - 截断法：直接截取所需位数，丢弃后面的所有位
- 溢出判断
    - 浮点数的溢出并不是以尾数溢出来判断的，尾数溢出可以通过右规操作得到纠正。运算结果是否溢出主要看结果的指数是否发生了上溢，因此是由阶码上溢来判断
    - 上溢：进入异常处理
    - 下溢：按机器零处理
- 注意IEEE754浮点数与采用补码表示阶码和尾数的浮点运算法则的相同和不同之处，考研有真题考到过！

**程序中的数据表示与运算（常考）：**
- 汇编语言中的数据类型
    - 寄存器、存储器操作数本没有数据类型
    - 对该数进行何种数据类型的操作完全取决于指令功能
    - 有符号运算、无符号运算、定点运算、浮点运算指令
- 💎C语言中数据类型
    - 整型
        - 有符号整型包括char、short、int、long
        - 分别采用8、16、32、64位补码进行表示
        - 通过unsigned声明为无符号类型
    - 整型运算溢出问题
        - 有符号整数和无符号整数、浮点数都存在运算溢出的问题
        - C语言不做溢出判断，需要程序员特别注意
    - 浮点型
        - C语言中常见的浮点数为float、double
        - 分别对应IEEE 754中的单精度和双精度浮点数
        - 不同数据类型的运算会在编译器的翻译下变成不同类型的汇编指令
    - 💎强制类型转换（难）
        - 相同位宽的整型数据进行强制转换时机器码保持不变
        - 小字长转大字长时，无符号整型进行零扩展，有符号整型进行符号扩展
        - 大字长转小字长时直接将机器码截短
        - float → double：由于double型数据的尾数、阶码宽度都比float型大，因此其表示范围更大、精度更高，转换后的 double 型数据与原 float 型数据完全相等
        - double → float：大数转换时可能发生溢出，高精度数转换时会发生舍入
        - float/double → int：小数部分会截断，大数转换时可能会溢出
        - int → float：两种类型都是 32 位，所表示的状态数是一样的，在数轴上表示的数据并不完全重叠，float 型用其中一部分状态表示了更大的整数和小数；- int 型中一些比较大的整数无法用float型精确表示。浮点数尾数连隐藏位在内一共24位，当int型数据的24～31位数据非0时，无法精确转换成 24 位浮点数的尾数，此时会发生精度溢出，需要进行舍入处理
        - int → double：浮点数尾数字段为 53 位，可以精确表示所有 32 位整数
        - 一些很有用的例子，回去慢慢看：
![](https://api2.mubu.com/v3/document_image/27750e8a-60b9-4faa-a47c-60a6d749286e-329792.jpg)

**王道习题：**

一轮标记题：5 7 10 12 13 14 17 20 21 22 23 24 25 27 28 29 30

二轮重做：5 7 17 21

大题：4 5 7 8
1.
- 答：
    - 阶码上溢出。一个正指数超过了最大允许值时，浮点数发生上溢出（即向 ∞ 方向溢出)。若结果是正数，则发生正上溢出（有的机器把值置为 +∞ ）；若结果是负数，则发生负上溢出（有的机器把值置为 -∞ ）。这种情况为软件故障，通常要引入溢出故障处理程序来处理
    - 阶码下溢出。一个负指数比最小允许值还小时，浮点数发生下溢出。一般机器把下溢出时的值置为 0（+0或-0）。不发生溢出故障
    - 尾数溢出。当尾数最高有效位有进位时，发生尾数溢出。此时，进行“右规”操作：尾数右移一位，阶码加 1，直到尾数不溢出为止。此时，只要阶码不发生上溢出，浮点数就不会溢出
    - 非规格化尾数。当数值部分高位不是一个有效值时（如原码时为 0 或补码时与符号位相同），尾数为非规格化形式。此时，进行“左规”操作：尾数左移一位，阶码减1，直到尾数为规格化形式为止

2.
- 解：略

3.
- 解：1)ture; 2)不一定true; 3)true; 4)不一定true

4.
- 解：1)好困，三刷的时候再算吧

5.
- 解：1)同上

6.
- 答：两个n位数的加减运算，其和/差最多为n+1位，因此有可能需要右规，但右规最多一次。由于异号数相加或同号数相减，其和/差的最少位数无法确定，因此左规的次数也无法确定，但最多不会超过尾数的字长n位次

7.
- 解：
    - 1)机器零，+0
    - 2)48
    - 3)非规格化数，-2 ^ -127
    - 4)负无穷大

8.
- 解：
    - 1) 会，原因略；不会，原因略；
    - 2) 相等；f1(23)返回值的机器数为00 FF FF FFH, f2(23)返回值的机器数为4B 7F FF FFH
    - 3) 浮点数的精度不够
    - 4) 超出int范围，溢出了；30
    - 5) 正无穷；126；23


错题总结：
- **对阶操作，是将较小的阶码调整到与较大的阶码一致，因此不存在阶码减小、尾数左移的情况**
- 与非规格化浮点数相比，采用规格化浮点数的目的主要是为了增加数据的表示精度
- 舍入是浮点数的概念，定点数没有舍入的概念。浮点数舍入的情况有两种：对阶、右规格化（注意，**右规可能引起阶码上溢，但对阶没这个可能**）。舍入不一定产生误差，如向下舍入11.00到11.0时是没有误差的
- 各类区间及浮点数的最大值、最小值问题：注意，0.111···1 = 1 - 2 ^ 23（常考）；注意，单精度非规格化，阶码是-126，没有隐含的高位1

#### （3）算术逻辑单元ALU

一位全加器：全加器（FA）是最基本的加法单元，逻辑表达式和逻辑电路如下：
![](https://api2.mubu.com/v3/document_image/d4b7af6f-4584-4804-b25b-82dbe4691705-329792.jpg)
![](https://api2.mubu.com/v3/document_image/e7354005-28dc-4b31-aad7-09d1c2c20423-329792.jpg)

**1）串行加法器和并行加法器**

串行加法器：
串行进位加法器：把n个加法器相连。串行进位又称行波进位，因为每级进位直接依赖于前一级的进位，即信号是逐级形成的。因此，**该加法器的运算速度和位数是线性关系**，位数越多，延迟时间就越长，而全加器本身的求和延迟只是次要因素。逻辑电路如下，注意其中的异或电路需要3T：
![](https://api2.mubu.com/v3/document_image/3eacad7e-b067-4be0-bb28-e2cbb58616f2-329792.jpg)
可控加减法电路：减法变加法，输入增加异或门，控制位送进位输入，逐位取反，末位加1。有符号无符号运算均适用，区别是溢出检测逻辑。逻辑电路如下：
![](https://api2.mubu.com/v3/document_image/4ab15384-9327-424e-ac65-4785220b98f7-329792.jpg)

并行加法器：
- 主要原理：采用先行进位电路提前得到所有进位位。因此，各位的求和运算可以并发运算。注意：先行进位电路也有开销和时间延迟
- 进位生成函数：
![](https://api2.mubu.com/v3/document_image/c28f2020-0709-4abd-8f1b-2032abfb35f8-329792.jpg)
- 进位传递函数：
![](https://api2.mubu.com/v3/document_image/7716ed85-94d2-4f8c-b49a-92ca21c371bc-329792.jpg)
- 进位信号仅仅与G，P，C0有关：
![](https://api2.mubu.com/v3/document_image/7dc167b8-b1ca-43a8-bc56-53a8c603f331-329792.jpg)
- 先行进位电路：
![](https://api2.mubu.com/v3/document_image/a96cee4e-04af-4fd9-8da2-4d699e861e40-329792.jpg)
- 四位快速加法器：
![](https://api2.mubu.com/v3/document_image/4d2ac825-0803-40cf-9ac5-45657dd1977c-329792.jpg)
- 先行进位电路级联：
![](https://api2.mubu.com/v3/document_image/4d959d83-ab59-4a96-9c0e-b602a6faa840-329792.jpg)
- 两级或多级先行进位方式：组内**并行**，组间**并行**

带标志加法器：增加生成相应的标志信息的逻辑电路：
- 溢出标志的逻辑表达式为OF = Cn ⊕ Cn-1，OF= 1表示带符号整数运算时发生溢出。对于无符号数运算，OF没有意义
- 符号标志就是和的符号，即SF = Fn-1，表示结果的符号，即F的最高位。对于无符号数运算，SF没有意义
- 零标志ZF = 1当且仅当F = 0，不管对于无符号数还是带符号整数运算，ZF都有意义
- 进位 / 借位标志CF =Cout ⊕ Cin（或者是记作Sub），即当Cin = 0（加法）时，CF为进位Cout，当Cin = 1（减法）时，CF为进位Cout取反。对于带符号数运算，CF没有意义

**2）算术逻辑单元ALU的功能和结构**

- 定点运算器
    - 算术逻辑运算单元ALU：算术逻辑运算单元是运算器的核心，由它实现算术逻辑运算
    - 通用寄存器组：通用寄存器组的作用是暂存参加运算的数据、运算的中间结果或最后结果
    - 输入选择电路：输入选择电路的作用是对若干个数据的输入进行选择或控制
    - 输出控制电路：输出控制电路对加法器的输出进行控制
- 💎运算器结构
    单总线结构：2个缓冲器，3个时钟完成运算
    双总线结构：1个缓冲器，2个时钟完成运算
    三总线结构：0个缓冲器，1个时钟完成运算
- 运算流水线
    - 浮点流水线，将浮点运算的步骤进行细分
    - 不提升单个运算的性能，优化密集型浮点运算性能
![](https://api2.mubu.com/v3/document_image/dba9a987-352f-4265-b9fa-abe403fc12f8-329792.jpg)

#### 其他

**字符与字符串：**

- ASCII码：国际通用的字符码，7位表示 128 个字符。实际占用 1 个字节，最高有效位 MSB = 0。有 33 个控制字符，其余为可打印字符：
    - 20H 开始是空格等可打印字符
    - 0 ～ 9 这 10 个数字是从 30H 开始的一个连续区域
    - 大写英文字母是从 41H 开始的一个连续区域
    - 小写英文字母是从 61H 开始的一个连续区域
- 汉字编码：
    - 输入码：汉字的输入。拼音，五笔等
    - 机内码：汉字的存储。GB2312、GBK、GB18030、Unicode、BIG5等标准
    - 字形码：汉字的输出
    - GB2312：
        - 区位码：矩阵形式，由4位十进制数构成，前2位区码，后2位位码
        - 汉字机内码：区位码（16进制）+ A0A0H（为区分ASCII码，MSB = 1），即：GB2312汉字占用两个字节，有效位14位
- 字符串：以"\0"结束的字符序列

#### 本章小结

- 用移码表示浮点数的阶码有什么好处？
    - 浮点数进行加减运算时要比较阶码的大小，移码比较大小更方便
    - 检验移码的特殊值（0和max）时比较容易。阶码以移码编码时的特殊值如下。0：表示指数为负无穷大，相当于分数分母无穷大，整个数无穷接近0，在尾数也为0时可用米表示0；尾数不为零表示未正规化的数。max：表示指数正无穷大，若尾数为0，则表示浮点数超出表示范围（正负无穷大）；尾数不为0，则表示浮点数运算错误
- 计算机内部的数值数据并非都是二进制数。在计算机内部，数值数据的表示方法有以下两大类：
    - 直接用二进制数表示。分为有符号数和无符号数，有符号数又分为定点数表示和浮点数表示。无符号数用来表示无符号整数（如地址等信息)
    - 二进制编码的十进制数，一般采用BCD码表示，用来表示整数
- 什么称为无符号整数的“溢出”？实际上，对于无符号定点整数来说，若寄存器位数不够，则计算机运算过程中一般保留低n位，舍弃高位。这样，会产生以下两种结果：
    - 保留的低n位数不能正确表示运算结果。在这种情况下，意味着运算的结果超出了计算机所能表达的范围，有效数值进到了第n+1位，称此时发生了“溢出”现象
    - 保留的低n位数能正确表达计算结果，即高位的舍去并不影响其运算结果
- 现代计算机中是否需要考虑原码加减运算？如果要，如何实现？
    - 因为现代计算机中浮点数采用IEEE 754标准，所以在进行两个浮点数的加减运算时，必须考虑原码的加减运算，因为IEEE 754规定浮点数的尾数都用原码表示。原码的加减运算可以有以下两种实现方式：
        - 1）转换为补码后，用补码加减法实现，结果再转换为原码
        - 2）直接用原码进行加减运算，符号和数值部分分开进行

### <a name="6">（三）存储器层次结构</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### （1）存储器的层次化结构

存储器分类：
- 按介质分
    - 磁存储器：机械装置，速度较慢，单位成本较低
    - 半导体存储：电子设备，速度快，单位成本高
    - 光存储器：便于携带，成本低廉，适合电子出版
- 按存取方式分
    - 顺序（串行访问）存储器：访问时间与存储单元位置有关，如磁带
    - 随机存储器：访问时间与存储单元位置无关，如半导体
    - 直接存储器：顺序、随机的折中，如磁盘、光盘
- 按信息的**可改写性**分
    - 读写存储器RAM
    - 只读存储器ROM
- 按信息的**可保存性**分
    - 易失性：掉电数据丢失，如SRAM，DRAM等
    - 非易失性：掉电数据不丢失，如磁盘，闪存等
- 按存储功能和速度分：寄存器、cache、主存、外存等

**主要技术指标：**
- 存储容量：存储器可以存储的二进制信息总量
- 存取时间：启动一次存储器的操作到该操作完成所经历的时间
- **存取周期：**
    - 又称**读写周期**或**访问周期**或**存储周期**
    - 连续启动两次访问操作之间的最短时间间隔
    - 存储周期大于存取时间，用户读写操作后复原
- 存储器带宽：单位时间内存储器所能传输的信息量

**存储器的层次化结构：**

- 存储器的层次结构
  - 理想存储器
    - 速度快、容量大、成本低（做梦）
  - 基本原理
    - 💎利用程序局部性的原理，从系统级将速度、容量、成本各异的存储器有机组合在一起，从而全方位优化存储系统的各项性能指标，构建理想存储器
    - 上层给下层做缓冲，提升命中率，让数据尽量在上层访问，详见cache机制
    - 现代计算机系统几乎都采用这种三级存储系统。需要注意的是，主存和Cache之间的数据调动是由硬件自动完成的，对所有程序员均是透明的；而主存和辅存之间的数据调动则是由硬件和操作系统共同完成的，对应用程序员是透明的
  - 层次结构![img](https://api2.mubu.com/v3/document_image/24bf5abb-4196-49c2-854e-2396a4af972e-329792.jpg)

**王道习题：**

一轮标记题：7 12

二轮重做：12

大题：2
1.
- 解：90% × 5ns + 10% × x = 12ns，解得x = 75ns

2.
- 解：牢记：*Cache/主存系统效率 = 访问Cache时间 / 平均访问时间*，这里平均时间为60ns，所以效率为83.3%

错题总结：
- 若采用**同时**访问Cache和主存的方式，则不命中的访问时间就是访问主存的时间，但若题设中没有说明(通常会说明)，则默认Cache不命中的时间为访问Cache和主存的时间之和

#### （2）主存储器与CPU的连接

主存的基本结构：
- 原理图![img](https://api2.mubu.com/v3/document_image/9bb46d83-e010-43fe-8e37-316b79e1ab1e-329792.jpg)
- 💎地址与容量关系
    - 地址译码器
        - 最小项生成器
        - 给出一个地址，只有唯一一根输出有效，选中一个存储体单元      
    - n位地址经过译码器产生2 ^ n个译码线   
    - 已知容量为C，地址线根数为log2C
    - C语言中的指针实际就是内存单元地址，所有指针变量是**无符号类型**
- 存储器芯片的组成
    - 存储体+IO/读写电路+地址译码器+片选控制信号+读写控制信号
    - 读RD/写WR控制线：决定芯片是进行读还是写操作
    - 片选线CS：确定哪个存储芯片被选中。可用于容量扩充
    - 引脚最低数目 = 片选线（至少1）+ 控制线（1或2, 读RD写WR）+ 数据线 + 地址线

💎主存中数据的存放：
  - 存储单元
    - **存储单元的大小和机器字长相关**
    - **一个存储周期可以访问一个机器字长的存储单元（关于存储字长，这个词大概率是个已经被淘汰或者说根本不存在的词语！详见知乎：https://www.zhihu.com/question/293885327）**
    - 64位计算机一次可以访问64位的数据
  - 💎地址访问模式
    - **存储单元可按不同的大小访问**（**都是一个存储周期**）
    - 百度百科：**存放一个机器字的存储单元，通常称为字存储单元，相应的单元地址叫字地址。而存放一个字节的单元，称为字节存储单元，相应的地址称为字节地址。如果计算机中可以编址的最小单元是字存储单元，则该计算机称为按字寻址的计算机**。如果计算机中可编址的最小单位是字节，则该计算机称为按字节寻址的计算机。如果机器字长等于存储器单元的位数，一个机器字可以包含数个字节，所以一个存储单元也可以包含数个能够单独编址的字节地址。例如一个16位二进制的字存储单元可存放两个字节，可以按字地址寻址，也可以按字节地址寻址。当用字节地址寻址时，16位的存储单元占两个字节地址
    - 王道：**地址码相同**的多个存储元（存放一个二进制位的物理器）构成一个存储单元
      - 字节访问、半字访问、字访问（机器指令支持）
      - 字节地址、半字地址、字地址
        - 实际计算机中只有字节地址
        - 半字地址 = 字节地址 << 1（相对字节地址少1根）
        - 字地址 = 字节地址 << 2（相对字节地址少2根）    
    - 不同地址访问模式![img](https://api2.mubu.com/v3/document_image/d86e9af0-38f8-4879-9fde-d559dbc27f89-329792.jpg)
  - 💎大端小端方式
    - 小端方式：存储器的低字节地址单元中存放的是数据的最低字节
    - 大端方式：存储器的低字节地址单元中存放的是数据的最高字节
  - 💎数据的边界对齐
    - 有利于减少访问时间，但会造成主存空间浪费
    - short按双字节对齐
    - float类型按4字节对齐
    - double按8字节对齐
    - 复杂数据结构也会考虑对齐问题

**主存储器与 CPU 的连接：**
- 💎存储扩展
  - 位扩展：（数据总线扩展）
    - 数据总线宽度不匹配：字位扩展 = 字长扩展 = 数据总线扩展
      - 多芯片并发：提供更多的数据位
      - 📈字长扩展原理图
        - ![img](https://api2.mubu.com/v3/document_image/add319f8-9fbd-411f-b719-8a7c8a54be8d-329792.jpg)
  - 字扩展：（地址总线控制）
    - 地址总线宽度不匹配：字数扩展 = 容量扩展 = 地址总线扩展
      - 高位用译码器进行芯片片选
        - 如果低位片选就变成了交叉编制模式
        - 译码器的功能就是最小项生成器
      - 多芯片串行：同一时刻只有一个芯片工作
      - **需明确每个存储芯片在全局范围内的地址空间**
      - 字数扩展原理图
        - ![img](https://api2.mubu.com/v3/document_image/dfb29104-4172-4b74-a1ab-c5ddaf83b2d9-329792.jpg)
  - 字位同时扩展
    - 二者都不匹配：综合扩展
      - 📈![img](https://api2.mubu.com/v3/document_image/c016dbb5-adfd-4215-ab20-c11dbfa90494-329792.jpg)
- 存储芯片的地址分配和片选
    - 先片选，再字选
    - 片选又分为线选法和译码片选法，注意前者是低电平有效
- 存储器与 CPU 的链接
    1. 合理选择存储芯片：ROM存放系统程序、标准子程序和各类常数，RAM为用户编程设置
    2. 地址线的连接：CPU地址线低位与存储芯片的地址线相连，高位连接译码器用于片选
    3. 数据线的连接
    4. 读/写命令线的连接：有些CPU的读/写命令线是分开的（读为RD，写为WE，均为低电平有效），此时CPU的读命令线应与存储芯片的允许读控制端相连，而CPU的写命令线则应与存储芯片的允许写控制端相连
    5. 片选线的连接：片选有效信号与CPU的访存控制信号MREQ（低电平有效）有关，因为只有当CPU要求访存时，才要求选中存储芯片。若CPU访问IO，则MREQ为高，表示不要求存储器工作

双口RAM和多模块存储器：
  - 双端口存储器
    - 一个存储器，两套独立读写逻辑，带宽提升一倍
    - 两端口存在访问冲突
      - 同一单元同时写
      - 同一单元一读一写
    - 图解
      - ![img](https://api2.mubu.com/v3/document_image/22e50af8-7a90-452c-89c5-d04dd5524d3e-329792.jpg)
  - 单体多字存储器
    - 一个地址，多个存储字，多个存储单元并发
    - 扩大了数据总线宽度
    - 双通道内存
      - 📈联动模式和非联动模式双通道内存![img](https://api2.mubu.com/v3/document_image/9ef46be6-5dc6-4909-8764-38fd6fb9af56-329792.jpg)
  - 多体交叉存储器
    - 顺序编址：高位片选，用于扩充容量，存在单点故障
    - 交叉编址：低位片选，用于提升速度（提高带宽），流水方式访问
        - 计算：**设模块字长等于数据总线宽度**，模块存取一个字的存取周期为T，总线传送周期为r，为实现流水线方式存取，存储器交叉模块数应大于等于**m=T/r**，式中，**m称为交叉存取度**。每经过r时间延迟后启动下一个模块，交叉存储器要求其模块数必须大于等于m，以保证启动某模块后经过 m × r 的时间后再次启动该模块时，其上次的存取操作已经完成（即流水线不间断）。这样，连续存取m个字所需的时间为**T+(m-1)r**
        - 对比：顺序方式连续读取m个字所需的时间为mT。可见低位交叉存储器的带宽大大提高
    - 📈图解
      - ![img](https://api2.mubu.com/v3/document_image/444f9292-c04c-41f3-820e-98ebdecbedc7-329792.jpg)

**王道习题：**

一轮标记题：10 13 14 17

二轮重做：14(看不懂题目) 16 17

大题：3 5
1.
- 解：
    - 在主存储器中，地址寄存器MAR用来存放当前CPU访问的内存单元地址，或存放CPU写入内存的内存单元地址。数据寄存器MDR用来存放由内存中读出的信息或写入内存的信息
    - 1) 按字节编址，1MB = 2^20×8位，地址寄存器为20位，数据寄存器为8位，编址范围为00000H ~ FFFFFH (FFFFFH - 00000H + 1 = 100000H = 2^20)
    - 2) 按字编址，1MB = 2^18x32位，地址寄存器为18位，数据寄存器为32位，编址范围为00000H～3FFFFH (3FFFFH - 00000H + 1 = 40000H = 2^18)

2.
- 解：
    - 1) 32, 22
    - 2) 32
    - 3) 在CPU的22根地址线中(A0 ~ A21)，地址线的作用分配如下：首先，此时不需要指定A0、A1来标识每组中的4片存储器，**因为此时是按字寻址的，所以4片每次都是一起取的**，而不是按字节编址时需要取4片中的某一片。A0 ~ A18：每片都是512K，所以需要19位来表示。A19、A20、A21：因为在扩展中4片一组，一共有8组，所以需要用3位地址线来决定取哪一组（通过3/8译码器形成片选信号）

3.
- 解：
    - 1) 64
    - 2) 采用异步刷新方式，在2ms时间内分散地把芯片64行刷新一遍，因此刷新信号的时间间隔为2ms/64=31.25μs，即可取刷新信号周期为31μs。注意：刷新周期也可取30μs，只要小于31.25μs 即可，但**通常取刷新间隔的整数部分**

4.
- 解：
    - 1) 256K × 32容量的存储器
    - 2) 18
    - 3) 略

5.(加入改错本，无需画图，主要**练习地址范围**)
- 解：略

错题总结：
- 实际的主存容量不能代表MAR的位数，考虑到存储器扩展的需要，MAR应保证能访问到整个主存地址空间，反过来，MAR的位数决定了主存地址空间的大小

#### （3）高速缓冲存储器(Cache)

1）Cache的基本工作原理

-  主要思路
    - 💎CPU 与主存之间增加一个隐藏的小容量的快速的SRAM 存储器，将 DRAM 主存中经常访问或即将访问的数据的副本调度到 SRAM中，使得大部分数据访问都可以在快速的 SRAM 中进行，从而提升系统读性能，写性能可以通过写回策略提升。![img](https://api2.mubu.com/v3/document_image/4668a5e0-ca8e-4237-90c8-741c553ca788-329792.jpg)
- 程序局部性原理
    - 时间局部性
        - 当程序访问一个存储位置时，该位置在未来可能会被多次访
        - 常用变量、程序的循环结构和过程调用
    - 空间局部性
        - 一旦程序访问了某个存储单元，则其附近的存储单元也即将被访问。
        - 数组、结构体、顺序指令
- 常用术语
    - 数据块：主存，cache均划分位大小相同的块
        - 块具有预读的作用
        - 块过大时间局部性利用不佳
        - 块过小空间局部性利用不
    - cache行，槽：包括数据副本和描述数据副本的元数据
        - 标记、标志、置换标志
    - 命中hit、缺失miss
    - 命中率、缺失率![img](https://api2.mubu.com/v3/document_image/b00d884f-85d9-4029-9f8c-92e5a8faeddb-329792.jpg)
    - 平均访问时间![img](https://api2.mubu.com/v3/document_image/e4f3293b-4747-4512-995d-4865464a86bf-329792.jpg)
    - cache访问效率![img](https://api2.mubu.com/v3/document_image/22a9c850-bf81-4ebc-9124-45e02812439c-329792.jpg)

2）Cach和主存之间的映射方式

💎查找机制：
- 硬件查找：相联存储器
    - 不按地址进行访问，按内容进行访问
    - 所有存储单元与关键字并发比较
    - 成本高：需要多路比较器
    - 📈图解![img](https://api2.mubu.com/v3/document_image/67ac43d8-48d4-41e3-b317-a5bcb5de114d-329792.jpg)

💎映射机制：
- 全相联
    - 基本特征
      - 主存块可以映射到任何一个cache行
      - 查找时**n路并发比较，硬件成本高**
      - 命中率高，cache利用率高
      - **cache满时需要淘汰算法**
    - 全相联cache容量计算
      - cache行内容
        - valid位（区分是否有数据）
        - 主存块地址tag
        - 数据块副本
        - *脏数据位*
        - *置换标记位*
        - **cache容量 = 行数 × cache行容量**
    - 全相联图解
      - 只是成本高，其访问速度比直接相联更快
      - 📈![img](https://api2.mubu.com/v3/document_image/bdc6007c-25a3-4b4d-90b9-469641d482cf-329792.jpg)
    - 全相联工程实现
      - **CPU与cache之间交换的单位是字**
      - **cache与主存交换单位是块**
      - 📈![img](https://api2.mubu.com/v3/document_image/7dc07942-b078-4923-9e08-df77d634d3e3-329792.jpg)
- 直接相联（映射）
    - 基本特征
      - 主存块只能映射到唯一的cache行
      - 查找时只需一个比较器，**硬件成本低**
      - 命中率低，cache利用率低
      - **无淘汰算法，有冲突，直接置换**
      - 直接相联cache容量计算：
        - cache行内容
          - valid位（区分是否有数据）
          - 区地址（标记）
          - 数据块副本
          - *脏数据位*
          - *置换标记位*
        - **cache容量 = 行数 × cache行容量**
    - 直接相联图解
      - 📈![img](https://api2.mubu.com/v3/document_image/68157b76-9fbe-42cf-82d4-9ff55dceb1d2-329792.jpg)
    - 直接相联工程实现
      - 📈增加了行索引译码器，所以其访问延迟比全相联慢![img](https://api2.mubu.com/v3/document_image/24c685a3-d04b-4256-80f6-96fe810a02d8-329792.jpg)
- 组相连
    - 折中实现，是直接相联和全相联的通用模型
    - **查找成本，命中率，利用率折中**
    - 地址划分对比
      - r=0 全相联  d=r 直接相联
      - 📈搞懂组相联，其他两个都ok，注意地址划分![img](https://api2.mubu.com/v3/document_image/1f097604-0d3a-4ee1-b006-d430bcefebc3-329792.jpg)
    - 📈组相联有两种方式，考研第一次出现的时候出现歧义![img](https://api2.mubu.com/v3/document_image/31f9fbc6-bf2e-4bb0-ab99-fb788820c5a8-329792.jpg)
      - 这里只关注最容易理解的一种
    - 工程实现
      - 📈成本低，多路比较器数目变少![img](https://api2.mubu.com/v3/document_image/d5ee1d0c-d214-4fc3-a53e-6fba5778e7aa-329792.jpg)

3）Cache中主存块的替换算法与写策略

替换策略：
- FIFO  先进先出
    - 每个数据块一个计数器（硬件成本）
    - 每次访问所有计数器+1
    - 替换计数值最大的行（时间最久）
    - 容易出现**颠簸现象**
- LFU 最不经常使用
    - 每个数据块一个计数器（硬件成本）
    - 访问命中的块计数器+1
    - 替换计数值最小的行（访问次数最少）
    - 历史访问计数并不能反映当前热度
- LRU 近期最少使用
    - 每个数据块一个计数器（硬件成本）
    - **访问命中的计数器清零**
    - 替换计数值**最大**的行（近期最少使用）
    - 近期最少使用，能反映当前数据热度，命中率高
- RAND 随机替换
    - 无计数器，成本最低，命中率低
    - **随机不一定效率低**，在虚存TLB中采用

写策略：
- 写入策略：
    - 写回（write-back）
        - 产生不一致性，有脏数据，写响应快
        - 提升写速度，减少访存次数
    - 写穿（write-through）
        - 不一致性，无脏数据，写响应慢
- 写分配策略：写入缺失时是否分配cache块（write-allocate和not-write-allocate）

💎cache读写基本流程：
- cache读流程
    - 命中直接访问cache，确实访问主存，并将数据块载入cache![img](https://api2.mubu.com/v3/document_image/aec85843-7046-42ea-a1cc-4a3ad191fe1b-329792.jpg)
- cache写流程
    - 命中根据写入策略写入，不命中根据写分配策略写入![img](https://api2.mubu.com/v3/document_image/14b6d7f2-bffc-4bb3-8047-6b94d66f0408-329792.jpg)

4）多层次Cache性能计算

见大题解答

**王道习题：**

一轮标记题：1 2 5 7 8 10 11 12 13 14 15 16 20

二轮重做：5 11 12 14 15(结合14) 19 20

大题：
1.
- 解：显然，1)应该写回，2)应该写穿

2.
- 解：略

3 ~ 9.
- 待做


错题总结：
- 什么是Cache地址？什么又是Cache的内容？实际上，**Cache地址应该是：块号 + 块内地址**。Cache行的内容是分为：标记阵列容量（替换算法控制位、脏位、标记项、有效位）+ 每行存储的数据。
- **主存容量 / Cache容量 = 标记项位数**
- 主存单元号（**字块号**） / 组相联路数 = 组号
- 采用指令Cache与数据Cache分离的主要目的是减少指令流水线资源冲突，因为把指令Cache与数据Cache分离后，取指和取数分别到不同的Cache中寻找，则**指令流水线中取指部分和取数部分就可以很好地避免冲突**，即减少了指令流水线的冲突
- 形如a[i] = a[i] + 1这种形式的时空局部性代码时，一定要注意的是，它包含了**一次读**与**一次写**

#### （4）虚拟存储器

1）虚拟存储器的基本概念

基本概念：在硬件和OS联合管理下，将磁盘空间、内存空间构成一个更大的虚拟地址空间，让更多的更大的程序在有限的内存空间运行，主要作用是扩大主存地址空间，进行存储保护
- 采用了类似cache的技术
    - 相同之处
        - 将经常访问的数据放到快速存储器中
        - 提升性能
        - 数据分块或分页
    - 不同之处
        - **cache解决性能问题，VM解决容量问题**
        - cache硬件实现，VM软硬协同
        - cache透明，**VM对应用程序员透明，对系统程序员不透明**
        - VM确实性能损失过大
- 实例
    - Windows页面文件，交换分区
    - 实模式：物理地址模式，嵌入式系统，OS引导之前
    - 保护模式：虚拟地址模式，OS引导之后
- 分类
    - 页式虚拟存储器（**考研重点，多次和cache一起考，结合OS一起复习**）
        - 以固定大小页为单位，常见4KB，也有更大的页
        - 无碎片，存储共享保护不方便
    - 段式虚拟存储器（OS课程复习，组成未考过）
        - 以段为单位，存储共享保护容易、易产生碎片
    - 段页式（OS课程复习，组成未考过）
- 具体见OS

2）页式虚拟存储器

- 见OS

3）TLB(快表)

- 💎CPU访存过程：可以无视右上角的“页表块cache命中”部分，我们默认直接访问主存页表
    - 📈流程图![img](https://api2.mubu.com/v3/document_image/7fda6601-0fb7-40c8-b34b-8c738fe710e5-329792.jpg)
    - 命中组合：
        - 访存零次（1）、访存一次（2、3）、访存两次（4）、访存两次 + 外存（5）
        - **注意三种不可能的情况**，为什么它们不可能？→ 关键看**页有没有缺失**
        - 📈![img](https://api2.mubu.com/v3/document_image/4ddfab15-9f4a-44fd-b0e4-3aae26d3f6a9-329792.jpg)
- 具体的地址翻译计算见本文OS部分，以及王道OS的p221（加入改错本√）

**王道习题：**

一轮标记题：2 3 5 11 12

二轮重做：11

大题：只做真题即可，其中第5题与OS重复
1.
- 解：读一遍题目：虚拟地址24位，物理地址20位，页内偏移12位，Cache直接映射（行索引3位），块内偏移5位
    - 1) 24；12；20；8
    - 2) 12 + 3 + 5
    - 3) 在主存中；对应物理地址04C60H, 对应标记为04C, 不命中
    - 4) TLB组索引为1位，标记为11位，则024BACH的标记为012H，在主存中


6.
- 解：读题：物理地址24位，虚拟地址30位，页偏移12位，TLB组索引3位
    - 1) 前18位，后12位
    - 2) 前15位，中3位
    - 3) 4号
    - 4) 页号增加2位，页框号不变，因此TLB表项增加2位

错题总结：
- 见OS

####  （5）其他

半导体存储器：CPU - SRAM - DRAM - ROM
- SRAM存储器
  - SRAM读写原理
    - 读出：行列同时选通，位线数据差分放大检出
    - 写入：行列同时选通，数据从位线写入
    - SRAM读写原理详解
      - 📈SRAM读原理![img](https://api2.mubu.com/v3/document_image/2e4c5365-ac5c-4b36-a4dc-232c76464eb6-329792.jpg)
        - 同时给出行选和列选信号，打开T5，T6，T7，T8门控管
        - 将I/O以及~I/O信号经I/O电路放大得到数据
      - 📈SRAM写原理![img](https://api2.mubu.com/v3/document_image/e2b09ac8-d011-47e7-8364-a1cee43a7302-329792.jpg)
        - 同时给出行选和列选信号，打开T5，T6，T7，T8门控管
        - 将写入数据加载在I/O以及~I/O端
  - SRAM特征
    - 性能好，读写对称，性能一样
    - **功耗大，存储密度低，单位容量成本高**
  - SRAM芯片
    - 数据总线双向
- DRAM存储器
  - 访问过程
    - 预充、访问、信号检测、数据恢复、数据读/写
  - DRAM特性
    - **行列分时选通，相比SRAM速度慢，电容会泄露丢失数据，需要定时刷新**
    - **功耗低，存储密度高，价格便宜，速度慢**
  - **DRAM刷新**
    - **按行刷新**：刷新行地址由刷新控制器提供
    - *最大刷新周期：信息存储到数据丢失之前的这段时间*
    - 集中刷新：集中安排时间刷新，**存在死区**，CPU长时间得不到响应
    - 分散刷新：**一个存储周期细分为CPU访内和刷新两部分，存储周期变慢（缺点极大）**
    - 异步刷新
      - 在最大刷新周期内每隔一段时间t（**将刷新周期除以行数**）刷新一行
      - 效率最高
    - 刷新时不需要选片，即整个存储器中的所有芯片同时被刷新
  - DRAM芯片
    - **行列地址复用，地址线减半，数据输入，输出分开，数据线倍增**
  - DDR存储带宽(了解)
    - 以 DDR4-3200 为例
      - 3200 为等效传输频率 f，单位为 MHz
      - 数据位宽 w = 8 字节
    - 则内存带宽 B = f × w = 3200 × 8 = 25.6GB/s
    - 由于时钟上跳沿和下跳沿各完成一次数据传输，因此数据总线频率为 3200/2 = 1600MHz，
    - DRAM 的工作频率为 1600MHz/8 = 200MHz （DDR2/3/4  频率倍数分别是2,4,8）
    - 有兴趣可以了解下DRAM存储带宽计算![img](https://api2.mubu.com/v3/document_image/755032f5-1628-422f-816a-36087261caa9-329792.jpg)
- 只读存储器
  - ROM  
    - 只读存储器
    - 利用开关电路存储数据
  - PROM  
    - 可编程一次
    - 利用熔丝或反向二极管存储数据
  - EPROM  
    - 可擦除可编程
    - 利用浮置栅存储数据
    - 紫外线擦除，高压写入
  - EEPROM  
    - 电可擦除
    - 在EPROM基础上增加控制栅极
- Flash存储器
  - 闪存，和EEPROM类似
  - U盘，SSD固态盘使用该技术
  - 固态硬盘由控制单元和存储单元（Flash芯片）组成。**保留了Flash存储器长期保存信息、快速擦除与重写的特性。对比传统硬盘也具有读写速度快、低功耗的特性**，缺点是价格较高

**王道习题：（961不知道考不考，大题待做）**

一轮标记题：1 6 7 9 12 14 15 16 17 18 19 22 25

二轮重做：7 9 14 17 18(题出得不是很好) 19 25

错题总结：
- RAM属于易失性半导体，SRAM和DRAM的区别在于是否需要动态刷新
- 地址复用的DRAM需要**行选通和列选通**的引脚，而片选线可由行选线替代
- DRAM的读并不是把信息读入CPU，也不是从CPU向主存存入信息，它只是把信息读出，通过一个刷新放大器后又重新存回存储单元，而刷新放大器是集成在DRAM上的。因此，这里只进行了一次访存，也就是**占用一个存取周期**
- 闪存的存储元由MOS管组成，是一种半导体存储器
- 25题：这题也很有迷惑性，我们探讨交叉编址的前提一般是：**模块字长等于数据总线宽度**，而这里是32位的总线可以同时读4个模块。但读取x依旧需要三个周期，因为double型变量应该按字对齐，也就是最后两位应该为00，但这里的804 001AH，最后两位为10，没有按字对齐的后果就是要多读一个周期

#### 本章小结

- 计算机如何管理存储器的层次？
    - **主存与Cache之间的信息调度功能全部由硬件自动完成**。**而主存与辅存层次的调度**目前广泛采用虚拟存储技术实现，即将主存与辅存的一部分**通过软/硬结合**的技术组成虚拟存储器，程序员可用这个比主存实际空间（物理地址空间）大得多的虚拟地址空间（逻辑地址空间）编程，当程序运行时，再由软/硬件自动配合完成虚拟地址空间与主存实际物理空间的转换。因此，**这两个层次上的调度或转换操作对于程序员来说都是透明的**
- Cache行的大小和命中率之间有什么关系？
    - 行的长度较大，可以充分利用程序访问的空间局部性，使一个较大的局部空间被一起调到Cache中，因而可以增加命中机会
    - 但是，行长也不能太大，主要原因有两个，一是会使失效损失变大。也就是说，若未命中，则需花更多时间从主存读块。二是行长太大，Cache项数变少，因而命中的可能性变小

## <a name="10">操作系统</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

### <a name="11">（一）操作系统概述</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### a)操作系统的基本概念；内核态与用户态、中断、异常和系统调用。

**操作系统的基本概念：**

操作系统：控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便接口与环境的程序集合

操作系统的特征：
- 并发（Concurrence）
- 共享（Sharing）：分为互斥共享方式和同时访问方式
- 虚拟（Virtual）：时分复用，如处理器的分时共享；空分复用，如虚拟存储器
- 异步（Asynchronism）：进程以不可预知的速度向前推进

操作系统的目标和功能：
- 四个「管理」
- 作为用户与计算机硬件系统之间的接口：分为命令接口和程序接口，前者又分为联机命令接口和脱机命令接口
- 实现对计算机资源的扩充

**王道习题：**

二轮重做：10 17

大题：
1.
- 解：略
- 答：**库函数是语言或应用程序的一部分，可以运行在用户空间中。而系统调用是操作系统的一部分，是内核为用户提供的程序接口，运行在内核空间中，而且许多库函数都会使用系统调用来实现功能。未使用系统调用的库函数，其执行效率通常要比系统调用的高，因为使用系统调用时，需要上下文的切换及状态的切换（也就是由用户态转向核心态）**

**操作系统的运行环境：**

处理器运行模式：
- 核心态 / 管态 / 内核态：操作系统的管理程序执行时处理机所处的状态。在此状态下处理机可使用全部指令（包括特权指令）；可以使用全部系统资源（包括整个存储区域）。以下内容的指令操作都工作在核心态：
    - 时钟管理：提供系统时间；通过时钟中断来实现进程的切换
    - 中断机制：只有一小部分功能属于内核，负责保护和恢复中断现场的信息，转移控制权到相关的处理程序
    - 原语：操作系统最底层；具有原子性；运行时间短且调用频率高
    - 系统控制的数据结构及处理：进程管理、存储器管理、设备管理
    - 注意：**切换到用户态的指令也是特权指令**
- 用户态 / 目态：用户程序执行时处理机所处的状态。在此状态下禁止使用特权指令，不能直接取用资源与改变机器状态，并且只允许用户程序访问自己的存储区域
    - 转到核心态的时机：用户程序访问系统资源（访管中断）、中断（I/O、时钟、通信等）、异常（故障、终止）
    - 注意：访管指令显然不可能是特权指令
    - 注意：**由用户态进入核心态，不仅状态需要切换，而且所用的堆栈也可能需要由用户堆栈切换为系统堆栈，但这个系统堆栈也是属于该进程的**

中断、异常、系统调用：
- 中断（Interruption）：也称**外中断**，指某个事件 (例如电源掉电、I/O传输结束等) 发生时，系统中止现行程序的运行、引出处理事件程序对该事件进行处理，处理完毕后返回断点继续执行的过程。**外中断可分为可屏蔽中断和不可屏蔽中断**。可屏蔽中断是指通过 INTR 线发出的中断请求，通过改变屏蔽字可以实现多重中断，从而使得中断处理更加灵活。不可屏蔽中断是指通过 NMI 线发出的中断请求，通常是紧急的硬件故障，如电源掉电等。此外，异常也是不能被屏蔽的
- 异常（Exception）：也称**内中断**，是由处理机内部事件引起的中断，**可分为故障（Fault）、自陷（Trap）、终止（Abort）**。异常可分为故障、自陷和终止。故障（Fault）通常是由指令执行引起的异常，如非法操作码、缺页故障、除数为0、运算溢出等。自陷（Trap）是一种事先安排的“异常”事件，用于在用户态下调用操作系统内核程序，如条件陷阱指令。终止（Abort）是指出现了使得CPU无法继续执行的硬件故障，如控制器出错、存储器校验错等。**故障异常和自陷异常属于软件中断（程序性异常)，终止异常和外部中断属于硬件中断**
- 系统调用：运行于核心态，功能大致可分为设备管理、文件管理、进程控制、进程通信、内存管理这五类

**王道习题：**

二轮重做：3 9 18 19 22 26 27 28

大题：
1.
- 解：略
- 答：区分执行态的主要目的是保护系统程序。用户态到核心态的转换发生在中断产生时，而核心态到用户态的转换则发生在中断返回用户程序时

2.
- 解：略
- 答：CPU操作与外设传输在时间上的重叠必须有中断和通道技术的支持，原因如下：
    - 通道是一种控制一台或多台外部设备的硬件机构，它一旦被启动就独立于CPU运行，因而做到了输入 / 输出操作与CPU并行工作
    - 中断就是在输入 / 输出结束时，或硬件发生某种故障时，由相应的硬件（即中断机构）向CPU发出信号，这时CPU立即停下工作而转向处理中断请求，待处理完中断后再继续原来的工作
    - 因此，通道技术和中断技术结合起来就可实现CPU与I/O设备并行工作，即CPU启动通道传输数据后便去执行其他程序的计算工作，而通道则进行输入/输出操作；当通道工作结束后，再通过中断机构向CPU发出中断请求，CPU则暂停正在执行的操作，对出现的中断进行处理，处理完后再继续原来的工作。这样，就真正做到了CPU与I/O设备并行工作

错题总结：
- 系统调用需要触发trap指令，如基于x86的Linux系统，该指令为int 0x80或sysenter。也就是说，用户程序设计时，使用的中断是内中断，其指令称为访管指令或trap指令
- 时钟中断的主要工作是处理和时间有关的信息及决定是否执行调度程序。和时间有关的所有信息包括系统时间、进程的时间片、延时、使用CPU的时间、各种定时器
- 计算机通过**硬件**机制完成由用户态到核心态的转换，而不是所谓“中断处理程序”，后者一般在核心态执行
- 子程序调用只需保存程序断点，即该指令的下一条指令的地址；中断处理不仅要保存断点(PC的内容)，还要保存程序状态字寄存器（PSW)的内容。**在中断处理中，最重要的两个寄存器是PC和PSWR**
- 当CPU检测到中断信号后，**由硬件自动保存被中断程序的断点(即程序计数器PC)**，之后，硬件找到该中断信号对应的中断向量，中断向量指明中断服务程序入口地址（各中断向量统一存放在中断向量表中，该表由操作系统初始化)。接下来开始执行中断服务程序，**保存PSW、保存中断屏蔽字、保存各通用寄存器的值**，并提供与中断信号对应的中断服务，中断服务程序属于操作系统内核
- 事件大总结：
    - *可能在用户态发生的事件：访管指令（只能）；**系统调用**；读时钟指令；取数指令；寄存器清零；跳转指令；设置断点指令；数据传送指令；压栈指令；从内存中取数；将运算结果装入内存；算术运算；命令解释；外部中断；各类异常（如缺页中断、trap指令）*
    - *只能在核心态发生的事件：广义指令（也就是系统调用）；置时钟指令；关中断指令；输入 / 输出；缺页处理；时钟中断处理；进程调度；进程切换；**设备管理、文件管理、进程控制、进程通信、内存管理**（也就是系统调用的细分功能）*

#### b)其他

操作系统发展历程：
- 手工操作阶段→联机批处理→脱机批处理→执行系统（左边三个均为单道批处理系统）→多道批处理系统/分时系统/实时系统→
- 单CPU计算机配置的操作系统：批量操作系统、分时操作系统、实时操作系统、个人计算机操作系统
- 具有并行结构的计算机系统配置的操作系统：网络操作系统（计算机网络，松耦合）、集群操作系统（分布存储的多计算机系统）

操作系统结构：
- 单体结构 / 模块结构：操作系统由多个模块构成，各模块可相互调用。优点：代码执行效率比较高。缺点：规模扩大时，难以维护、调试。操作系统实例：UNIX、Linux
- 层次结构：层次结构是把操作系统划分为若干层，各层之间只能是单向依赖或单向调用关系，这样不但系统结构清晰，而且不构成循环。优点：整体问题局部化，系统的正确性可通过各层正确性来保证。增加、修改或替换层次不影响其他层次，有利于系统的维护和扩充。缺点：层次结构是分层单向依赖的，必须要建立模块（进程）间的通信机制，系统花费在通信上的开销较大，系统的效率也就会降低
![](https://files.catbox.moe/5vd9ka.png)
![](https://files.catbox.moe/d4dgqg.png)
- 微内核构架：分为运行在核心态的微内核和运行在用户态并以C/S方式活动的服务进程。微内核：最基本的核心功能（进程 / 线程管理、低级存储器管理、中断和陷入处理）。优点：扩展性和灵活性、可靠性和安全性、可移植性、可以很好地支持分布式计算。缺点：系统开销大
- 宏内核构架：**主流的操作系统都是基于宏内核的构架，如Windows, Android, iOS, macOS, Linux等，但也广泛吸取了微内核构架的优点**
- 外核：不同于克隆真实机器的另一种虚拟机策略，外核所做的是保持多个虚拟机之间彼此不发生冲突

**操作系统引导（结合第四章学习）**：引导过程如下：
- 1.开机后，CPU加电，初始化(CS) = 0FFFFH，(IP) = 0，自动从FFFF:0单元开始执行程序。FFFF:0处有一条JMP指令，CPU执行该指令后，转去执行BIOS中的硬件系统检测和初始化程序。
- 2.初始化程序将建立BIOS所支持的中断向量，即将BIOS提供的中断例程的入口地址登记在中断向量表中。
- 3.硬件自检。启动BIOS程序后，先进行硬件自检，检查硬件是否出现故障。如有故障，主板会发出不同含义的蜂鸣，启动中止；如无故障，屏幕会显示CPU、内存、硬盘等信息
- 4.BIOS将控制权交给排在首位的启动设备后，CPU将该设备主引导扇区的内容（主引导记录MBR）加载到内存中，然后由MBR检查分区表，查找活动分区，并将该分区的引导扇区的内容（分区引导记录PBR）加载到内存，执行引导程序（启动管理器）
- 5.加载操作系统

虚拟机：
- 第一类虚拟机管理程序：直接运行在裸机上，是唯一一个运行在最高特权级的程序
- 第二类虚拟机管理程序：运行在宿主操作系统上，自己则是客户操作系统，实际上就像一个普通的进程

错题总结：
- 操作系统的基本类型主要有批处理操作系统、分时操作系统和实时操作系统
- 现代操作系统都是多任务的（主要特点是并发和并行），但并不一定需要运行在多CPU的硬件上，单个CPU也可满足要求
- 甘特图画法：
    - 横坐标上标出合适的时间间隔，纵坐标上的点是程序的名字
    - 过横坐标上每个标出的时间点，向上作垂直于横坐标的虚线
    - 用几种不同的线（推荐用“直线”“波浪线”“虚线”三种，较易区分）代表对不同资源的占用，按照题目给出的任务时间片，平行于横坐标把不同程序对应的线段分别画出来
    - 画图时要注意，如处理器、打印设备等资源是不能让两个程序同时使用的，有一个程序正在使用时，其他程序的请求只能排队。
- 常驻内存的只是操作系统内核，其他部分仅在需要时才调入
- 操作系统的引导程序位于磁盘活动分区的引导扇区中。引导程序分为两种：一种是位于ROM中的**自举程序**（BIOS的组成部分)，用于启动具体的设备；另一种是位于装有操作系统硬盘的活动分区的引导扇区中的**引导程序**（称为启动管理器)，用于引导操作系统
- 虚拟机既可以用软件实现，也可以用硬件实现

#### 本章小结

- 特权指令与非特权指令：
    - 所谓特权指令，是指有特殊权限的指令，由于这类指令的权限最大，使用不当将导致整个系统崩溃，如清内存、置时钟、分配系统资源、修改虚存的段表或页表、修改用户的访问权限等。若所有程序都能使用这些指令，则系统一天死机n次就不足为奇。为保证系统安全，这类指令只能用于操作系统或其他系统软件，不直接提供给用户使用
    - 在用户态下使用特权指令时，将产生中断以阻止用户使用特权指令
- 定义微内核构架OS的四个方面：①内核足够小；②基于C/S模式；③机制与策略分离；④采用面向对象技术

### <a name="12">（二）进程管理</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### a)进程、线程的基本概念以及两者的区别

*程序段 + 相关数据段 + PCB = 进程实体 / 进程映像*

- 进程：进程是进程实体的运行过程，是系统进行**资源分配和调度**的一个独立单位（强调资源）
- 线程：直接的理解就是“轻量级进程”，**它是一个基本的CPU执行单元**，也是程序执行流的最小单位，**是被系统独立调度和分派的基本单位**（强调调度/执行）
    - 线程由线程ID、程序计数器、寄存器集合和堆栈组成
    - 线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可以使用其进程拥有的全部资源
    - 线程也有就绪、阻塞、运行三种基本状态
    - 若线程的切换发生在同一个进程内部，则只需要很少的时空开销
- 进程与线程的区别：
    - 调度：拥有资源的是进程，独立调度的是线程
    - 并发性：线程的并发性更好（因为线程切换时，有可能会发生进程切换，也有可能不发生）
    - 拥有资源：线程只有必不可少、能保证独立运行的资源
    - 独立性：每个进程都拥有独立的地址空间和资源，进程中的线程对其他进程不可见
    - 系统开销：进程开销大，线程开销小，且同一进程中的不同线程之间的同步与通信非常容易实现
- 线程的组织与控制：
    - 线程控制块TCB：包括①线程标识符；②一组寄存器，包括程序计数器、状态寄存器和通用寄存器；③线程运行状态，用于描述线程正处于何种状态；④优先级；⑤线程专有存储区，线程切换时用于保存现场等；⑥堆栈指针，用于过程调用时保存局部变量及返回地址等
    - 一个线程可以读、写甚至清楚同一进程的另一个线程的堆栈
    - 线程也是具有生命期的，它由创建而产生，由调度而执行，由终止而消亡。相应地，在操作系统中就有用于创建线程和终止线程的函数（或系统调用）
    - 通常，线程被终止后并不立即释放它所占有的资源，只有当进程中的其他线程执行了分离函数后，被终止线程才与资源分离，此时的资源才能被其他线程利用。被终止但尚未释放资源的线程仍可被其他线程调用，以使被终止线程重新恢复运行
- 线程的实现方式：
    - 用户级线程（ULT）（多对一）：内核意识不到线程的存在，使用线程库设计多线程程序。该方式可以使线程切换时不转换到内核空间，节省了模式切换的开销
    - 内核级线程（KLT）（一对一）：又称内核支持的线程，该方式的线程切换比较快、开销小，但同一进程的线程切换仍需要转到核心态进行，系统开销较大
    - 组合方式（多对多）：多内核级线程对多用户级线程（通过时分多路复用实现）（**要求用户级线程的数量大于等于内核级线程的数量**）
    - 线程库的实现方法：
        - 在用户空间提供一个没有内核支持的库
        - 实现由操作系统直接支持的内核级的一个库
        - 目前使用的三种主要线程库为：POSIX Pthreads、Windows API、Java，其中POSIX Pthreads两种方式都支持，Windows支持内核级，Java依靠前两者实现
    

**王道习题：**

一轮标记题：5 7 14 15 20(1, 5) 22 33 38 40 44 47 48 56

二轮重做：1 14 16 26 28 52 56

大题：1 2 5 6
1.
- 答：执行一条命令或运行一个应用程序时，进程和程序之间形成一对一的关系。进程在执行过程中可以加载执行不同的应用程序，从而形成一对多的关系；以不同的参数或数据多次执行同一个应用程序时，形成多对一的关系；并发地执行不同的应用程序时，形成多对多的关系

2.
- 答：父进程创建子进程后，父进程与子进程同时执行（并发）。主程序调用子程序后，主程序暂停在调用点，子程序开始执行，直到子程序返回，主程序才开始执行

3.
- 答：**每个进程有自己独立的地址空间。在操作系统和硬件的地址保护机制下，进程无法访问其他进程的地址空间，所以必须借助于操作系统的系统调用函数实现进程之间的通信**。进程通信的主要方式有:
    - 共享内存区。通过系统调用创建共享内存区。多个进程可以（通过系统调用）连接同一个共享内存区，通过访问共享内存区实现进程之间的数据交换。**使用共享内存区时需要利用信号量解决同步互斥问题**
    - 消息传递。通过发送/接收**消息**，系统调用实现进程之间的通信。当进程发送消息时，系统将消息从用户缓冲区复制到内核中的消息缓冲区，然后将消息缓冲区挂入消息队列。进程发送的消息保持在消息队列中，直到被另一进程接收。当进程接收消息时，系统从消息队列中解挂消息缓冲区，将消息从内核的消息缓冲区中复制到用户缓冲区，然后释放消息缓冲区（即直接通信方式）
    - 管道系统。管道是先进先出（FIFO）的信息流，**允许多个进程向管道写入数据，允许多个进程从管道读出数据**。在读/写过程中，操作系统保证数据的写入顺序和读出顺序是一致的。进程通过读/写管道文件或管道设备实现彼此之间的通信。
    - 共享文件。利用操作系统提供的文件共享功能实现进程之间的通信。这时，**也需要信号量来解决文件共享操作中的同步和互斥问题**

4.
- 答：多线程是指在一个程序中可以定义多个线程并同时运行它们，每个线程可以执行不同的任务。多线程与多任务的区别：多任务是针对操作系统而言的，代表操作系统可以同时执行的程序个数；多线程是针对一个程序而言的，代表一个程序可以同时执行的线程个数，而每个线程可以完成不同的任务

5.
- 答：
    - 1) 是。若系统中未运行进程，则系统很快会选择一个就绪进程运行。只有就绪队列中无进程时，CPU才可能处于空闲状态
    - 2) 不一定。因为系统中的所有进程可能都处于等待态，**可能处于死锁状态**，也有可能因为等待的事件未发生而进入循环等待态
    - 3) 不一定。因为高优先级的进程有可能正处在等待队列中，进程调度会从就绪队列中选择一个进程占用CPU，这个被选中的进程可能优先级较低

6.
- 答：
    - 1) 为支持多进程的并发执行，系统为每个进程建立了一个数据结构：进程控制块（PCB），用于进程的管理和控制。PCB中记录了有关进程的一些描述信息和控制信息，包括**进程标识符、进程当前的状态、优先级、进程放弃CPU时的现场信息，以及指示组成进程的程序和数据在存储器中存放位置的信息**、资源使用信息、进程各种队列的连接指针和反映进程之间的隶属关系的信息等
    - 2) 创建、阻塞、唤醒、终止（总之就是没有运行原语）
    - 3) 略，**总之强调两点：①进程状态的转换；②进程PCB的改变**

7.
- 答：
    - 1) 时间片轮转法调度进程策略
    - 2) 
        - 1.进程被调度，获得CPU，进入运行态
        - 2.进程需要读文件，因IO操作进入阻塞态
        - 3.进程打印输出结果，因打印机未结束而阻塞
        - 4.打印机打印结束，进程重新回归就绪态，并排在尾部
        - 5.进程所需数据已从磁盘进入内存，进程回到就绪态
        - 6.运行的进程因为时间片用完而让出CPU，排到就绪队列尾部

错题总结：
- 程序代码经过多次创建可对应不同进程，而**同一个**系统进程（或线程）可以由系统调用的方法被不同的进程（或线程）多次使用
- 只要就绪队列不为空，CPU就总是可以调度进程运行，保持繁忙。这与就绪进程的数目没有关系，除非就绪队列为空，此时CPU进入等待态，导致CPU的效率下降
- 多线程系统可以做到：
    - 利用线程并行地执行矩阵乘法运算
    - Web服务器利用线程响应HTTP请求
    - 基于GUI的调试程序用不同的线程分别处理用户输入、计算和跟踪等操作
- **匿名管道只能用于具有亲缘关系的进程间通信，命名管道可用于同一主机上的任意进程间通信**。*管道自带同步与互斥，*且为半双工，数据只能向一个方向流动。需要双方通信时，需要建立起两个管道
- 我们把管道一次最多可以缓存的数据量大小叫做PIPESIZE。内核在处理管道数据的时候，底层也要调用类似read和write这样的方法进行数据拷贝，这种内核操作每次可以操作的数据量也是有限的，一般的操作长度为一个page，即默认为4k字节。我们把每次可以操作的数据量长度叫做PIPEBUF。PIPEBUF的作用是，内核在处理管道的时候，*如果每次读写操作的数据长度不大于PIPEBUF时，保证其操作是原子的。*而PIPESIZE的影响是，大于其长度的写操作会被阻塞，直到当前管道中的数据被读取为止
- **用户级线程的切换可以在用户空间完成，内核级线程的切换需要操作系统帮助进行调度，因此用户级线程的切换效率更高**
- 信箱通信是一种间接通信

#### b)进程控制块、进程的状态与转换

PCB：使参与并发执行的每个程序（含数据）能够独立运行的专门的数据结构。系统唯有通过进程的PCB才能感知到进程的存在。一个PCB实例如下：

进程描述信息|进程控制和管理信息|资源分配清单|处理机相关信息
:-:|:-:|:-:|:-:
进程标识符（PID）|进程当前状态|代码段指针|通用寄存器值
用户标识符（UID）|进程优先级|数据段指针|地址寄存器值
|代码运行入口地址|堆栈段指针|控制寄存器值
|程序的外存地址|文件描述符|标志寄存器值
|进入内存时间|键盘|状态字
|处理机占用时间|鼠标
|信号量使用

- 进程控制：进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般把进程控制用的程序段称为原语，原语的特点是执行期间不允许中断，是一个不可分割的基本单位
    - 创建原语：
        - 1）为新进程分配一个唯一的进程标识号，并申请一个空白PCB（PCB是有限的）。**若PCB申请失败，则创建失败**
        - 2）为进程分配其运行所需的资源，如内存、文件、I/O设备和CPU时间等（在PCB中体现）。这些资源或从操作系统获得，或仅从其父进程获得。**如果资源不足，则并不是创建失败，而是处于创建态，等待内存资源**
        - 3）初始化PCB，主要包括初始化标志信息、初始化处理机状态信息和初始化处理机控制信息，以及设置进程的优先级等
        - 4）若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待被调度运行
        - 允许一个进程创建另一个进程，此时的创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源归还给父进程。此外，在撤销父进程时，通常也会同时撤销其所有的子进程
    - 进程的终止：①正常结束；②异常结束；③外界干预
    - 进程的阻塞和唤醒：一个进程从运行态变成阻塞态是主动的行为，而从阻塞态变成就绪态是被动的行为，需要其他相关进程的协助。应当注意，Block原语和Wakeup原语是一对作用刚好相反的原语，必须成对使用

- 进程的状态和转换：
    - 运行态：在单处理机中，每个时刻只有一个进程
    - 就绪态：进程在该队列获得了除处理机外的一切所需资源
    - **阻塞态 / 等待态**：可以根据阻塞原因的不同，设置多个阻塞队列
    - 创建态：进程正在创建
    - 结束态：进程正在消失，可能是进程正常结束或其他原因退出运行。进程首先将进程置为结束态，再进一步处理资源释放和回收等工作
    - 转换：图略

#### c)进程同步的基本概念；实现临界区互斥的基本方法；信号量机制及P、V操作；了解经典同步问题，并通过信号量机制解决进程同步问题

进程同步的基本概念：	
- 为什么要引入同步互斥：因为并发进程是异步的，为了协调进程之间的相互制约关系，所以引入同步互斥
- 进程的异步性：由于系统的资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进
- 并发过程执行产生的两种相互制约关系：
    - 同步：进程 A 应在进程 B 之前执行
    - 互斥：进程 A 和进程 B 不能在同一时刻执行
- 临界资源：一次仅允许一个进程使用的资源；如物理设备(打印机)，共享变量，共享数据，共享缓冲区，公用队列
- 共享资源：可用被多个进程同时使用的资源；如可重入代码/纯代码，共享程序段，磁盘，非共享数据
- 临界区：访问临界资源的那段代码。如果n个进程涉及到了同一个变量A，则A的相关临界区 = 访问临界资源A的那段代码 = n个代码段
- 同步机制遵循的准则：
    - 空闲让进：临界区空闲，允许一个进程进入【运行进程访问空闲的临界资源】
    - 忙则等待：有进程进入临界区时，其他进程需等待【两个进程不能同时进入临界资源】
    - 有限等待：请求访问的进程应保证在有限时间内进入临界区【进程等待进入临界区的时间是有限的】
    - 让权等待：进程不能进入临界区时，应该立即释放处理器，防止进程忙等待【不能进入临界区的执行态进程立即放弃CPU】

实现临界区互斥的基本方法：（不是没有考过哦！）
- 软件实现法：
    - 单标志法（必须交替，违背“空闲让进”）
    - 双标志法先检查（进入区有多段代码，可能会导致错误，违背“忙则等待”）
    - 双标志法后检查（同时设置标志，可能会导致“饥饿”现象）
    - Peterson's Algorithm：先双标志法，再单标志，最后检查（不满足“让权等待”）
- 硬件实现法：低级方法 / 元方法
    - 中断屏蔽方法
    - 硬件指令方法：
        - TestAndSet指令：true表示正被占用
        - Swap指令：交换key和lock的值
- 互斥锁（mutex lock）：
    - 定义：解决临界区最简单的工具
    - 特点：通常采用硬件机制实现；常用于多处理器系统
    - 缺点：忙等待
    - 代码：acquire()获取锁，release()释放锁

管程：一个共享类
- 定义：
    - 管程定义了共享数据结构和各种进程在该数据结构上的全部操作
    - 结构类似于Class，把对共享资源的操作封装起来
    - 管程支持进程互斥；任何时候只有一个进程在管程中执行
    - 管程不仅能实现进程间的互斥，还能实现进程间的同步
- 组成：这类题目如果看到是管程外这个字眼，那就是错误的，**管程的组成都是基于管程内部的**
    1. 管程的名字
    2. 局部于管程内部的共享数据结构或者共享变量说明
    3. 对管程内的数据结构进行操作的一组过程
    4. 对局部于管程内部的共享数据设置初始值的语句
- 管程中设置的条件变量	
    - 定义：阻塞原因定义为条件变量condition
    - 有两种操作：
        - x.wait：**阻塞进程，将其插入到阻塞队列中**
        - x.signal：唤醒进程，将其插入到就绪队列中
    - 与信号量的相似点：
        - wait/signal类似于信号量的P/V操作，实现进程的阻塞/唤醒，但不能说和PV操作相同
    - 与信号量的不同点：
        - 条件变量没有值，仅实现“排队等待”功能
        - 信号量有值，这个值反映了剩余资源数

**信号量机制及P、V操作：**
- 信号量的分类：
    - 整型信号量
        - 该信号量被定义为一个用于表示资源数目的整型量S
        - 该机制不遵循“让权等待”的准则
    - 记录型信号量
        - 是一种不存在“忙等”现象的进程同步机制
        - 需要一个用于代表资源数目的整型变量Value
        - 需要一个进程链表L，用于链接所有等待该资源的进程
        - wait操作 = P操作 = 请求一个资源
        - signal操作 = V操作 = 释放一个资源
- P操作（wait）
    - 将信号量值S减1，表示「申请占用一个资源」
	- **如果 s < 0，表示已经没有可用资源，则执行 P 操作的进程被阻塞**
	- 如果 s ≥ 0，表示现有的资源足够你使用，则执行 P 操作的进程继续执行
	- 举例：当信号量的值为2时，表示有2个资源可以使用；当信号量的值为-2的时候，表示有两个进程正在等待使用这个资源
- V操作（signal）
    - 将信号量值S加1，表示「释放一个资源」，即使用完资源后归还资源
	- **如果s ≤ 0，表示有某些进程正在等待该资源。由于我们已经释放出一个资源了，因此需要唤醒阻塞进程**
    - S = 0表示没有临界资源可供使用，为什么还要唤醒进程？
        - V操作是先执行S + 1，也就是说，把信号量的值加1后才变成了0
        - 在此之前，信号量的值是-1，即有一个进程正在等待这个临界资源，我们需要唤醒它
- 利用信号量实现同步：
	- 信号量表示资源量：
        - 同步信号量初始值不确定，可以设置
        - 信号量最大值 = 最多可以请求的资源数
        - 信号量最小值 = 最大值 / 初始值 - 最大请求值
    - 步骤：
        - step1：定义一个同步信号量，并初始化为当前可用资源的数量
        - step2：在先执行的操作的「后」面执行 V 操作，释放资源
        - step3：在后执行的操作的「前」面执行 P 操作，申请占用资源
- 利用信号量实现互斥：
    - 信号量表示互斥量：
        - 互斥信号量初始值=1，表示临界区只运行一个进程进入，从而实现互斥
        - 互斥信号量=0，表示临界区已经有一个进程进入，临界区外还没有进程等待
        - 互斥信号量<0，表示临界区中有一个进程
        - 信号量为负数时，其绝对值表示在临界区外等待进入的进程数
    - 步骤：
        - step1：定义一个互斥信号量，并初始化为 1
        - step2：把对于临界资源的访问置于 P 操作和 V 操作之间
        - **P 操作和 V 操作必须成对出现**
        - 缺少 P 操作就不能保证对临界资源的互斥访问
        - 缺少 V 操作就会导致临界资源永远得不到释放、处于等待态的进程永远得不到唤醒

**了解经典同步问题，并通过信号量机制解决进程同步问题：**
- 生产者-消费者问题
```
semaphore mutex = 1; //互斥信号量
semaphore empty = n; //空缓冲区数量
semaphore full = 0; //满缓冲区数量

producer(){
    while(1){
        produce an item in nextp;
        P(empty);
        P(mutex);
        add nextp to buffer;
        V(mutex);
        V(full);
    }
}

consumer(){
    while(1){
        P(full);
        P(mutex);
        remove an item from buffer;
        V(mutex);
        V(empty);
        consume the item;
    }
}
```
- 复杂的生产者问题（爸爸放苹果，女儿吃苹果，妈妈放橘子，儿子吃橘子）
```
semaphore plate = 1, apple = 0, orange = 0; //有一个盘子、零个苹果、零个橘子

dad(){
    while(1){
        prepare an apple;
        P(plate);
        put the apple on the plate;
        V(apple);
    }
}

daughter(){
    while(1){
        P(apple);
        take the apple from the plate;
        V(plate);
        eat the apple;
    }
}

// mom & son类似。
```

- 读者-写者问题（①允许多个读者可以同时对文件执行读操作；②只允许一个写者往文件中写信息；③任一写者在完成写操作之前不允许其他读者或写者工作；④写者执行写操作前，应让已有的读者和写者全部退出）
```
int count = 0; //读者数量
semaphore mutex = 1; //保护count变量
semaphore rw = 1; //读写者互斥
semaphore w = 1; //用于实现写优先

writer(){
    while(1){
        P(w);
        P(rw);
        writing;
        V(rw);
        V(w);
    }
}

reader(){
    while(1){
        P(w);
        P(mutex);
        if(count == 0) //一有读者，rw就开P
            P(rw);
        conut ++;
        V(mutex);
        V(w);
        reading;
        P(mutex);
        count --;
        if(count == 0) //最后一个读者了，rw可以V
            V(rw);
        V(mutex);
    }
}

//这里的写进程优先是相对而言的，有些书上把这个算法称为读写公平法，即读写进程具有一样的优先级。当一个写进程访问文件时，若先有一些读进程要求访问文件，后有另一个写进程要求访问文件，则当前访问文件的进程结束对文件的写操作时，会是一个读进程而不是一个写进程占用文件（在信号量w的阻塞队列上，因为读进程先来，因此排在阻塞队列队首，而V操作唤醒进程时唤醒的是队首进程），所以说这里的写优先是相对的

//读者-写者问题有一个关键的特征，即有一个互斥访问的计数器count，因此遇到一个不太好解决的同步互斥问题时，要想一想用互斥访问的计数器count能否解决问题

```

- 哲学家进餐问题（五人五筷）
```
semaphore chopsticks[5] = {1, 1, 1, 1, 1};
semaphore mutex = 1; //取左右筷子的这一整个操作需要一个互斥，免得被抢筷子
Pi(){
    do{
        P(mutex);
        P(chopsticks[i]);
        P(chopsticks[(i + 1) % 5]);
        V(mutex);
        eat;
        V(chopsticks[i]);
        V(chopsticks[(i + 1) % 5]);
        think;
    } while(1);
}
```

- 吸烟者问题（供应商无限地、串行地提供材料，每个吸烟者需要不同的材料）
```
int num = 0;
semaphore offer1 = 0, offer2 = 0, offer3 = 0; //定义信号量，表示三种资源
semaphore finish = 0; //定义信号量，表示抽烟是否完成
Provider(){
    while(1){
        num++;
        num = num % 3;
        if(num == 0){
            put the src;
            V(offer1);
        }
        else if (num == 1){
            put the src;
            V(offer2);
        }
        else{
            put the src;
            V(offer3);
        }
        P(finish);
    }
}

Smoker1(){
    while(1){
        P(offer1);
        make a tobacco and smoke;
        V(finish);
    }
}

// Smoker2 & Smoker3类似
```
- 总结：
    - 生产者-消费者问题：互斥+同步问题
    - 一家人吃水果问题：互斥+同步问题，爸爸+女儿这一连续过程和妈妈+儿子这一连续过程互斥
    - 读者-写者问题：互斥+写优先
    - 哲学家进餐问题：互斥
    - 吸烟者问题：互斥，注意：供应商提供资源，吸烟者制作香烟这一连续过程是彼此互斥的

**王道习题：**

一轮标记题：1 3 9 16 18 20 25 26 28 30 38

二轮重做：43 46 49

大题：
1.
- 答：前两问略。管程的引入是为了解决临界区分散所带来的管理和控制问题。在没有管程之前，对临界区的访问分散在各个进程之中，不易发现和纠正分散在用户程序中的不正确使用P、V操作等问题。管程将这些分散在各进程中的临界区集中起来，并加以控制和管理，管程一次只允许一个进程进入管程内，从而既便于系统管理共享资源，又能保证互斥

2.
- 答：互斥；互斥；同步；同步

3 ~ 7.
- 待做

错题总结：
- 可重入代码 / 纯代码：一种允许多个进程同时访问的代码；如进程映像中的共享程序段
- PV操作实现的同步的S的初值由用户确定；如果期望的信息还没发送，则对应的初值为0，若信息已存在，则初值为非0的正数；PV操作实现的互斥的S的初值=1
- 判断代码中的语句是否要互斥执行，可以从以下几个方面考虑【见王道书P121第43题】
    - 不同范围的变量不需要互斥（如进程A和进程B都有变量x，这是两个不同范围的变量，不用互斥）
    - 对变量赋值前，都有声明语句的话，不需要互斥（如「int a; a=1; int a; a=2」，a=1和a=2不需要互斥）（说明是局部变量？）
- 在实现临界区互斥时，“让权等待”准则不一定非得实现，如皮特森算法

#### d)进程间通信，包括共享存储系统、消息传递系统、管道

- 进程间通信：进程通信是指进程之间的信息交换。**PV操作是低级通信方式**，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三类：
    - 共享存储：
        - 共享存储又分为两种：低级方式的共享是基于数据结构的共享，高级方式的共享则是基于存储区的共享
        - 对共享空间进行读/写操作时需要使用同步互斥工具
        - 让两个进程共享空间需要通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的
    - 消息传递：
        - 进程间的数据交换以**格式化的消息**（Message）实现
        - 进程通过系统提供的发送消息和接收消息两个原语进行数据交换
        - 通信过程对用户透明，简化了通信程序的设计，是当前应用最广泛的进程间通信机制
        - 微内核操作系统中，微内核与服务器之间的通信就采用了消息传递机制
        - 该机制很好地支持多处理机系统、分布式系统、计算机网络
            - **直接通信方式**：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息
            - **间接通信方式**：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息，这种中间实体一般称为信箱。该通信方式广泛应用于计算机网络中
    - 管道通信：
        - 所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间的通信的一个共享文件，又名pipe文件
        - 以**字符流形式**传输，只支持**半双工通信**
        - 管道机制必须提供三方面的协调能力：互斥、同步、确定对方的存在
        - 管道可以克服使用文件进行通信的两个问题：
            - 管道的大小是受限的
            - 管道满，写阻塞；管道空，读阻塞
        - 管道内部已经实现同步机制，能够保证数据一致性（保证数据的安全性，在写数据的时候不会被别人读，不会发生二义性）

#### e)进程调度的基本准则；典型调度算法：先来先服务调度算法、短作业(短进程、短线程)优先调度算法、时间片轮转调度算法、优先级调度算法

调度的概念：
- 基本概念
	- 调度是处理机进行分配，即从**就绪队列**中按一定算法（公平，高效的原则）选择一个进程并将处理机分配给他运行，以实现进程并发地执行
	- 调度是多道程序OS的基础；调度是OS设计的核心问题
- 高级调度/作业调度
    - 是**内存与辅存的调度**，从后备队列中调度作业
    - 每个作业只调入调出一次
    - 通常存在于多道批处理系统中
    - 内存与磁盘之间交换数据的转态转换：就绪态到挂起态（408不考挂起）
- 中级调度/内存调度
    - 目的是提高内存利用率和系统吞吐量
    - **将暂时不能运行的进程调到外存等待，设为挂起态**，最后修改状态为就绪态，挂在就绪队列上
    - 是存储器管理中的对换功能
- 低级调度/进程调度
    - 从就绪队列中选取一个进程，调用频率很高
    - 各种OS都必须配置这种调度
- 三种调度的联系
    - 作业调度为进程活动做准备，进程调度使进程正常活动
    - 中级调度将暂时不能运行的进程挂起，中级调度处于另外两个调度之间
    - 调用频率：作业调度 < 内存调度 < 进程调度
    - 进程调度是最基本的，不可或缺
- 易错点：
	- 作业是用户提交的，以用户任务为单位
	- 进程是系统自动生成的，以操作系统控制为单位
	- 进程的调度就是把一个进程从就绪态转换为了运行态

**调度的目标：**
- CPU利用率 = CPU有效工作时间 / (CPU有效工作时间 + CPU空闲等待时间)
- 系统吞吐率：单位时间内CPU完成作业的数量
- *周转时间：指从作业提交到完成所经历的时间*
    - 周转时间 = 作业完成时间 - 作业提交时间
    - 平均周转时间 = (作业1的周转时间 + ... + 作业n的周转时间) / n
    - 带权周转时间 = 作业周转时间 / 作业实际运行时间
    - 平均带权周转时间 = (作业1的带权周转时间 + ... + 作业n的带权周转时间) / n
- *等待时间：进程等待时间之和，处理机调度算法的主要影响指标*
- *响应时间 = 系统响应时间 - 作业提交时间，该指标在交互式系统里很重要*
- 调度最终目标要考虑的元素：**特定用户的要求 + 系统整体效率 + 调度算法的开销**

调度的实现：
- 调度器：用于调度和分派CPU的组件
    - 排队器：按策略给就绪进程排出一个或多个队列
    - 分派器：从就绪队列中取出进程，并分配CPU
    - 上下文切换器：在对处理机进行切换时，会发生两对上下文的切换操作（原进程→分派器，分派器→新进程）（这个一般不考）
    - 通常采用两组寄存器，其中一组供内核使用，一组供用户使用
- 调度的时机：
	- 不能进行调度与切换的情况：
        - 在处理中断的过程中
        - 进程在OS内核临界区中
        - 其他需要完全屏蔽中断的原子操作过程中
    - 可以进行调度与切换的情况：
        - 发生引起调度条件且当前进程无法继续进行下去时（非剥夺调度）
        - 中断处理结束或自陷处理结束后，被置上请求调度标志（剥夺方式的调度）
- 调度方式：非抢占调度方式、抢占调度方式

**典型的调度算法：**
- FCFS（先来先服务）调度算法：
    - 既可用于作业调度，也可用于进程调度
    - 属于不可剥夺算法
    - 对长作业比较有利，对短作业比较不利
- SJF（短作业优先）/ SPF （短进程优先）调度算法：
    - 对长作业很不利，甚至可能会导致“饥饿”现象
    - 选择的作业时间是用户估计时间，选择的进程时间是系统估计的运行时间
    - 该算法的平均等待时间和平均周转时间最少
- 优先级调度算法：
    - 适合实时操作系统
    - 既可用于作业调度，也可用于进程调度
    - 可分为非抢占式优先级调度和抢占式优先级调度
    - 根据优先级是否可以改变，可分为静态优先级和动态优先级
    - 优先级设置原则：
        - 系统进程优先于用户进程
        - 交互型进程优先于非交互型进程
        - I/O型进程优先于计算型进程
- 高响应比优先调度算法：FCFS + SJF
    - 主要用于作业调度
    - *响应比Rp = (等待时间 + 要求服务时间) / 要求服务时间*
    - 作业的等待时间相同时，要求服务时间越短，响应比越高，有利于短作业，因而类似于SJF
    - 要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而类似于FCFS
    - 对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，也可获得处理机，克服了“饥饿”现象
- 时间片轮转调度算法：
    - 适合分时系统
	- 若时间片过大，退化为FCFS
	- 若时间片过小，则切换频繁，处理机开销增大
    - 时间片的大小应选择适当，时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力
- 多级队列算法：设置多个就绪队列，不同队列使用不同的调度算法
- 多级反馈队列调度算法：FCFS + 优先级 + 时间片
    - 1. 设置多个就绪队列，并为每个队列赋予不同的优先级（优先级算法）
    - 2. 赋予各个队列的进程运行时间片的大小各不相同（时间片轮转）
    - 3. 每个队列都采用FCFS算法（FCFS）

属性|FCFS|SJF|高响应比|时间片轮转|多级反馈队列
:-:|-|-|-|-|-
可抢占？|**×**|√|√|√|队列内算法不一定
不可抢占？|√|√|√|×|队列内算法不一定
优点|公平且实现简单|平均等待时间最少，效率最高|兼顾长短作业，满足短作业优先且不会发生饥饿现象|兼顾长短作业，为了多个用户能及时干预系统，绝对可抢占的|兼顾长短作业，有较好的响应时间，可行性强
缺点|不利于短作业|长作业会饥饿，估计时间不易确定|计算响应比的开销大|平均等待时间最长，上下文切换浪费时间|无
适用于|无|作业调度，批处理系统|无|分时系统，人机交互系统|相当通用，大家都满意的算法
默认决策模式|非抢占|非抢占|非抢占|抢占|抢占

进程切换的实现：对于通常的进程而言，其创建、撤销及要求由系统设备完成的IO操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的，因此可以说，**任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的**

模式切换与上下文切换的区别：模式切换时，CPU逻辑上可能还在执行同一进程。用户进程最开始都运行在用户态，若进程因中断或异常进入核心态运行，执行完后又回到用户态刚被中断的进程运行。用户态和内核态之间的切换称为模式切换，而不是上下文切换，因为没有改变当前的进程。上下文切换只能发生在内核态，它是多任务操作系统中的一个必需的特性

调度和切换的区别：调度是指决定资源分配给哪个进程的行为，**是一种决策行为**；切换是指实际分配的行为，**是执行行为**。一般来说，先有资源的调度，然后才有进程的切换

**王道习题：**

一轮标记题：1 3 17 22 26 35

二轮重做：3 32(注意调度切换时间要算上) 

大题：1 6 7 8 9 12
1.
- 答：多级反馈队列调度算法能较好地满足各种类型用户的需要。对终端型作业用户而言，由于它们提交的作业大多属于交互型作业，作业通常比较短小，**系统只要能使这些作业在第1级队列所规定的时间片内完成，便可使终端型作业用户感到满意**；对于短批处理作业用户而言，它们的作业开始时像终端型作业一样，若仅在第1级队列中执行一个时间片即可完成，便可获得与终端型作业一样的响应时间，对于稍长的作业，**通常也只需要在第2级队列和第3级队列中各执行一个时间片即可完成，其周转时间仍然较短**；对于长批处理作业用户而言，它们的长作业将依次在第1,2,...,n级队列中运行，然后按时间片轮转方式运行，**用户不必担心其作业长期得不到处理**

2.
- 答：略

3 ~ 6、10.
- 解：画好甘特图就不难

7.（注意，是优先数越小，优先级越高！）
- 答：具有两道作业的批处理系统，内存只存放两道作业，它们采用抢占式优先级调度算法竞争CPU，而将作业调入内存采用的是短作业优先调度。8:00，作业1到来，此时内存和处理机空闲，作业1进入内存并占用处理机；8:20，作业2到来，内存仍有一个位置空闲，因此将作业2调入内存，又由于作业2的优先数高，相应的进程抢占处理机，在此期间8:30作业3到来，**但内存此时已无空闲，因此等待**。直至8:50，作业2执行完毕，此时作业3、4竞争空出的一道内存空间，作业4的运行时间短，因此先调入，但它的优先数低于作业1，因此作业1先执行。到9:10时，作业1执行完毕，再将作业3调入内存，且由于作业3的优先数高而占用CPU

8.
- 解：
    - 可抢占式SJF：P1 - P2 - P4 - P1 - P3，平均周转时间为13
    - 时间片轮转算法按就绪队列的FCFS进行轮转，**在时刻2，P被挂到就绪队列队尾，队列顺序为P2, P3, P1，此时P4还未到达**

9.
- 答：
    - 1) 6%
    - 2) (1次调度 + 1次切换) / 一个时间片，答案为1.5%。注意题设问的是切换消耗，所以分子不需要加中断的消耗
    - 3) 为提高CPU的效率，一般情况下要尽量减少时钟中断的次数，如由每秒120次降低到100次，以延长中断的时间间隔。或将每个时间片的中断数量（时钟数）加大，如由24个中断加大到36个。也可优化中断处理程序，减少中断处理开销，如将每次500μs的时间降低到400μs。若能这样，则时钟中断和进程切换的总开销占CPU的时间比为(36×400μs + 1ms + 2ms) / (1/100 × 36) ≈ 4.8%

11.
- 解：
    - 1) J1: 10:00 ~ 10:35; J4: 10:35 ~ 10:55; J2:10:55 ~ 11:25; J5: 11:25 ~ 11:55; J3:11:55 ~ 12:40
    - 2) 75min

12.
- 解：
    - 1) nice值较大的进程可能会始终无法得到调度，产生“饥饿”现象
    - 2) nice + (1 + cpuTime) / (1 + waitTime); 处于就绪态时，waitTime定时加1，该值会逐渐减小
- 答：
    - 2) nice + k1 * cpuTime - k2 * waitTime

错题总结：
- 该类题型的做法，依旧是画甘特图较为行之有效
- 时间片轮转增加了系统开销，所以不会使得系统高效运行
- 所谓CPU繁忙型，是指该类作业需要大量的CPU时间进行计算，其定义更接近于长作业。FCFS有利于CPU繁忙型的作业，而不利于IO繁忙型的作业
- UNIX属于分时操作系统
- 中断向量本身是用于存放中断服务例行程序的入口地址，而中断向量的地址应是该入口地址的地址（也就是地址从0开始的一系列中断向量）
- 抢占式的短作业优先算法 = “**最短剩余时间**优先算法”（SRTN）
- 注意时间片轮转算法的就绪队列在最开始时的轮转调度，极易出错！

#### f)死锁的形成原因与必要条件；死锁预防、死锁避免、死锁检测和解除

死锁的形成原因与必要条件:
- 为什么会出现死锁？
	1. 系统资源的竞争【空间上】	
        - 系统中不可剥夺资源不足以满足多个进程
		- 只有对不可剥夺资源（如磁带机，打印机）的竞争才可能产生死锁
	2. 进程推进顺序非法【时间上】	
        - 进程运行时，请求和释放资源的顺序不当
		- 系统对独占资源分配不当
    3. 系统资源不足不是系统产生死锁的原因，资源不足只会对进程造成“饥饿”
- 产生死锁的必要条件
	- 互斥条件：多个线程不能同时使用同一个资源
	- 不剥夺条件：进程A已经拥有资源1，在自己使用完之前不能被其他进程获取
	- 请求并保持条件：进程A已经有资源1，想申请资源2，但是资源2被进程B持有，进程A处于等待状态，但是进程A不释放资源1
	- 循环等待条件：两个线程获取资源的顺序构成了环形链（注意，有环形链不代表就是死锁！）

**死锁预防、死锁避免、死锁检测和解除：**
- 死锁预防	
名称|特点|举例
:-:|-|-    
破坏互斥条件|缺点：如打印机等临界资源只能互斥使用|该方法不太可行
破坏不剥夺条件|常用于状态易于保存和恢复的资源（CPU的寄存器和内存资源）|**剥夺资源法**
破坏请求并保持条件|可能会导致饥饿现象|**一次性分配策略、静态分配策略**
破坏循环等待条件|可采用顺序资源分配法，但是编号必须相对稳定，限制了新类型设备的增加|**资源有序分配策略**
- 死锁避免	
    - 系统安全状态：死锁包含在不安全状态之中（系统处于安全状态时，一定无死锁；系统处于不安全状态时，不一定出现死锁）
    - 银行家算法
    0. Column: Available(Work) Max(Only used in step 1) Allocation Need
    1. Need = Max - Allocation（先算Need）
    2. Request ≤ Need & Request ≤ Available?（第一次检测）
    3. Try: Available -= Request, Allocation += Request, Need -= Request（该减减，该加加）
    4. Safety test: Work = Available, while(Work ≥ Need) {Work += Allocation}（第二次检测）
    - 具体到画表，推荐画三列：Allocation、Need、Available(Work)
    - **死锁避免时不会限制用户申请资源的顺序**；需要进程运行所需资源总量信息；不会给可能导致死锁的进程分配资源
- 死锁的检测
    1. 资源分配图：资源分配图是一个有向图，用于表示某时刻系统资源与进程之间的状态。**圆圈代表进程，框代表一类资源；从进程到资源的边叫做请求边；从资源到进程的边叫做分配边**
    2. 死锁定理：S为死锁的条件是当且仅当S状态的资源分配图是不可完全简化的
- 死锁的解除
    1. 资源剥夺法：挂起某些死锁进程，并抢占它的资源
    2. 撤销进程法：强制撤销部分甚至全部死锁进程并剥夺这些进程的资源
    3. 进程回退法：让一个或多个进程回退到足以回避死锁的地步
- 各个策略的比较：

名称|资源分配策略|各种可能模式|主要优点|主要缺点
-|-|-|-|-
死锁预防|保守，宁可资源闲置|一次请求所有资源，资源剥夺，资源按序分配|适用于突发式处理的进程，不必进行剥夺|效率低，进程初始化时间延长；剃夺次数过多；不便灵活申请新资源
死锁避免|是“预防”和“检测”的折中（在运行时判断是否可能死锁）|寻找可能的安全允许顺序|不必进行剥夺|必须知道将来的资源需求；进程不能被长时间阻塞
死锁检测|宽松，只要允许就分配资源|定期检查死锁是否己经发生|不延长进程初始化时间，允许对死锁进行现场处理|通过剥夺解除死锁，造成损失

**王道习题：**

二轮重做：18 21 22

大题：（死锁是没考过大题的）
1.
- 答：2 > 1 > 3

2.
- 答：系统会死锁。因为对两个账户进行加锁操作是可以分割进行的，若此时有两个用户同时进行转账，P先对账户A进行加锁，再申请账户B；P先对账户B进行加锁，再申谓账户A，此时产生死锁。解决的办法是：可以采用资源顺序分配法对A、B账户进行编号，用户转账时只能按照编号由小到大进行加锁；也可采用资源预分配法，要求用户在使用资源前将所有资源一次性申请到

3.
- 答：略

4.
- 解：不发生死锁要求，**必须保证至少有一个进程能得到所需的全部资源并执行完毕，m ≥ n * (k - 1) + 1时，一定不会发生死锁**

5.
- 解：略

6.
- 解：
    - 1) 安全，例如P2, P3, P4, P1
    - 2) P2, P3, P4, P1
    - 3) **若2)中的两个请求立即得到满足，则此刻系统并未立即进入死锁状态，因为这时所有的进程未提出新的资源申请，全部进程均未因资源请求没有得到满足而进入阻塞态。只有当进程提出资源申请且全部进程都进入阻塞态时，系统才处于死锁状态**

7 ~ 8.
- 解：略

9.（加入改错本）
- 解：见改错本

错题总结：
- 王道的21题较难，被称作“单行线问题”，说是单行线，其实是在说“两个方向都能通行，但一边要等另一边的车通行完的单行线”

#### 本章小结

- 死锁与饥饿：
    - 一组进程处于死锁状态是指组内的每个进程都在等待一个事件，而该事件只可能由组内的另个进程产生。这里所关心的主要是事件是资源的获取和释放
    - 与死锁相关的另一个问题是**无限期阻塞（Indefinite Blocking）或饥饿（Starvation）**，即进程在信号量内无穷等待的情况
    - 产生饥饿的主要原因是：在一个动态系统中，对于每类系统资源，操作系统需要确定一个分配策略，当多个进程同时申请某类资源时，由分配策略确定资源分配给进程的次序。有时**资源分配策略可能是不公平的**，即不能保证等待时间上界的存在。在这种情况下，即使系统没有发生死锁，某些进程也可能会长时间等待。当等待时间给进程推进和响应带来明显影响时，称发生了进程“饥饿”，当“饥饿”到一定程度的进程所赋予的任务即使完成也不再具有实际意义时，称该进程被“饿死”
    - “饥饿”并不表示系统一定会死锁，但至少有一个进程的执行被无限期推迟。“饥饿”与死锁的主要差别如下:
        1. 进入“饥饿”状态的进程可以只有一个，而因循环等待条件而进入死锁状态的进程却必须大于等于两个
        2. **处于“饥饿”状态的进程可以是一个就绪进程，如静态优先权调度算法时的低优先权进程，而处于死锁状态的进程则必定是阻塞进程**

### <a name="13">（二）内存管理</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

基本概述：
内存管理是操作系统对内存的划分和动态分配。

内存管理的目的：
1. 为了更好地支持多道程序并发执行
2. 方便用户
3. 提高内存利用率

内存管理的功能：
1. 内存空间的分配与回收：由OS完成主存储器空间的分配和管理
2. 地址转换：存储管理将逻辑地址转换为物理地址
3. 内存空间的扩充：利用虚拟存储技术/自动覆盖技术，从逻辑上扩充内存
4. 内存共享：允许多个进程访问内存的同一部分
5. 存储保护：保证多道作业在各自的存储空间运行，互不干扰

内存管理的分配：
1. 连续分配：单一连续分配--「**单道发展到多道OS**」-->固定分区分配--「**为了适应大小不同的程序**」-->动态分区分配
2. 不连续分配：分段存储管理--->分页存储管理--->段页存储管理

#### a)程序装入与链接；逻辑地址与物理地址空间；重定位；内存保护。

程序装入与链接：
1. 编译：由编译程序将用户源代码编译成若干目标模块
2. 链接：由链接程序将目标模块和库函数链接，形成完整的装入模块
    - 链接类别：静态链接、装入时动态链接、运行时动态链接（**只有最后一种是运行时才去链接所需模块**）
3. 装入：是**由装入程序**将装入模块装入内存运行
    - 静态装入：只适用于单道程序环境。在编译时把物理地址计算好
    - 可重定位装入（静态重定位）：装入时把逻辑地址转换为物理地址，但装入后不能改变
    - 动态运行时装入（**动态重定位**）：
        - 装入程序把装入模块装入内存后，**并不立即把装入模块中的逻辑地址转换为物理地址**，而是把这种地址转换推迟到程序真正要执行时才进行
        - 这样可以将程序分配到不连续的存储区；在程序运行之前**可以只装入部分代码即可投入运行**，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享
        - 需要**重定位寄存器**的支持

逻辑地址与物理地址空间：

区别|逻辑地址|物理地址
-|-|-
定义|每个目标模块都从0号单元开始编址的地址|物理地址空间是指内存中物理单元的集合
特点|1.不同进程可以有系统的逻辑地址，这些逻辑地址可以映射到主存的不同位置；2.进程运行时，看到和使用的地址都是逻辑地址；3.将逻辑地址转换为物理地址的过程叫做地址重定位，该过程通过MMU实现|物理地址是地址转换的最终地址

- 形成逻辑地址的阶段：链接
- 形成物理地址的阶段：装入或程序运行时

重定位：
1. 动态重定位是在作业的**执行**过程中进行的
2. 静态重定位是在装入的时候进行的
3. 固定分区分配可以采用静态重定位（装入后位置不再改变）
4. 在**整个系统**设置一个重定位寄存器，**用来存放程序在内存中的始址**


内存保护：
- 目的：确保每个进程都有一个单独的内存空间
- 有两种方法：
1. 在CPU中设置一对上下限存储器，判断CPU访问的地址是否越界
2. 使用重定位寄存器和界地址寄存器（只有OS内存才可以使用这两个寄存器）
	- 重定位寄存器（也叫**基地址寄存器**）含最小的物理地址值【用于“加”】
	- **界地址寄存器**含逻辑机制的最大值【用于“比”】
	- 逻辑地址 + 基地址寄存器的值 --映射-→ 物理地址
    - 加载重定位寄存器和界地址寄存器时**必须使用特权指令**，只有操作系统内核才可以加载这两个存储器
- 内存保护需要由OS和硬件机构合作完成，以保证进程空间不被非法访问

内存共享：
- 概念：
    - 只有只读区域的进程空间可用共享
    - 纯代码/可重入代码 = 不能修改的代码，不属于临界资源
    - 可重入程序通过减少交换数量来改善系统性能
- 实现方式
    1. 段的共享
    2. 基于共享内存的进程通信（第二章的同步互斥）
    3. 内存映射文件

#### b)分区管理；交换与覆盖技术。

分区管理：
- 定义：连续分配管理是为一个用户程序分配一个连续的内存空间
- 特点
    - 用户程序在主存中都是连续存放的
    - 非连续分配的方式的存储密度 < 连续分配方式
- 碎片
    - 内部碎片：当程序小于固定分区大小时，也要占用一个完整的内存分区，导致分区内部存在空间浪费
    - 外部碎片：内存中产生的小内存块
- 分类

区别|1.单一连续分配|2.固定分区分配
-|-|-
定义|在此方法下，内存分为两个区：系统区：供OS用，在低地址区；用户区：内存用户空间由一道程序独占|用户内存空间划分为固定大小（分区大小相等或不等）的区域；每个区装一道作业
优点|简单，无外部碎片；无需进行内存保护（内存中永远只有一道程序）|简单
缺点|只能用于单用户单任务的OS；有内部碎片，存储器利用率极低|程序太大可能放不下任何一个分区，有内部碎片；不能实现多进程共享一个主存区，存储空间利用率低

3. 动态分区分配：进程转入内存时，根据进程的实际需要，动态地分配内存；动态分区是在作业装入时动态建立的；会产生**外部碎片**，克服外部碎片需要**紧凑**技术，这需要动态重定位寄存器的支持

动态分配算法|**空闲分区按什么次序链接的**|特点
-|-|-
a.首次适应算法|按地址递增的次序|最简单，效果最好，速度最快
b.邻近适应算法（循环首次适应算法）||比首次适应算法差
c.最佳适应算法|按容量递增的次序|**性能很差**，会产生最多的外部碎片
d.最坏适应算法|按容量递减的次序|可能导致没有可用的大内存块，性能差

交换与覆盖技术：
- 覆盖：
    - 基本思想：由于程序运行时并非任何时候都要访问程序及数据的各个部分，因此可把用户空间分成一个固定区和若干覆盖区。将经常活跃的部分放在固定区，将那些**即将要访问的段**放入覆盖区
    - 特点：打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，此外，内存中能够更新的地方只有覆盖区的段，不在覆盖区中的段会常驻内存。覆盖技术对用户和程序员**不透明**
    - 单一连续存储管理可采用覆盖技术
- 交换（对换）：
    - 基本思想：把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序**从内存移到辅存**，把内存空间腾出来，这一过程又称**换出**；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称**换入**。第2章介绍的中级调度采用的就是交换技术
    - 交换通常在有许多进程运行且内存空间吃紧时开始启动，而在系统负荷降低时就暂停
    - 使用交换技术时，一个进程正在I/O操作，则不能交换出主存；开辟一个缓冲I/O区后，可以交换出主存
- 覆盖和交换的提出是为了解决主存空间不足的问题，不是从物理上解决，而是将暂时不用的部分换出主存以节省空间，从而在逻辑上扩充主存

#### c)分页管理方式；分段管理方式；段页式管理方式。

**分页管理方式：**
- 基本概念：
    - 页/页面：进程中的块
        - 页面大--->页内碎片增多，降低内存的利用率
        - 页面小--->进程的页面数大，页表过长，占用大量内存，增加物理地址转换的开销，降低页面换入/出的效率
    - 页框/页帧：内存中的块
    - 块/盘块：外存中的块
    - 页表：由页表项组成
- 逻辑地址：假设每页为4KB，则：**31--页号P--12-11--页内偏移量W--0**
- 页表项：假设逻辑空间为32位，字节编址，则共需要2^32B / 4KB = 1M页帧，那么：**页表始址+页号×页表项长度（隐含）→ 19--页帧号b--0**
- 📈图解 ![img](https://api2.mubu.com/v3/document_image/325c5532-e1e8-4d99-b9cc-81b4e5b954ac-329792.jpg)
- 物理地址：设页面大小为L，逻辑地址为A
    1. 计算页号计算页号P (P = A / L）和页内偏移量W（W = A % L)
    2. 比较页号Р和页表长度M，若P ≥ M，则产生越界中断，否则继续执行
    3. 页表中页号Р对应的页表项地址 = 页表始址F + 页号P × 页表项长度，取出该页表项内容b，即为页帧号。注意区分页表长度和页表项长度。页表长度是指一共有多少页，页表项长度是指页地址占多大的存储空间
    4. 计算物理地址E = b × L + W，用得到的物理地址E去访问内存
- 📈图解 ![img](https://api2.mubu.com/v3/document_image/c134e860-8e0e-4522-9e42-c29d2b7a02a4-329792.jpg)
- 快表（相联存储器）：这个时候的页表项：**39--页号--20-19--页帧号b--0**
- 两级页表/多级页表：顶级页表最多只能有1个页面
- 特点
    - 所有进程都有一张页表
    - 分页是面向计算机的
    - 系统设置一个页表寄存器PTR用于存放**页表在内存中起始地址和长度**
    - 无论采用什么页面置换算法，每种页面第一次访问时不可能在内存中，必然发生缺页，所以缺页次数 ≥ 不同的页号数量

**分段管理方式：**
- 逻辑地址：**段号S + 段内偏移量W**
    - 在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显式提供，在高级程序设计语言中，这个工作由编译程序完成
- 段表项：段表项地址（隐含）+ 段长 + 始址 
- 物理地址（**访问了两次内存**）：
    1. 从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。注意，在地址变换的题目中，要注意逻辑地址是用二进制数还是用十进制数给出的
    2. 比较段号S和段表长度M，若S ≥ M，则产生越界中断，否则继续执行
    3. 段表中段号S对应的段表项地址 = 段表始址F + 段号S × 段表项长度，取出该段表项的前几位得到段长C。若段内偏移量 ≥ C，则产生越界中断，否则继续执行
    4. 取出段表项中该段的始址b，计算E = b + W，用得到的物理地址E去访问内存。
- 优点
    - 能产生连续的内存空间
    - 分段存储管理能反映程序的逻辑结构并有利于段的共享和保护
    - 程序的动态链接与逻辑结构有关，分段存储管理有利于程序的动态链接
- 缺点
    - 会产生**外部碎片**
    - 内存交换的效率低
- 特点
    - 方便编程、分段共享
    - 分段管理地址空间是二维的（段号和段内偏移要用户显式给出）
    - 每段的长短不同
    - 系统设置一个段表寄存器STR用于存放**段表在内存中起始地址和长度**

**段页式管理方式：**
- 实现方法
    1. 将程序划分为多个有逻辑意义的段【分段】
	2. 对分段划分出来的连续空间，再划分固定大小的页【分页】
- 逻辑地址：**段号S + 段内页号P + 页内偏移量W**
	- 对内存的管理以存储块为单位，地址空间是二维的
- 物理地址（**访问了三次内存**）：
    1. 访问段表（**页表长度 + 页表起始地址，相当于PTR**），得到**页表起始地址**
	2. 访问页表，得到物理页号
	3. 将物理页号与页内偏移组合，得到物理地址
- 特点
    - 系统依旧要设置一个段表寄存器STR用于存放**段表在内存中起始地址和长度**
    - 同样可以使用快表，此时tag由段号、页号组成，value则是页帧号和保护码

**王道习题：**

一轮标记题：2 8 10 12 14 18 19 21 25 27 30 31 33 34 41 47 48 49 51 54

二轮重做：2 10 18 30 41 47 49

大题：
1.
- 答：动态分区和固定分区分配方式相比，内存空间的利用率要高一些。但是，总会存在一些分散的较小空闲分区，即外部碎片，它们存在于已分配的分区之间，不能充分利用。可以采用拼接技术加以解决。固定分区分配方式存在内部碎片，而无外部碎片；动态分区分配方式存在外部碎片，无内部碎片

2.
- 首次适应算法显然不满足，最佳适应算法满足

3 ~ 12.
- 待做

错题总结：
- 对于交换技术，要明确其对象是**主存与辅存**，因此：在使用交换技术时，若一个进程正在I/O操作，则不能交换出主存，否则其I/O数据区将被新换入的进程占用，导致错误。不过可以在操作系统中开辟I/O缓冲区，将数据从外设输入或将数据输出到外设的I/O活动在系统缓冲区中进行，这时系统缓冲区与外设I/O时，进程交换不受限制
- 动态重定位是在作业的**执行**中进行的
- 页表和段表同样存储在内存中，**系统提供给用户的物理地址空间为总空间大小减去页表或段表的长度**。由于页表和段表的长度不能确定，所以提供给用户的物理地址空间大小也不能确定
- 页式管理中很重要的一个问题是页面大小如何确定。确定页面大小有很多因素，如**进程的平均大小、页表占用的长度**等。而一旦确定，**所有的页面就是等长的**，以便易于系统管理
- 存储管理的目的是**方便用户**和**提高内存利用率**
- 在多个进程并发执行时，所有进程的页表大多数驻留在内存中，在系统中只设置一个页表寄存器(PTR)，它存放页表在内存中的始址和长度。平时，**进程未执行时，页表的始址和页表长度存放在本进程的PCB中**，当调度到某进程时，才将这两个数据装入页表寄存器中。每个进程都有一个单独的逻辑地址，有一张属于自己的页表
- 段内位移的最大值就是最大段长

#### d)虚拟内存基本概念和局部性原理；缺页中断；地址变换过程。

虚拟内存基本概念和局部性原理：
- 传统存储管理方式的特征
    - 一次性：作业必须一次性全部装入内存，才能开始运行
    - 驻留性： 
    	- 作业被装入内存后，就一直驻留在内存中，直到作业结束
	    - 运行中的进程会因等待I/O而被阻塞，可能处于长期等待状态
- 局部性原理
    - 时间局部性：程序中的某条指令一旦执行，不久后该指令可能再次运行；出现的原因是**程序中存在着大量的循环结构**
    - 空间局部性：程序在一段时间内所访问的地址，可能集中在一定的范围内
- 虚拟存储器
    - 定义：系统为用户提供的一个比实际内存容量大得多的存储器
    - 特征：
        - 多次性 = 即只需将当前运行的那部分程序和数据装入内存即可开始运行【最重要的特征】
	    - 对换性 = 即作业无需一直常驻内存，要用时换入，不要用时换出
	    - 虚拟性 = 从逻辑上扩充内存的容量【最重要的目标】
- 虚拟内存的实现
    - 方式(离散分配)
        1. 请求分页存储管理
        2. 请求分段存储管理
	    3. 请求段页式存储管理
    - 需要的东西：
        - 一定的硬件支持，一定容量的内存和外存
        - *页表/段表机制*作为主要的数据结构
        - **中断机制，当程序要访问的部分还未调入内存时，产生中断**
        - *地址变换机构*

请求分页管理方式：
- 特点
    - 只要求将当前一部分页面装入内存，便可启动作业运行，不需要一次全部装入
    - 在作业执行的过程中，当访问的页面不存在时，再通过调页功能将其调入
- 相比基本分页管理增加的功能
    - 请求调页功能：将要用的页面调入内存【调入】
    - 页面置换功能：将不用的页面换出到外存【调出】
- 页表项的构成：**页号 + 页帧号 + 状态位P + 访问字段A + 修改位M + 外存地址L**
    - 状态位/合法位P：标记该页是否已被调入内存中 → 供程序访问时参考，用于判断是否触发缺页异常
    - 访问字段A：记录本页在一段时间内被访问的次数 → 供置换算法换出页面时参考
    - 修改位M：标识该页在调入内存后是否被修改过 → 当页面被淘汰时，若页面数据没有修改，则不用写回外存
    - 外存地址L：用于指出该页在外存上的地址，通常是物理块号 → 供写回外存和从外存中调入此页时参考
    - 对比：Cache行的构成 = *状态位* + 主存块地址tag + 数据块副本 + *脏位/修改位* + *置换标记位/访问字段*，三处相同，页表项的页号 + 页帧号与Cache的tag等效
- **缺页中断**
    - 定义：缺页是在CPU执行某条指令过程中，进行取指令或读写数据时发生的一种故障，是内中断或者叫做异常
    - 产生时间
        - 每当要访问的页面不在内存中时，便产生一个缺页中断，请求OS将所缺的页调入内存
        - 缺页中断是**访存指令**引起的，说明所要访问的页面不在内存中
        - 进行缺页中断处理并调入所要访问的页后，**访存指令应该重新执行**
    - 特点	
        - **在指令执行期间而非一条指令执行完后产生和处理中断信号**
        - 一条指令在执行期间，可能产生*多次缺页中断*
        - 请求分页存储器中，页面尺寸增大，存放程序需要的页帧数减少，缺页中断次数也会减少
        - 影响缺页中断的因素有：缺页率，磁盘读写时间，内存访问时间
        - 缺页处理过程中可能执行的操作：*修改页表项，分配页框/置换页面，磁盘I/O*（内存没有页面，需要从外存读入）
- 地址变换机构新增功能
    1. 产生和处理中断信号
    2. 从内存中换出一页
- 请求分页系统外存组成	
    - 存放文件的文件区【采用离散分配方式】
    - 存放对换页面的对换区【采用连续分配方式】
    - 📢对换区的磁盘I/O速度更快

#### e)页面置换算法：最佳置换算法(OPT)、先进先出置换算法(FIFO)、最近最少使用置换算法(LRU)、时钟置换算法(CLOCK)；工作集模型。

**页面置换算法（即选择调出页面的算法）：**

区别|最佳置换算法OPT|先进先出置换算法FIFO|最近最久未使用置换算法LRU|时钟置换算法CLOCK
-|-|-|-|-
被淘汰的页面|以后永不使用的|在内存中驻留时间最久的页面|最近最长时间未访问过的页面|最近未使用的页面
特点|◎ 基于队列实现的；◎ **该算法无法实现**；◎ 只能用于评价其他算法|◎ 会出现*Belady异常*（分配的物理块数增大但页故障数不减反增）；◎ 性能差，但实现简单|◎ 性能好，但实现复杂；◎ 需要寄存器和栈道硬件支持；◎ 堆栈类算法；◎ 耗费高因为要对所有页排序|◎ FIFO和LRU的结合

CLOCK算法的淘汰顺序：访问位为A，修改位为M
- 1类A = 0, M = 0: 最近未被访问且未被修改，**是最佳淘汰页**
- 2类A = 0, M = 1: 最近未被访问，但已被修改，不是很好的淘汰页（也就是说，**访问比修改的优先级要高**！符合逻辑）
- 3类A = 1, M = 0: 最近已被访问，但未被修改，可能再被访问
- 4类A = 1, M = 1: 最近已被访问且已被修改，可能再被访问

抖动/颠簸：
- 定义
    - 在页面置换时，出现频繁的页面调度行为
	- 所有页面置换策略都有可能造成抖动
- 产生原因	
    - 系统中同时运行的进程太多—>分配给每个进程的物理块太少—>进程在运行时频繁出现缺页—>频繁的调动页面
	- 主要原因是因为页面置换算法不合理
- 解决方法
    - 撤销部分进程
	- 增加磁盘交换区大小和提高用户进程优先级都与抖动**无关**

工作集模型：
- 定义：在某段时间间隔内，进程要访问的页面集合
- 如何确定工作集：基于局部性原理，用最近访问过的页面来确认
- 有什么作用
    - 工作集反映了进程在接下来一段时间内很可能频繁访问的页面集合
    - 为了防止抖动现象，要使分配给进程的物理块数（驻留集大小） > 工作集大小

**王道习题：**

一轮标记题：1 2 10 13 23 26 29 33 43

二轮重做：29 35 39 43

大题：
1.
- 答：
    - 1) 覆盖技术与虚拟存储技术最本质的不同在于，覆盖程序段的最大长度要受内存容量大小的限制，而虚拟存储器中程序的最大长度不受内存容量的限制，只受计算机地址结构的限制。另外，覆盖技术中的覆盖段由程序员设计，且要求覆盖段中的各个覆盖具有相对独立性，不存在直接联系或相互交叉访问；而虚拟存储技术对用户的程序段没有这种要求。
    - 2) 交换技术就是把暂时不用的某个程序及数据从内存移到外存中，以便腾出必要的内存空间，或把指定的程序或数据从外存读到内存中的一种内存扩充技术。交换技术与虚存中使用的调入/调出技术的主要相同点是，都要在内存与外存之间交换信息。交换技术与虚存中使用的调入/调出技术的主要区别是：交换技术调入/调出**整个进程**，因此一个进程的大小要受内存容量大小的限制；而虚存中使用的调入/调出技术在内存和外存之间来回传递的是**页面或分段**，而不是整个进程，从而使得进程的地址映射具有更大的灵活性，且允许进程的大小比可用的内存空间大

2.
- 答：每页32B，即页内偏移地址为5位
    - 101：转换为二进制：001 000 001，则页号为2，物理地址为f3,1
    - 204：转换为二进制：010 000 100，则页号为4，不在TLB里，查内存页表得到物理地址为f5,4
    - 576：缺页中断

3 ~ 14.
- 待做

15 ~ 21.
- 待做

错题总结：
- 内存抖动是指频繁地引起主存页面淘汰后又立即调入，调入后又很快淘汰的现象。这是**由页面置换算法不合理引起**的一种现象，是页面置换算法应当尽量避免的
- 当系统处于频繁的（缺页导致的）换入换出过程时，说明内存不够用了，我们可以：
    - 增大内存
    - 减少多道程序的度数
    - 但注意：增大磁盘对换区容量，提高磁盘对换速度或者CPU速率，这些都于事无补！
- 在任一时刻t，都存在一个集合，**它包含所有最近k次内存访问所访问过的页面**。这个集合w(k, t)就是工作集
- 系统调用是由用户进程发起的，请求操作系统的服务。例如：创建新进程可以通过系统调用来完成，如Linux中通过fork系统调用来创建子进程。以下行为则不属于系统调用：当内存中的空闲页框不够时，操作系统会将某些页面调出，并将要访问的页面调入，这个过程完全由操作系统完成，不涉及系统调用；进程调度完全由操作系统完成，无法通过系统调用完成；生成随机数只需要普通的函数调用，不涉及请求操作系统的服务

#### f)其他

进程的内存映像：
操作系统内核段（**高地址**）
↓
用户栈（运行时创建）
↓
↑
共享库的存储映射区
↑
动态生成的堆（运行时由malloc创建）
读/写数据段（.data、.bss）
只读代码段（.init、.text、.rodata）
未使用区（**低地址**）

其中：
- 共享库用来存放进程用到的共享函数库代码，如printf()函数等
- 在读/写数据段中，.data是已初始化的全局变量和静态变量；.bss是未初始化及所有初始化为0的全局变量和静态变量
- 在只读代码段中，.init是程序初始化时调用的_init函数；.text是用户程序的机器代码；.rodata是只读数据

页框分配（进程准备执行时，由OS决定给特定进程分配几个页框）：
- 驻留集 = 给一个进程分配的物理页框（也叫做物理块）的集合
- 驻留集的大小
    1. 分配给进程的页框越少，驻留在内存的进程就越多，CPU的利用率就越高
    2. 进程在主存中的页面过少，缺页率相对较高
    3. 分配的页框过多，对进程的缺页率没有大的影响
- 分配策略
    - 固定分配局部置换：物理块固定，缺页时先换出一个线程再调入所缺页
    - 可变分配全局置换：物理块可变，缺页时增加物理块再调入所缺页
    - 可变分配局部置换：物理块可变，若不频繁缺页则用局部置换，频繁缺页再用全局置换
    - 📢对各进程进行固定分配时页面数不变，不可能出现全局置换
- 物理块调入算法
    1. 平均分配算法
    2. 按比例分配算法
    3. 优先权分配算法
- 调入页面的时机
- 预调页策略 = 运行前的调入，主要用于进程的首次调入，由程序员指出应先调入哪些页
- 请求调页策略 = 运行时的调入
    - 调入的页一定会被访问，策略易于实现
    - 每次仅调入一页，增加了磁盘I/O开销
- 从何处调入页面
    1. 系统拥有足够的对换区空间
    2. 系统缺少足够的对换区空间
    3. UNIX方式
- 如何调入页面	
    - 情况1：所访问的页面不在内存时--->缺页中断--->无空闲物理块--->决定淘汰页--->调出页面--->调入所缺页面
    - 情况2：所访问的页面不在内存时--->缺页中断--->有空闲物理块--->调入所缺页面

内存映射文件：
- 定义：与虚拟内存有些相似，将**磁盘文件的全部或部分内容**与进程虚拟地址空间的某区域建立映射关系
- 作用：**可以直接访问**被映射的文件，而不必执行文件I/O操作，也无需对文件内容进行缓存处理 
- 优点：适合用来管理大尺寸文件

虚拟存储器性能影响因素：
1. 页面较大—>缺页率较低—>可以减少页表长度，但使得页内碎片增大
2. 页面较小—>缺页率较高
	- —>可以减少内存碎片，提高内存利用率
	- —>使得页表过长，占用大量内存
3. 分配给进程的物理块数越多，缺页率就越低
4. 分配给进程的物理块数超过某个值时，对缺页率的改善并不明显
5. 好的页面置换算法可以使进程在运行过程中具有较低的缺页率
6. *LRU，CLOCK*将未来可能要用到的进程保存在内存中，可以提高页面的访问速度
7. 编写程序的局部化程度越高，执行时的缺页率越低
8. 存储和访问尽量使用系统的访问方式（如都按行存储就按行访问）

## <a name="16">计算机网络</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

### <a name="17">（一）计算机网络概述</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)计算机网络定义与分类

计算机网络：一般认为，计算机网络是一个将分散的、具有独立功能的计算机系统，通过通信设备与线路连接起来，由功能完善的软件实现资源共享和信息传递的系统

计算机网络的组成：
- 从组成部分上看，由硬件、软件、协议三大部分组成
- 从工作方式上看，分为边缘部分和核心部分
- 从功能组成上看，由通信子网和资源子网组成，通信子网 = 各种传输介质 + 通信设备 + 相应的网络协议，资源子网 = 实现资源共享功能的设备 + 相应软件

计算机网络的功能：1.数据通信（最基本和最重要的功能）；2.资源共享；3.分布式处理；4.提高可靠性；5.负载均衡（即：将工作任务均衡分配）

计算机网络的分类：
- 按分布范围分：1.广域网（WAN）2.城域网（MAN）3.局域网（LAN）4.个人区域网（PAN）
- 按传播技术分：1.广播式网络：局域网、广域网中的无线和卫星通信网络；2.点对点网络，采用分组存储转发与路由选择机制
- 按拓扑结构分：主要分为总线形、星形、环形和网状网络等，前三者多用于局域网，网状网络多用于广域网
- 按使用者分：分为公用网和专用网
- 按交换技术分：1.电路交换网络（典型：传统电话网络）；2.报文交换网络（又称存储-转发网络）；3.分组交换网络（又称包交换网络，现在的主流网络基本都是这种）
- 按传输介质分：分为有线和无线两大类

计算机网络的性能指标：
- 带宽：在计算机网络中，是“最高数据传输速率”的同义语，单位是比特/秒
- 时延：由发送时延（分组长度/信道带宽）、传播时延（信道长度/电磁波在信道上的传播速率）、处理时延（存储转发时的处理时间）、排队时延（进入路由器时要排队）组成，后两者一般可忽略不计
- 时延带宽积 = 传播时延 × 信道带宽
- 往返时延：指从发送端发出一个短分组，到发送端收到来自接收端的确认（接收端收到数据后立即发送确认)，总共经历的时延。在互联网中，往返时延还包括各中间结点的处理时延、排队时延及转发数据时的发送时延
- 吞吐量（Throughput）：单位时间内通过某个网络（或信道、接口）的数据量
- 速率：也称数据传输速率、数据率或比特率
- 信道利用率 = 有**数据**通过时间 / （有 + 无）数据通过时间

**王道习题：**

一轮标记题：6 10 12 16 18

二轮重做：3 16 18

大题：1 5 6
1.
- 解：101000B，25000B，10000B；

2.
- 解：80Mb/s，409.6Mb/s

3.
- 解：略
- 答：如果网络容易丢失分组，那么对每个分组逐一进行确认较好，此时仅重传丢失的分组。另一方面，如果网络高度可靠，那么在不发生差错的情况下，仅在整个文件传送的结尾发送一次确认，从而减少了确认次数，节省了带宽。不过，即使只有单个分组丢失，也要重传整个文件。

4.
- 解：电路：s + x / b + k * d；分组：设共有n个分组，则n * p / b + (k - 1) * p / b + k * d
- 解析：**计算分组交换的时延时，我们可以从最后一个分组的视角进行考虑，它首先需要排队等n次传播时延，然后又需要经过k次传播时延和k-1次中间结点的传输时延**

5.
- 解：t = (x / p + k - 1) * (p + h) / b，t对p求导，得p = √((xh)/(k-1))

6.
- 解：
    - 1)2RTT + 1000 * 1024 * 8 / (1.5 * 10 ^ 6) + 0.5RTT = 0.2 + 5.46 + 0.05 = 5.71s
    - 2)5.71 + 999RTT = 105.61s
    - 解析：**最后一个分组虽然没有确认，但此时已经满足题设要求的“直到文件的最后一位到达目的地”了**
    - 3)2RTT + 49RTT + 0.5RTT = 5.15s

7.
- 解：略
- 答：不相同。在报文流中，网络保持对报文边界的跟踪；而在字节流中，网络不进行这样的跟踪。例如，一个进程向一条连接写了1024B，稍后又写了1024B，那么接收方共读了2048B。对于报文流，接收方将得到两个报文，每个报文1024B。而对于字节流，报文边界不被识别，接收方将全部2048B作为一个整体，在此已经体现不出原先有两个不同报文的事实

错题总结：
- 广播式网络共享广播信道（如总线)，通常是局域网的一种通信方式（局域网工作在数据链路层)，因此不需要网络层，因而也不存在路由选择问题。但数据链路层使用物理层的服务必须通过服/访问点实现
- ARPAnet是最早的计算机网络，它是因特网的前身

#### (2)计算机网络体系结构

计算机网络体系结构：计算机网络各层及其协议的集合

*n-SDU + n-PCI = n-PDU = (n-1)-SDU*

协议：由语法、语义和同步三部分组成，语法规定了传输数据的格式，语义规定了所要完成的功能，同步规定了执行各种操作的条件、时序关系等

接口：同一结点内相邻两层间交换信息的连接点。在典型的接口上，同一结点相邻两层的实体通过SAP进行交互。**物理层的服务访问点就是网卡接口，数据链路层的服务访问点是MAC地址，网络层的服务访问点是IP地址，传输层的服务访问点是端口号，应用层提供的服务访问点是用户界面**

服务：下层为紧邻的上层提供的功能调用，上层与下层之间交换的命令称为服务原语
- 服务原语：请求（Request）（C->S）、指示（Indication）（S->C）、（对请求的）证实（Confirmation）（S->C）、（对指示的）响应（Response）（C->S），无应答服务只有前两者
- 注意：**协议是“水平”的，但服务是“垂直”的**
- 注意：**只有能被上层看到的功能，才能算得上是服务！**
- 服务的分类：
    - 面向连接服务和无连接服务
    - 可靠服务和不可靠服务
    - 有应答服务和无应答服务

OSI参考模型：**有7层**，自下而上依次为**物理层、数据链路层、网络层、传输层、会话层、表示层、应用层**，低三层统称为通信子网，传输层承上启下，高三层统称为资源子网。其中，会话层允许不同主机上的各个进程之间进行会话，表示层主要处理在两个通信系统中交换信息的表示方式，应用层为特定类型的网络应用提供访问OSI参考模型环境的手段

TCP/IP模型：APRA在研究APRAnet时提出了TCP/IP模型，从低到高依次为**网络接口层、网际层、传输层和应用层**，并由于得到了广泛应用而成为事实上的国际标准

两个模型的对比：
- 相似之处：都采取分层的体系结构；都基于独立的协议栈；都可以解决异构网络的互联问题；
- 差别：
    - OSI精准地定义了服务、协议和接口三个概念，与面向对象思想非常吻合
    - OSI通用性良好，TCP/IP则不适合于非TCP/IP的协议栈
    - TCP/IP在设计之初就考虑到了多种异构网的互联问题，OSI是后来加上的
    - 主要考察点：**OSI在网络层就支持无连接和面向连接的通信，在传输层仅有面向连接的通信，而TCP/IP则选择了更省钱的做法**

**王道习题：**

二轮重做：1 8 12 13 

大题：

2.
- 解：物理层；网络层；数据链路层；应用层；会话层

错题总结：
- 在OSI参考模型中，会话层的两个主要服务是会话管理和同步。会话层使用校验点可使通信会话在通信失效时从校验点继续恢复通信，实现数据同步
- 在OSI参考模型中，**2、3、4层均提供差错控制、流量控制等功能，3、4层均提供拥塞控制功能**

### <a name="18">（二）物理层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)物理层的基本概念

- 物理层解决了什么？
	- 物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。
- 物理层主要任务？
	- 确定与传输媒体接口有关的一些特性
- 与传输媒体接口有关的特性？
	- 机械特性：定义物理连接的特性，规定物理连接时所采用的规格、接口形状、引线数目、引脚数量和排列情况
	- 电气特性：规定传输二进制时，线路上信号的**电压范围**，阻抗匹配、传输速率和距离限制。如某网络在物理层规定，信号的电平用+10V ~ +15V表示二进制0，用-10V ~ -15V表示二进制1，电线长度限于15m之内，这些都是电气特性
	- 功能特性：指明某条线上出现的某一电平的**电压表示何种意义**。注意与电气特性区分，如描述一个物理层接口引脚处高电平时的含义表示的是功能特性
    - 过程特性：指明对于不同功能的各种可能事件的出现顺序
- 物理层协议也称物理层接口标准，或物理层规程（Procedure）
- 常用的物理层接口标准：EIA RS-232-C、ADSL、SONET/SDH、EIA/TIA RS-449、CCITT的X.21等

**物理层设备：**
中继器（转发器/放大器）：
- 中继器的功能：对信号再生和还原（而非简单地将衰减的信号放大），保持与原数据相同，以增加信号传输的距离，延长网络的长度
- 中继器的两端
	- 中继器两端的网络部分是网段，而不是子网，使用中继器连接的几个网段**仍然是一个局域网**
    - **中继器没有存储转发功能，因此它不能连接两个速率不同的网段，中继器两端的网段一定要使用同一个协议**
- 5-4-3规则
	- 网络标准中对信号的延迟范围作了具体的规定，因而中继器只能在规定的范围内进行，否则会网络故障。
	- 采用粗同轴电缆的10BASE5以太网规范中，4个中继器，串联5段通信介质，只有3段可以挂接计算机，其余2段只能用作扩展通信范围的链路段

集线器：
- 本质是一个多端口的中继器
- 集线器功能
	- 对信号进行再生放大转发
	- 端口收到数据后，从除输入端口外的所有端口转发出去
    - 不具备信号的定向传送能力，是一个共享设备

**王道习题：**

一轮标记题：2 3 8

二轮重做：7

#### (2)数据通信的基础知识

基础知识：
- 数据：传送信息的实体，通常是有意义的符号序列
- 信号：数据的电气 / 电磁的表现，是数据在传输过程中的存在形式
    - 数字信号（离散信号）：代表消息的参数取值是离散的
    - 模拟信号（连续信号）：代表消息的参数取值是连续的
- 信源：产生或发送数据的源头
- 信宿：接收数据的终点
- 信道：信号的传输媒介。一般用来表示向某一个方向传送信息的介质，因此一条通信线路往往包含一条发送信道和一条信道
- 信道分类：
    - 按传输信号：模拟信道用于传输模拟信号；数字信道用于传输数字信号
    - 按传输介质：无线信道、有线信道
- 信号分类：
    - 基带信号：将数字信号1和0直接用两种不同的电压表示，然后送到数字信道上传输（基带传输）
    - 宽带信号：将基带信号进行调制后形成频分复用模拟信号，然后送到模拟信道上传输（宽带传输）
- 通信方式：
    - 单工通信：
        - 单向通信。即只能有一个方向的通信而没有反方向的交互
        - 如无线电广播、有线电广播
    - 半双工通信：
        - 双向交替通信。即通信双方都可以发送信息，但不能双方不能同时发送
        - 这种方式是一方发送另一方接收
    - 全双工通信
        - 双向同时通信。即通信双方可以同时发送或接收信息
        - 单工通信需要一条信道，而半双工通信和全双工通信需要两条信道
- 数据传输方式：
    - 串行传输	
        - 1比特1比特地按照时间顺序传输
        - 速度慢，费用低，适合远距离
    - 并行传输	
        - 若干比特通过多条通信信道同时传输
        - 速度快，费用高，适合近距离
        - 适用于计算机内部数据传输



- 码元：码元是指用一个**固定时长**的信号波形（数字脉冲）表示一位k进制数字，代表不同离散数值的基本波形，是数字通信中数字信号的计量单位，这个时长内的信号称为k进制码元，而该时长称为码元宽度。1码元可以携带若干比特的信息量
    - 在使用二进制编码时，只有两种不同的码元，一种代表0状态，一种代表1状态，是二进制码元
    - 一个码元所携带的信息量是不固定的，是由调制方式和编码方式决定的
- 速率 && 波特
    - 1波特表示数字通信系统每秒传输一个码元
    - **码元传输速率 = 码元速率 = 波特率 = 波形速率 = 符号速率 = 调制速率**：表示单位时间内数字通信系统所传输的码元个数（也可以称为脉冲个数或信号变化的次数），单位是波特（Baud）
    - **信息传输速率 = 信息速率 = 比特率**：表示单位时间内数字通信系统传输的二进制码元个数（或者比特数），单位：b/s
    - 关系：波特率 = 比特率 / 每码元所含比特数
    - 信道的**极限容量**是指信道的最高码元传输速率或信道的极限信息传输速率



**奈氏准则 & 香农定理：**
- 码间串扰：信号中的许多高频分量往往不能通过信道，否则在传输中会衰减，导致接收端收到的信号波形失去码元之间的清晰界限
- 影响失真程度的因素：码元传输速率、信号的传输距离、噪声干扰、传输媒体的质量
- 奈氏准则 / 采样定理 / 奈奎斯特定理：
	- **在理想低通（无噪声、带宽有限）的信道中，为了避免码间串扰，极限码元传输速率为2W Baud**（W是信道带宽，单位是Hz）
	    - **带宽只有在奈氏准则和香农定理中单位是HZ，其余都是b/s**
        - 理想低通信道下的极限数据传输率 = 2W *log2V（W是信道带宽，单位：Hz。V是码元的离散电平数目，即共有几种码元）
    - 在任何信道中，码元传输速率是有上限的，如果传输速率超过这个上限，就会出现严重的码间串扰问题，使接收端对码元的识别成为不可能
    - 如果信道的频带越宽，也就是能够通过的信号高频分量越多，那么就可以用更高速率传送码元而不出现码间串扰
    - 由于码元的传输速率受奈氏准则的制约，所以**要提高数据的传输速率，就必须设法使每个码元能携带更多的个比特量的信息**
- 香农定理：
	- **在带宽受限且有噪声的信道中，为了不产生误差，信息的数据传输率有上限值**
    - 信噪比
        - 信号的平均功率和噪声的平均功率之比，常记于S/N，并用分贝（dB）作为度量单位
        - 信噪比（dB） = 10 lg(S/N) (dB)
    - 信道的极限数据传输速率 = W log2(1+S/N) (b/s)
    - 信道的带宽越大或信道的信噪比越大，则信息的极限传输速率就越高
    - 对一定的传输带宽和一定的信噪比，信息传输速率的上限就确定了
    - **只要信息的传输速率低于信道的极限传输速率，就一定能找到某种方法来实现无差错传输**

**编码与调制：**
- **编码：数据→数字信号；调制：数据→模拟信号**
- 信号是数据的具体表示形式，它和数据有一定的关系，但又和数据不同。数字数据可以通过**数字发送器**转换为数字信号传输，也可以通过**调制器**转换成模拟信号传输；同样，模拟数据可以通过**PCM编码器**转换成数字信号传输，也可以通过**放大器调制器**转换成模拟信号传输。这样，就形成了4种编码方式
- **基带信号 & 带通信号：**
    - 基带信号：**来源于信源的信号**。将数字信号1和0直接用两种不同的电压表示，再送到数字信道上传输（基带传输）
        - 计算机输出的代表各种文字或图像文件的数据信号都属于基带信号
        - 基带信号就是发出的直接表达了要传输的信息的信号。如说话的声波就是基带信号
	    - 基信号往往包含较多带的低频成分，甚至有直流成分，而许多信道并不能传输这种低频分量或直流分量。为了解决这个问题，就必须对基带信号进行调制
    - 带通信号：**经过载波调制后的信号（即仅在一段频率范围内能通过信道）**
- **基带调制 & 带通调制：**
    - 基带调制：
        - 仅仅对基带信号的波形进行变换，使它能够与信道特性相适应
        - 经过变换后的信号仍然是基带信号
        - **由于基带调制是把数字信号从一种形式转换为另一种形式的数字信号，所以这种过程又称为编码**
    - 带通调制：
        - 使用载波进行调制，**把基带信号的频率搬移到更高的频段，并转换为模拟信号**，这样就可以更好地在模拟信道中传输
- 数字数据**编码为**数字信号
	- 归零编码（RZ）
        - 信号电平在一个码元之内都要恢复到零的编码方式
		- 这种编码在传输过程中处于低电平的情况多，信道利用率低
	- 非归零编码（NRZ）
        - 正电平为1，负电平为0
		- 编码容易实现，但没有检错功能，且无法判断一个码元的开始和结束，以至于收发双方难以保持同步
		- 需要在接收方和发送方另外建立一条信道来传输时钟周期信号来保证同步，无法保证自同步
		- **只有非归零编码不含同步信息**
	- 反向不归零编码（NRZI）
        - 信号电平翻转表示0，信号电平不变表示1
		- 反向不归零编码对于全部是1的信号同样难以确认一共发送了多少个信号，同样需要在收发双方之间另外建立一条信道传输时钟周期信号，无法实现自同步
	- **曼彻斯特编码**
        - **前高后低表示1，前低后高表示0**
		- 该编码特点是在每一个码元的中间出现电平跳变，位中间的跳变既作为时钟信号（可用于同步），又作为数据信号
		- **所占的频带宽度是原始的基带宽度的两倍，即每个码元都被调成两个电平，所以数据传输速率只有波特率的1/2**（在一个时钟周期内电平变化了两次，而只传输了一位比特），编码效率为50%
        - **以太网使用的编码方式就是曼彻斯特编码**
	- 差分曼彻斯特编码	
        - 若码元为1，则前半个码元的电平与上一个码元的电平相同，若为0，则相反。（**前同后异为1，前异后同为0**）
		- 该编码的特点是在每个码元中间都有一次电平的跳转，可以实现自同步，且抗干扰强于曼彻斯特编码。
	- 4B/5B编码：
        - 比特流中插入额外的比特以打破一连串的0或1，就是用5个比特来编码4个比特的数据，之后再传给接收方，因此称为4B/5B，编码效率为80%
        - 5位码共32种组合，但只采用其中的16种对应16种不同的4位码，其他16种作为控制码（帧的开始和结束、线路的状态信息等）或保留
- 数字数据**调制为**模拟信号
    - 1）幅移键控（ASK）：调幅
    - 2）频移键控（FSK）：调频
    - 3）相移键控（PSK）：调相
    - 4）正交振幅调制（QAM）：在频率相同的前提下，将ASK与PSK结合起来，形成叠加信号。设波特率为B，采用m个相位，每个相位有n种振幅，则该QAM技术的数据传输速率R为 R= B log2(mn) (b/s)
- 模拟数据**编码为**数字信号
	- 计算机内部处理的是二进制，处理的都是数字音频，所以需要将模拟音频通过采样、量化转换成有限个数字表示的离散序列（即实现音频数字化）
	- 典型的例子
		- 对音频信号进行编码的脉码调制（PCM），在计算机应用中，能够达到最高保真水平的就是PCM编码。它的主要步骤包括三步：抽样、量化、编码
	- 抽样
		- 对模拟信号进行周期性扫描，把时间上连续的信号变成时间上离散的信号
		- 为了使得所得到的离散信号能无失真地代表被抽样的模拟数据，要使采样定理进行采样：**f采样频率 ≥ 2f信号最高频率**
	- 量化：把抽样取得的电平幅值**按照一定的分级标度**转化为对应的数字值，并取整数，这就把连续的电平幅值转换为离散的数字量
	- 编码：把量化的结果转换为与之对应的二进制编码
- 模拟数据**调制为**模拟信号
	- 在模拟信号传输过程中，可能信道的长度非常长，环境比较恶劣，会导致传输的模拟信号会受到衰减
	- 为了保证传输的有效性，需要将信号调制成频率更高的信号来应对传输过程的衰减
    - 接收方接收到调制的信号后，通过**解调器**将信号还原为原来的信号

**王道习题：**

一轮标记题：1 3 4 9 10 17 18 20 25 29 33 36

二轮重做：9 16 17 18 25 41

大题：2 4 5(答案都看不懂！)
1.
- 答：分组交换生成的PDU的长度较短且是固定的，而报文交换生成的PDU的长度不是固定的。正是这一差别使得分组交换具有独特的优点：①缓冲区易于管理；②分组的平均延迟更小，网络中占用的平均缓冲区更少；③更易标准化；④更适合应用。因此，现在的主流网络基本上都可视为分组交换网络

2.
- 1) 2.57s
- 2) 32MB
- 3) 它表示发送方在收到一个响应之前能够发送的数据量
- 4) 在图像可以开始到达地面之前，至少需要一个RTT。假定仅有带宽延迟，那么发送需要的时间等于25MB/(100Mb/s)=(25×1024×1024×8)bit/(100Mb/s)≈2.1s。因此，直到最后一个图像位到达地球，总共花的时间等于2.1+2.57=4.67s

3.
- 1) (10000b / 10Mb/s) * 2 + 20μs * 2 + 35μs = 2075μs
- 2) 10000b / 10Mb/s + 5000b / 10Mb/s + 20μs * 2 + 35μs = 1575μs

4.
- 解：每部电话平均每小时通话次数=4/8=0.5次，每次通话6分钟，因此一部电话每小时占用一条电路3分钟，即20部电话可共享一条线路。**由于只有10%的呼叫是长途，因此200部电话占用一条完全时间的长途线路**。局间干线复用了10^6/(4×10)=250条线路，每条线路支持200部电话，因此一个端局能支持的最大电话数是200×250=50000部

5.
- 解：由于每个话路采用7bit编码，然后再加上1bit信令码元，因此一个话路占用8bit。帧同步码是在24路的编码之后加上1bit，因此每帧有8bit×24 + 1bit = 193bit。因为每秒采样8000次，因此采样频率为8000Hz，即采样周期为1/8000s = 125μs。所以T1的数据率为193bit/(125×10^-6s)= 1.544Mb/s

6.
- 解：
    - 整个传输过程的总时延 = 连接建立时延 + 源点发送时延 + 中间结点的发送时延 + 中间结点的处理时延 + 传播时延
    - 源点要将L位的报文分割成分组，分组数 = L/p，每个分组的长度为(h+p)，源点要发送的数据量 = (h+p)L/p，所以源点的发送时延 = (h+p)L/(pb)秒
    - 每个中间结点的发送时延 = (h+p)/b秒，源点和终点之间的线路数为k，所以有k-1个中间结点，因此中间结点的发送时延 = (h + p)(k - 1)/b秒
    - 中间结点的处理时延 = m(k-1)秒，传播时延 = kd秒。
    - 所以源结点开始发送数据直至终点收到全部数据所需要的时间= s +(h +p)L/(pb)+(h+ p)(k- 1)/b + m(k- 1)+ kd秒。

错题总结：
- 注意区分「采样频率」和「信道频率」
- 不同的数据交换方式有不同的性能。为了使数据在网络中的传输时延最小，首选的交换方式是电路交换；为保证数据无差错地传送，不应选用的交换方式是电路交换；在出错率很高的传输系统中，选用数据报方式更合适
- 电路交换是真正的物理线路交换，例如电话线路；**虚电路交换是多路复用技术，每条物理线路可以进行多条逻辑上的连接**。虚电路不只是临时性的，它提供的服务包括永久性虚电路(PVC)和交换型虚电路(SVC)，其中前者是一种提前定义好的、基本上不需要任何建立时间的端点之间的连接，而后者是端点之间的一种临时性连接，这些连接只持续所需的时间，并且在会话结束时就取消这种连接。数据报服务是无连接的，不提供可靠性保障，也不保证分组的有序到达。
- 虚电路服务需要有建立连接的过程，每个分组使用短的虚电路号，属于同一条虚电路的分组按照同一路由进行转发，分组到达终点的顺序与发送顺序相同，可以保证有序传输，不需要为每条虚电路预分配带宽

#### (3)传输介质及其特性

定义：
- 传输介质也称传输媒体，它是数据传输系统中发送设备和接收设备之间的物理通路
- 传输信息所利用的一些传输媒体，如双绞线、光缆、无线信道等，**并不在物理层协议之内而在物理层协议之下**，因此有人将物理媒体称作第0层（物理层规定了电气特性，所以能识别所传送的是比特流。）
- 传输介质可以分为：导向性传输介质和非导向性传输介质
    - 导向性传输介质：铜线，光纤
    - 非导向性传输媒介质：空气，真空，海水

双绞线：
- 把两根互相绝缘的铜导线并排放在一起，然后用规则的方法绞合起来。绞合可减少对相邻导线的电磁干扰
- 双绞线的带宽取决于铜线的粗细和传输的距离
- 从用户电话机到交换机的双绞线称为用户线或用户环路
- 非屏蔽双绞线UTP：无屏蔽层的双绞线
- 屏蔽双绞线STP：为了提高双绞线抗电磁干扰的能力，可以在双绞线的外面再加上一层用金属丝编织成的屏蔽层
- 优缺点：价格便宜，通信距离短，长距离的模拟传输需要放大器放大衰减信号，对于数字传输则要用**中继器**将失真的信号整形

同轴电缆：
- 同轴电缆由内导体铜质芯线（单股实心线或多股绞合线）、绝缘层、**网状编织的外导体屏蔽层**（也可以是单股的）以及保护塑料外层所组成
- 基带同轴电缆：传送基带数字信号，用于局域网
- 带宽同轴电缆：传送宽带信号，用于有线电视系统
- 优缺点：由于外导体屏蔽层的作用，同轴电缆具有很好的抗干扰特性，被广泛用于传输较高速率的数据，其传输距离比双绞线更远，价格也更高

光纤：
- 光纤通信就是利用光导纤维（以下简称为光纤）传递光脉冲来进行通信。有光脉冲相当于1，而没有光脉冲相当于0
- 特点：
	- 传输损耗小，中继距离长，对远距离传输特别经济。
	- 抗雷电和电磁干扰性能好。
	- 无串音干扰，保密性好，也不易被窃听或截取数据。
	- 体积小，重量轻。
- 分类：

名称|定义|光源|特点
:-:|-|-|-
单模光纤|一种在**横向模式**直接传输光信号的光纤|定向性很好的激光二极管|**衰耗小**，适合远距离传输
多模光纤|有**多种**传输光信号模式的光纤|发光二极管|**易失真**，适合近距离传输

联动：
- 10BASE-T是传送**基带信号**的**双绞线以太网**，**T表示采用双绞线**，现10BASE-T采用的是**无屏蔽双绞线(UTP)**，传输速率是10Mb/s。物理上采用星型拓扑，逻辑上总线型，每段双绞线最长为100m，采用**曼彻斯特编码**，采用CSMA/CD介质访问控制

**王道习题：**

一轮标记题：1 3 4 7

二轮重做：7 9 ~ 12

错题总结：
- 传统以太网采用广播的方式发送信息，同一时间只允许一台主机发送信息，否则各主机之间就会形成冲突，因此主机间的通信方式是半双工
- 同轴电缆比双绞线的传输速率更快，得益于其高屏蔽性，从而既有很高的带宽，又有很好的抗噪性
- **光纤的直径减小到与光线的一个波长相同时，光纤就如同一个波导，光在其中没有反射，而沿直线传播，这就是单模光纤**

#### (4)信道复用技术

- 复用是通信技术中的一个重要概念
- 复用就是通过一条物理线路同时传输多路用户的信号
- 当网络中传输媒体的传输容量大于多条单一信道传输的总通信量时，可利用复用技术在一条物理线路上建立多条通信信道来充分利用传输媒体的带宽
- 信道划分的实质就是通过分时、分频、分码等方法把原来的一条广播信道，逻辑上分为几条用于两个结点之间通信的互不干扰的子信道，实际上就是把广播信道转变为点对点信道。具体见3-6（介质访问控制协议）

#### (5)数字传输系统

早期的数字传输系统存在的缺点：
1. 速率标准不统一
2. 不是同步传输

SDH/SONET标准的制定，使北美、日本和欧洲这三个地区三种不同的数字传输体制在STM-1等级上获得了统一。各国都同意将这一速率以及在此基础上的更高的数字传输速率作为国际标准。这是第一次真正实现了数字传输体制上的世界性标准。现在SDH/SONET标准已成为公认的新一代理想的传输网体制，因而对世界电信网络的发展具有重大的意义。SDH标准也适合于微波和卫星传输的技术体制

#### (6)宽带接入技术

ADSL技术：
- 非对称数字用户线ADSL技术就是用数字技术对现有的模拟电话用户线进行改造，使它能够承载带宽业务（**这里的非对称体现在上行与下行的带宽不对称**）
- 标准模拟电话信号的频带被限制在300 ~ 3400Hz的范围内，但用户线本身实际可通过的信号频率仍然超过1MHz
- ADSL技术就把0 ~ 4kHz低端频谱留给传统电话使用，而把原来没有被利用的高端频谱留给用户上网使用
- ADSL在用户线（铜线）的两端各安装一个**ADSL调制解调器**
- ADSL的传输距离
    - ADSL的传输距离取决于数据率和用户线的线径（用户线越细，信号传输时的衰减就越大）
    - ADSL所能够得到的最高数据传输速率于实际的用户线上的信噪比密切相关。
    - 例如：0.5毫米线径的用户线，传输速率为1.5 ~ 2.0 Mb/s时可传送5.5公里，但当传输速率提高到6.1Mb/s时，传输距离旧缩短为3.7公里。如果把用户线的线径减小到0.4毫米，那么在6.1Mb/s的传输速率下就只能传送2.7公里

**光纤***同轴*混合网（HFC网）：
- HFC网是在目前覆盖面很广的有线电视网CATV的基础上开发的一种居民宽带接入网
- HFC网的主干线采用**光纤**
- 每个家庭要安装一个用户接口盒，用户接口盒UIB（user interface box）要提供三种连接，即：
    - 使用**同轴电缆**连接到机顶盒（set-top box），然后再连接到用户的电视机
    - 使用**双绞线**连接到用户的电话机
    - 使用**电缆调制解调器**连接到用户的计算机

FTTx技术：
- FTTx是一种实现宽带接入网的方案，代表多种宽带光纤接入方式：
    - 光纤到户FTTH（fiber to the home）：光纤一直铺设到用户家庭，可能是居民接入网最后的解决方法
    - 光纤到大楼FTTB（fiber to the building）：光纤进入大楼后就转换为电信号，然后用电缆或双绞线分配到各用户
    - 光纤到路边FTTC（fiber to the curb）：光纤铺到路边，从路边到各用户可使用**星形结构双绞线**作为传输媒体

#### (7)其他

电路交换、报文交换与分组交换：
- 电路交换：需要建立一条专用的数据通信路径，这条路径上可能包含许多中间节点。这条通信路径在整个通信过程中将被独占，直到通信结束才会释放资源。电路交换**适合实时性要求较高的大量数据传输的情况**
- 报文交换（注意，此处的“报文”与UDP中的“报文”不是同一个意思！）：以报文作为数据传输单位，携带有源地址和目的地址等信息。报文交换主要使用在早期的电报通信网中，现在较少使用，通常被较先进的分组交换方式所取代
- 分组交换：分组交换根据其通信子网向端点系统提供的服务，**还可进一步分为面向连接的虚电路方式和无连接的数据报方式**。这两种服务方式都由**网络层**提供。要注意数据报方式和虚电路方式是分组交换的两种方式

#### 本章小结

什么是基带传输、频带传输和宽带传输?三者的区别是什么?
- 基带传输（数据→数字）：通常用于**局域网**；常用的编码方法有不归零编码和曼彻斯特编码
- 频带传输（数据→模拟）：用数字信号对特定频率的载波进行调制（数字调制)，将其变成适合于传送的信号后再进行传输，这种传输方式就是频带传输。远距离传输或无线传输时，数字信号必须用频带传输技术进行传输。利用频带传输，不仅解决了电话系统传输数字信号的问题，而且可以实现多路复用，进而提高传输信道的利用率。同样传输1010，经过调制，一个码元对应4个二进制位，假设码元A代表1010，那么在模拟信道上传输码元A就相当于传输了1010，这就是频带传输。**借助频带传输，可将链路容量分解成两个或多个信道，每个信道可以携带不同的信号，这就是宽带传输**。宽带传输中所有的信道能同时互不干扰地发送信号，链路容量大大增加。比如把信道进行频分复用，划分为2条互不相关的子信道，分别在两条子信道上同时进行频带传输，链路容量就大大增加了，这就是宽带传输

什么是同步通信和异步通信？
- 同步通信的通信双方必须先建立同步，即双方的时钟要调整到同一个频率。收发双方不停地发送和接收连续的同步比特流。主要有两种同步方式：一种是全网同步，即用一个非常精确的主时钟对全网所有结点上的时钟进行同步；另一种是准同步，即各结点的时钟之间允许有微小的误差，然后采用其他措施实现同步传输。**同步通信数据率较高，但实现的代价也较高**
- 异步通信在发送字符时，所发送的字符之间的时间间隔可以是任意的，但接收端必须时刻做好接收的准备。发送端可以在任意时刻开始发送字符，因此必须在每个字符开始和结束的地方加上标志，即开始位和停止位，以便使接收端能够正确地将每个字符接收下来。异步通信也可以帧作为发送的单位。这时，帧的首部和尾部必须设有一些特殊的比特组合，使得接收端能够找出一帧的开始（即帧定界）。**异步通信的通信设备简单、便宜，但传输效率较低（因为标志的开销所占比例较大)**

如何提高信息传输速率？
- 要么设法提高传输线路的带宽，要么设法提高所传信道的信噪比，此外没有其他任何办法

### <a name="19">（三）数据链路层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)数据链路层功能和设计要点

- 数据链路层在网络体系结构中的地位
- 为网络层提供服务
    - 无确认的无连接服务【适用于实时通信或误码率较低的通信信道 - 以太网】
    - 有确认的无连接服务【适用于误码率较高的通信信道 - 无线通信】
    - 有确认的有连接服务【适用于对可靠性，实时性要求较高的场合】
- 使用**点对点**信道的数据链路层
    - **三个重要问题：封装成帧，透明传输，差错检测**
- 使用**广播**信道的数据链路层
    - 共享式以太网的媒体接入控制协议CSMA/CD
    - 802.11局域网的媒体接入控制协议CSMA/CA
- 数据链路层的互连设备
    - 网桥和交换机的工作原理
    - 集线器（物理层互连设备）与交换机的区别

**组帧（封装成帧）：**
- 封装成帧是指数据链路层给上层交付的协议数据单元添加**帧头和帧尾**使之成为帧
    - 帧头和帧尾中包含有重要的控制信息
    - 帧头和帧尾的作用之一就是帧定界
- 为了提高帧的传输效率，应当使帧的数据部分的长度尽可能大些
- 考虑到差错控制等多种因素，每一种数据链路层协议都规定了帧的数据部分的长度上限，即**最大传送单元MTU**
- 透明传输是指**数据链路层对上层交付的传输数据没有任何限制**，就好像数据链路层不存在一样
- 组帧方法：【目前最常用的是比特填充法+违规编码法】
    - 字符计数法	
        - 在帧头部使用一个计数字段来标明帧内字符数
        - 缺点：如果计数字段出错，就失去了帧定界划分的依据【计数字段的脆弱性】
    - 使用字符填充的首位定界法	
        - SOH表示帧的首部开始，EOT表示帧的结束
        - 在特殊字符前面填充一个转义字符ESC来区分
        - 接收方收到数据会删除ESC然后得到原来的数据
        - 缺点：实现复杂与不兼容
    - 使用比特填充的首位标志法	
        - 使用01111110表示一帧的开始和结束（6个1）
        - 在数据中如果出现连续的5个1，就插入一个0
        - 很容易用硬件实现，性能优于字符填充法
    		违规编码法	
        - 在**物理层进行比特编码**时，通常采用违规编码法
        - 局域网IEEE 802标注采用这个方法
        - 违规编码法不需要填充技术，只适合于采用冗余编码的特殊编码环境
可靠传输
**王道习题：**

大题：
1.
- 答：
    - 1) 5 A B ESC FLAG（二进制）
    - 2) FLAG A B ESC ESC ESC FLAG FLAG（二进制）
    - 3) 01111110 01000111 11**0**100011 111**0**00000 011111**0**10 01111110

#### (2)错误检测和纠正（408压根没考过这个，961不知道考不考，先不复习）

#### (3)基本数据链路协议，包括：停止-等待协议、后退N帧协议和选择重传协议；

可靠传输的基本概念：
- 数据链路层向上层提供的服务类型
    - 不可靠传输服务：仅仅丢弃有误码的帧，其他什么也不做
    - 可靠传输服务：想办法实现发送端发送什么，接收端就收到什么
- 一般情况，有线链路的误码率比较低，为了减小开销，并不要求数据链路层向上提供可靠传输服务。即使出现误码，可靠传输由上层处理
- 传输差错还包括分组丢失，分组失序，分组重复
    - 分组丢失，分组失序以及分组重复一般不会出现在数据链路层，而出现在上层
- 可靠传输服务并不局限于数据链路层，其他各层也可以实现可靠传输
- 捎带确认：将确认帧捎带在一个回复的数据帧中
- 自动重传请求（ARQ）→连续ARQ协议：通信中用于处理信道所带来的差错
- 信道吞吐率 = 信道利用率 × 发送方的发送速率

停止-等待协议（SW）：
- 从滑动窗口机制的角度看，停止-等待协议相当于发送窗口和接收窗口大小均为1的滑动窗口协议
- ①数据帧错（误码）；②确认帧错（无数据帧没法发、丢失了、迟到了）
- 需要给数据分组编号，只需要1个比特编号，即编号0和1
- 超时计时器设置的重传时间一般略大于“从发送方到接收方的平均往返时间”
	- 在数据链路层点对点的往返时间好确认，重传时间好确认
    - 在传输层，由于端到端往返时间不确定，重传时间不好确认

后退N帧协议（GBN）：
- 为了减少开销，GBN协议规定接收端不一定每收到一个正确的数据帧就必须立即发回一个确认帧，而可以**在连续收到好几个正确的数据帧后，才**对最后一个数据帧发确认信息，或者可在自己有数据要发送时才将对以前正确收到的帧加以**捎带确认**。这就是说，对某一数据帧的确认就表明该数据帧和此前所有的数据帧均已正确无误地收到
- 若采用n比特对帧编号，**则其发送窗口的尺寸W_T应满足1 ≤ W_T ≤ 2 ^ n - 1**。若发送窗口的尺寸大于2 ^ n - 1，则会造成接收方无法分辨新帧和旧帧
- 由于接受窗口仍为1，因此可以保证数据的有序接收

选择重传协议（SR）：
- 在选择重传协议中，接收窗口和发送窗口的大小是相同的（选择重传协议是对单帧进行确认，所以发送窗口大于接收窗口会导致溢出，发送窗口小于接收窗口没有意义)，且最大值都为序号范围的一半，若采用n比特对帧编号，则**需要满足:W_Tmax = W_Rmax = 2 ^ (n - 1)**
- 所需缓冲区的数目等于窗口的大小

**王道习题：**

一轮标记题：3 8 13 14 15

二轮重做：3 4 8 10 13 15

大题：1 
1.
- 答：发送方:01234567012345670，发送方发送0 ~ 5号共6个数据帧时，因发送窗口已满，发送暂停。接收方收到所有数据帧，对每个帧都发送确认帧，并期待后面的6、7、0号帧。若所有的确认帧都未到达发送方，经过发送方计时器控制的超时时间后，发送方再次发送之前的6个数据帧，**而接收方收到0号帧后，无法判断是新的数据帧还是旧的重传的数据帧**。

2.
- 解：300bit

3.
- 解：
    - RTT = 250×2 = 500ms = 0.5s. 一个帧的发送时间等于2000bit / (100kb/s) = 20 × 10 ^ -3s
    - 一个帧发送完后经过一个单程时延到达接收方，再经过一个单程时延发送方收到应答，从而可以继续发送，因此要达到传输效率最大，就是不用等确认也可继续发送帧。设窗口值等于x，令2000bit × x / (100kb/s) = 20 × 10 ^ -3s + RTT = 0.52s，得x=26。要取得最大信道利用率，窗口值是26即可，因为在此条件下，可以不间断地发送帧，所以发送速率保持在100kb/s
    - 因此帧的顺序号应为5位。在使用后退N帧ARQ的情况下，最大窗口值是31，大于26，可以不间断地发送帧，此时信道利用率是100%

 4 ~ 7.
- 待做

错题总结：
- 计算信道利用率：推荐用**画图法**
- 发送窗口的大小 ≤ 窗口总数 - 1
- 数据帧长度不确定时，为保证信道利用率达到最高，**应以最短的帧长计算**

#### (4)滑动窗口协议

GBN和SR，就是滑动窗口协议与请求重传技术的结合

#### (5)点对点协议PPP（408没考过，这年头谁还拨号上网）

- 广域网：通常是指覆盖范围很广（远超一个城市的范围）的长距离网络，它是因特网的核心部分
    - 广域网由**一些结点交换机（注意不是路由器）及连接这些交换机的链路**组成。结点交换机的功能是将分组存储并转发。结点之间都是点到点连接，但为了提高网络的可靠性，通常一个结点交换机往往与多个结点交换机相连（一言以蔽之，**局域网——路由器——结点交换机——结点交换机——路由器——个人主机**）
- 互联网：互联网不等于广域网，互联网可以连接不同类型的网络（既可以连接局域网，又可以连接广域网)，通常使用路由器来连接
- 以太网：802.3局域网称为以太网
- 局域网和广域网的区别：

区别|广域网|局域网
-|-|-
覆盖范围|很广，通常跨区域|较小，通常在一个区域内
连接方式|结点之间都是**点到点连接**，但为了提高网络的可靠性，一个结点交换机往往与多个节点交换机相连|普遍采用**多点接入**技术
OSI参考模型层次|三层：物理层，数据链路层，**网络层**|两层：物理层，数据链路层
着重点|强调资源共享，通信子网主要使用分组交换技术|强调数据传输

- 局域网和广域网的联系：
    1. 广域网和局域网都是互联网的重要组成构建，从互联网的角度来看，二者平等！**（不是包含关系）**
    2. 连接到一个广域网和一个局域网上的主机在该网内进行通信，只需要使用其网络的物理地址

- PPP (Point-to-Point Protocol）是使用串行线路通信的**面向字节**的协议，该协议应用在直接连接两个结点的链路上。设计的目的主要是用来通过**拨号或专线方式**建立点对点连接发送数据，使其成为**各种主机、网桥和路由器之间简单连接**的一种共同的解决方案
    - **PPP和HDLC协议均是数据链路层协议**
    - HDLC是面向比特的协议，PPP协议是面向字节的协议
    - **PPP只支持全双工链路**
    - PPP协议不使用序号和确认机制，只保证无差错接收（CRC检验），而端到端差错检测由高层协议负责。HDLC协议的信息帧使用了编号和确认机制，能够提供可靠传输
	- **PPP协议的组成：**
		- 链路控制协议LCP：用于建立、配置以及测试数据链路的连接
		- 一套网络控制协议NCPs：其中的每一个协议支持不同的网络层协议
		- 一个将IP数据报封装到串行链路的方法
    - PPP帧：**标志字段F(7E) + 地址字段A(FF) + 控制字段C(03) + 协议字段（2字节）+ 信息字段（长度可变，大于等于0且小于等于1500）+ 帧检验序列FCS（2字节，即CRC里的冗余码，检验区为地址字段 + 控制字段 + 协议字段 + 信息字段）+ 标志字段F(7E)**，其中的7E就是上文的01111110
        - 注意：**因为PPP是点对点的，并不是总线形，所以无须采用CSMA/CD协议，自然就没有最短帧，所以信息段占0 ~ 1500字节，而不是46 ~ 1500字节**。另外，当数据部分出现和标志位一样的比特组合时，就需要采用一些措施来实现透明传输
    - PPP协议的状态变迁：从设备之间无链路开始，到先建立物理链路，再建立链路控制协议LCP链路。经过鉴别后再建立网络控制协议NCP链路，然后才能交换数据
        - 由此可见：PPP协议不是纯粹的数据链路层的协议，它还包含了物理层和网络层的内容。
	- PPP两端的网络层可以运行不同的网络层协议，但仍然能使用同一个PPP进行通信
    - PPP支持PAP和CHAP认证
        - CHAP的安全性更高
        - PAP在传输密码时是明文，CHAP在传输过程中传输哈希值
        - PAP认证通过两次握手实现，CHAP通过三次握手
    - PPP可用于拨号连接，支持动态分配IP地址

**王道习题：**

二轮重做：1 5 6 8

错题总结：
- 广域网不等于互联网。互联网可以连接不同类型的网络（既可以连接局域网，又可以连接广域网)，通常使用路由器来连接。广域网是单的网络，通常使用结点交换机连接各台主机（或路由器），而不使用路由器连接网络。其中**结点交换机在单个网络中转发分组**，而路由器在多个网络构成的互联网中转发分组
- 以太网是局域网的一种实现形式，其他实现形式还有令牌环网、FDDI（光纤分布数字接口，IEEE 802.8）等

#### (6)介质访问控制协议，包括介质访问控制基本概念、协议分类、CSMA/CD协议；

信道划分介质访问控制：
- 频分多路复用：分频
- 时分多路复用：分时。可分为同步时分多路复用和异步时分多路复用（又称统计时分复用）
	- 同步时分多路复用是一种静态时分复用技术，预先分配时间片
    - 异步时分多路复用是一种动态时分复用技术，动态分配时间片
    - FDM适合传输模拟信号，TDM适合传输数字信号
- 波分多路复用：光纤，分频
- 码分多路复用：
    - CDM是另一种共享信道的方法。
    - 由于CDM主要用于多址接入，常用的名词为码分多址CDMA
    - 与FDM和TDM不同，CDM的每一个用户可以在同样的时间使用同样的频带进行通信
    - 由于各用户使用经过特殊挑选的不同码型，因此各用户之间不会造成干扰
    - CDM最初用于军事通信，这种系统所发送的信号有很强的抗干扰能力频谱类似于白噪声，不易被敌人发现
    - 随着技术的进步，CDMA设备的价格和体积都大幅度下降，因而现在已广泛用于民用的移动通信中
    - CDMA中，每一个比特时间再划分为m个短的间隔，称为码片
    - 通常m=64或128
    - 使用CDMA的每一个站被指派一个唯一的m bit码片序列
        - *一个站如果要发送比特1，则发送他自己的m bit码片序列*
        - *一个站如果要发送比特0，则发送他自己的m bit码片序列的二进制反码*
    - 码片序列的挑选原则：
        1. 分配给每个站的码片序列**必须各不相同**，实际采用伪随机序列
        2. **分配给每个站的码片序列必须相互正交（内积=0）**‘
    - **具体到如何计算：序列中的1对应1，0对应-1，将对应站的码片序列与信道上的序列求规格化内积（也就是算完内积求平均），若计算结果为数值1，则被判断的站发送了比特1；若计算结果为数值-1，则被判断的站发送了比特0；若计算结果为数值0，则被判断的站未发送数据**

**随机访问协议分类【胜利者通过争用获得信道，从而获得信息的发送权，又称争用型协议】：**
- 纯ALOHA协议：纯ALOHA系统采用的重传策略是让各站等待一段随机的时间，然后再进行重传。若再次发生碰撞，则需要再等待一段随机的时间，直到重传成功为止
- **时隙**ALOHA协议
    - 时隙ALOHA协议把所有各站在时间上同步起来，并将时间划分为一段段等长的时隙(Slot)，规定只能在每个时隙开始时才能发送一个帧。从而避免了用户发送数据的随意性，减少了数据产生冲突的可能性，提高了信道的利用率
    - 帧到达 = 帧准备发送
    - 碰撞之后的重传策略与纯ALOHA类似
- CSMA（载波监听多点访问）
    - 并不适用确认机制
    - 1-坚持CSMA：坚持监听，且空闲时发送概率为1
    - 非坚持CSMA：如果信道忙，不坚持监听，而是等待一个随机的时间
    - p-坚持CSMA：
        - 如果信道忙，就持续监听（p-坚持CSMA适用于时隙信道，此处持续侦听就是推迟到下一个时隙再侦听）
        - 如果信道空闲，以概率p发送数据，以概率1-p推迟到下一个时隙。下一个时隙亦是如此，这个过程一直持续到数据发送成功或因其他结点发送数据而检测到信道忙为止，若是后者，则等待下一个时隙再重新开始侦听
        - 三者的比较：

信道状态|1-坚持CSMA|非坚持CSMA|p-坚持CSMA
-|-|-|-
空闲|立即发送数据|立即发送数据|以概率P发送数据，以概率1-p推迟到下一个时隙
忙|继续坚持侦听|放弃侦听，等待一个随机的时间再侦听|持续侦听，直到信道空闲

**CSMA/CD（载波监听多点访问/碰撞检测）：**
- 是对CSMA的改进，是早期共享信道以太网适用的信道访问控制协议，适用于总线形网络或**半双工**网络环境
- 流程：“先听后发，**边听边发**，冲突停发，随机重发”：
    1. 适配器从网络层获得一个分组，封装成以太网帧，放入适配器的缓存，准备发送
    2. 如果适配器侦听到信道空闲，那么它开始发送该帧。如果适配器侦听到信道忙，那么它持续侦听直至信道上没有信号能量（**空闲9.6μs/96比特时间，即帧间间隔**），然后开始发送该帧
    3. 在发送过程中，适配器持续检测信道。若一直未检测到碰撞，则顺利地把这个帧发送完毕。若检测到碰撞，则中止数据的发送，并发送一个拥塞信号，以让所有用户都知道
    4. 在中止发送后，适配器就执行**指数退避算法**，等待一段随机时间后返回到步骤2
- 站A在发送帧后至多经过时间2τ（端到端传播时延的2倍）就能知道所发送的帧有没有发生碰撞，因此**把以太网端到端往返时间2τ称为争用期（又称冲突窗口或碰撞窗口）**。只有经过争用期这段时间还未检测到碰撞时，才能确定这次发送不会发生碰撞
- *最小帧长 = 总线传播时延 × 数据传输速率 × 2*
- 以太网规定取51.2μs为争用期的长度。对于10Mb/s的以太网，在争用期内可发送512bit，即64B。因此，**以太网规定最短帧长为64B**，凡长度小于64B的帧都是由于冲突而异常中止的无效帧，收到这种无效帧时应立即丢弃。如果只发送小于64B的帧，**那么需要在MAC子层中于数据字段的后面加入一个整数字节的填充字段**，以保证以太网的MAC帧的长度不小于64B
- **截断二进制指数退避算法**【可使重传需要推迟的平均时间随重传次数的增大而增大（这也称**动态退避**），因而能降低发生碰撞的概率，有利于整个系统的稳定】
    1. 确定基本退避时间，一般取两倍的总线端到端传播时延2τ（即争用期）
    2. 定义参数k，它等于重传次数，**但k不超过10，即k=min(重传次数,10)**。当重传次数不超过10时，k等于重传次数；当重传次数大于10时，k就不再增大而一直等于10（这个条件往往容易忽略）
    3. 从离散的整数集合(0,1,...,2^k-1)中随机取出一个数r，重传所需要退避的时间就是r倍的基本退避时间，即2rτ
    4. 当重传达**16次**仍不能成功时，说明网络太拥挤，认为此帧永远无法正确发出，抛弃此帧并向高层报告出错（这个条件也容易忽略）
- 并不适用确认机制
- 总结！：
    - 帧的发送流程：封装成帧 → 载波监听（CS）→ 碰撞检测（CD） → 截断二进制指数退避算法 → 发送该帧 → 发送结束
    - 帧的接收流程：监听信道 → 信道活跃？ → 开始接收帧 → 接收完成？ → **帧太短？**（小于最短帧长则认为遭遇了碰撞）→ **地址正确？**（帧的目的MAC地址与接收方的MAC地址相同或是广播地址）→ **校验正确？**（使用CRC检查帧是否出现了误码）→ 接收该帧 → 接收结束

轮询访问——令牌传递协议：逻辑拓扑必须是环，适合负载很高的广播信道，证明了即使是广播信道也可通过介质访问控制机制使广播信道逻辑上变为点对点的信道，所以说数据链路层研究的是“点到点”之间的通信

**王道习题：**

一轮标记题：7 9 10 12 14 17 25 26 27 30

二轮重做：10 27

大题：3(考察时隙ALOHA)
1.
- 答：
    - CSMA/CD是一种动态的介质随机接入共享信道方式，而TDM是一种静态的信道划分方式，所以从对信道的利用率来说，CSMA/CD用户共享信道，更灵活，信道利用率更高。TDM不同，它为用户按时隙固定分配信道，**用户没有数据传送时，信道在用户时隙就浪费了**
    - CSMA/CD让用户共享信道，因此同时有多个用户需要使用信道时会发生碰撞，从而降低信道的利用率；而在TDM中，用户在分配的时隙中不会与其他用户发生冲突
    - 对局域网来说，连入信道的是相距较近的用户，因此通常信道带宽较大。使用TDM方式时，用户在自己的时隙中没有发送的情况更多，不利于信道的充分利用
    - 对于计算机通信来讲，突发式的数据更不利于使用TDM方式

2.
- 解：100bit

3.
- 解：50 / 8000 = 0.00625

4 ~ 8.
- 待做

错题总结：
- 王道第10题，**本质就是一个初中物理：s = vt**，现在v增加了，那么要么增加s，要么减少t！而t，即传播时延，又存在一个s = vt，传播速率一般是不会增加或减少的，由此可知，**传播时延与链路距离成正比**

#### (7)以太网，包括MAC地址、IEEE局域网标准、以太网、高速以太网技术；

局域网的基本概念和体系结构：
- 基本概念：局域网是指在一个较小的地理范围（如一所学校）内，将各种计算机、外部设备和数据库系统等通过双绞线、同轴电缆等连接介质互相连接起来，组成资源和信息共享的计算机互联网络。
- 三要素：拓扑结构、传输介质、介质访问控制方式
    - 常见拓扑结构：①星形结构；②环形结构；③总线形结构；④星形和总线形结合的复合型结构
    - 常用传输介质：双绞线、铜缆和光纤等多种传输介质，其中双绞线为主流传输介质
    - 常用介质访问控制方式：CSMA/CD、令牌总线和令牌环，其中前两种方法主要用于总线形局域网，令牌环主要用于环形局域网
- 简单了解：前面我们知道有TCP/IP、OSI，现在还有个IEEE 802模型，其定义的局域网只对应OSI的数据链路层 + 物理层，且数据链路层 = LLC子层 + MAC子层（由于以太网在局域网市场中取得垄断地位，几乎成为局域网的代名词，而802委员会制定的LLC子层作用已经不大，因此现在许多网卡仅装有MAC协议而没有LLC协议）

**以太网与IEEE 802.3：**
- 以太网的一系列关键词：**逻辑拓扑是总线形结构**；物理拓扑是星形或拓展星形结构；基带信号；CSMA/CD；广播和组播；无连接服务；曼彻斯特编码
- 以太网的传输介质与网卡：

参数|10BASE5|10BASE2|10BASE-T|10BASE-FL
-|-|-|-|-
传输媒体|**基带同轴电缆（粗缆）**|**基带同轴电缆（细缆）**|**非屏蔽双绞线**|**光纤对(850nm)**
编码|曼彻斯特编码|曼彻斯特编码|曼彻斯特编码|曼彻斯特编码
物理拓扑结构|总线形|总线形|**星形**|**点对点**
最大段长|500m|185m|100m|2000m
最多结点数目|100|30|2|2

- **以太网的MAC帧：**
    - MAC地址也叫物理地址
    - MAC地址长6字节，一般用由连字符（或冒号）分隔的12个十六进制数表示，如02-60-8c-e4-b1-21。高24位为厂商代码，低24位为厂商自行分配的网卡序列号
    - 以太网V2的MAC帧：前导码（7字节的前同步码 + 1字节的帧开始定界符，注意，这一部分不属于MAC帧）+ **目的地址（6字节）+ 源地址（6字节）+ 类型（2字节，指出数据域中携带的数据应交给哪个协议实体处理）+ 数据（46 ~ 1500字节）+ 填充 + 校验码**（采用CRC，校验范围是整个MAC帧但不包括自己）
    - 以太网802.3的MAC帧：类型 → 长度/类型
    - 区分：不同的Type字段值可以用来区别这两种帧，当Type字段值小于等于1500（或者十六进制的0x05DC）时，帧使用的是EEE802.3格式。当Type字段值大于等于1536（或者十六进制的0x0600）时，帧使用的是V2格式。以太网中大多数的数据帧使用的是V2格式
- 高速以太网：
    - 100BASE-T以太网：基本与10BASE-T一致，但速率为100Mb/s。可在全双工方式下工作而无冲突发生，在全双工方式下不使用CSMA/CD协议；帧间时间间隔从原来的9.6μs改为现在的0.96μs
    - 吉比特以太网：又称千兆以太网，允许在1Gb/s速率下用全双工和半双工两种方式工作
    - 10吉比特以太网：10吉比特以太网不再使用铜线而**只使用光纤**作为传输媒体。10吉比特以太网**只工作在全双工方式**，因此没有争用问题，也不使用CSMA/CD协议

**VLAN基本概念与基本原理：**

- 802.3ac标准定义了支持VLAN的以太网帧格式的扩展。它在以太网帧中插入一个4字节的标识符（**插入在源地址字段和类型字段之间**)，称为VLAN标签，用来指明发送该帧的计算机属于哪个虚拟局域网。插入VLAN标签的帧称为802.1Q帧，由于VLAN帧的首部增加了4字节，**因此以太网的最大帧长从原来的1518字节变为1522字节**
- VLAN标签的前两个字节置为0x8100，表示这是一个802.10帧。在VLAN标签的后两个字节中，前4位没有用，后12位是该VLAN的标识符VID，它唯一标识了该802.1Q帧属于哪个VLAN。**12位的VID可识别4096个不同的VLAN，但0和4095都不用来表示VLAN，因此用于表示VLAN的VID的有效取值范围是1 ~ 4094**。插入VID后，802.1Q帧的FCS必须重新计算
- 不同VLAN的主机之间的通信，需要通过上层的路由器

**王道习题：**

一轮标记题：4 5 8 9 10 11 13 16 17 20 22

二轮重做：4 10 16 17 20 22

错题总结：
- 在以太网中，如果一个结点要发送数据，那么它将以“广播”方式把数据通过作为公共传输介质的总线发送出去，连在总线上的所有结点（**包括发送结点**）都能“收听”到发送结点发送的数据信号
- T表示传输介质为双绞线，F表示光纤
- 链路聚合是解决交换机之间的宽带瓶颈问题的技术

#### (8)局域网互连技术，包括物理层及数据链路层互连技术、网桥概念和工作原理、局域网交换机工作原理；

- 网段：两个或多个以太网通过网桥连接后，就成为一个覆盖范围更大的以太网，而原来的每个以太网就称为一个网段
- 网桥：网桥工作在链路层的MAC子层，可以使以太网各网段成为隔离开的碰撞域（又称冲突域）
    - 如果把网桥换成工作在物理层的转发器，那么就没有这种过滤通信量的功能
    - 网桥具有路径选择的功能，例如：网络1和网络2通过网桥连接后，网桥接收网络1发送的数据帧，检查数据帧中的地址，如果是网络2的地址，那么就转发给网络2；如果是网络1的地址，**那么就将其丢弃，因为源站和目的站处在同一个网段，目的站能够直接收到这个帧而不需要借助网桥转发**
- **局域网**交换机（以太网交换机）：多端口网桥
    - 利用以太网交换机还可以方便地实现虚拟局域网VLAN，VLAN不仅可以隔离冲突域，而且可以隔离广播域
    - 以太网交换机的每个端口都直接与单台主机相连（网桥的端口往往连接到一个网段），并且一般都工作在**全双工方式**
    - 对于传统 10Mb/s 的共享式以太网，若共有N个用户，拥有N个端口的交换机的总容量就是N × 10Mb/s，这是交换机最大的优点
    - 以太网交换机主要采用两种交换模式：
        1. 直通式交换机，只检查帧的目的地址，这使得帧在接收后几乎能马上被传出去。这种方式速度快，但缺乏智能性和安全性，也无法支持具有不同速率的端口的交换
        2. 存储转发式交换机，先将接收到的帧缓存到高速缓存器中，并检查数据是否正确，确认无误后通过查找表转换成输出端口将该帧发送出去。如果发现帧有错，那么就将其丢弃。优点是可靠性高，并能支持不同速率端口间的转换，缺点是延迟较大
    - 以太网一般都具有多种速率的端口
    - 决定一个帧是应该转发到某个接口还是应该将其丢弃称为过滤。决定一个帧应该被移动到哪个接口称为转发。交换机的过滤和转发借助于交换表(switch table)完成
    - 自学习的过程见习题
    - 交换表中的每个表项都设有一定的有效时间，过期的表项会自动删除。这就保证了交换表中的数据符合当前网络的实际状况

**王道习题：**

一轮标记题：4 7 12 13 17

二轮重做：7 12 16 17

错题总结：
- 交换机能隔离冲突域，工作在全双工状态，使网络中多对结点同时通信，提高了网络的利用率，这是交换机的优点
- 直通交换方式是指以太网交换机可以在各端口间交换数据。它在输入端口检测到一个数据包时，检查该包的包头，获取包的目的地址，启动内部的动态查找表转换成相应的输出端口，在输入与输出交叉处接通，把数据包直通到相应的端口，实现交换功能。通常情况下，直通交换方式只检查数据包的包头即前14个字节，由于不需要考虑前导码，只需要检测目的地址的6B

#### (9)无线局域网(IEEE802.11)基本知识，包括CSMA/CA协议原理等。

无线局域网的组成：
- 有固定基础设施无线局域网：IEEE制定了无线局域网的802.11系列协议标准，802.11使用星形拓扑，其中心称为接入点AP，在MAC层使用CSMA/CA协议。使用802.11系列协议的局域网又称Wi-Fi
    - 802.11标准规定无线局域网的最小构件是基本服务集BSS。一个基本服务集覆盖的地理范围称为一个基本服务区BSA，无线局域网的基本服务区的范围直径一般不超过100m
    - *移动站A → AP1 →（有线）→ AP2 → 移动站B*
- 无固定基础设施移动自组织网络：又称自组网络(ad hoc network)。自组网络没有上述基本服务集中的AP，而是由一些平等状态的移动站相互通信组成的临时网络。各结点之间地位平等，中间结点都为转发结点，因此都具有路由器的功能
    - 自组网络和移动IP并不相同。移动IP技术使漫游的主机可以用多种方法连接到因特网，其核心网络功能仍然是基于固定网络中一直使用的各种路由选择协议。而自组网络是把移动性扩展到无线领域中的自治系统，具有自己特定的路由选择协议，并且可以不和因特网相连
- 无线网不能使用CSMA/CD的原因：
    1. 接收信号的强度往往会远小于发送信号的强度，因此若要实现碰撞检测，则硬件上的花费就会过大
    2. 在无线通信中，并非所有的站点都能够听见对方，即**存在“隐蔽站”问题**

**CSMA/CA（载波监听多点访问/碰撞避免）：**
- 是802.11局域网采用的无线信道访问控制协议
- 802.11局域网在使用CSMA/CA的同时，还使用链路层的ARQ方案
- 为了尽量避免碰撞，802.11规定，所有的站完成发送后，必须再等待一段很短的时间（继续监听）才能发送下一帧。这段时间称为帧间间隔IFS
- **当且仅当检测到信道空闲且这个数据帧是要发送的第一个数据帧时，才不使用退避算法**。其他所有情况都必须使用退避算法，具体为：①在发送第一个帧前检测到信道忙；②每次重传；③每次成功发送后要发送下一帧
- 退避算法简单总结：随机选取回退值，忙则不变，空闲（**检测到DIFS**）则自减，减至0则可以发送了
- 预约：信道预约不是强制性规定，各站可以自己决定使用或不使用信道预约。只有当数据帧长度超过某一数值时，使用RTS和CTS帧才比较有利

**CSMA/CD与CSMA/CA的区别:**
1. CSMA/CD可以检测冲突，但无法避免；CSMA/CA发送数据的同时不能检测信道上有无冲突，本结点处没有冲突并不意味着在接收结点处就没有冲突，只能尽量避免
2. 传输介质不同。CSMA/CD用于总线形以太网，CSMA/CA用于无线局域网802.11a/b/g/n等
3. 检测方式不同。CSMA/CD通过**电缆中的电压变化**来检测；而CSMA/CA采用**能量检测、载波检测和能量载波混合检测**三种检测信道空闲的方式

**802.11局域网的MAC帧：**
- 802.11局域网的MAC帧——数据帧：MAC首部（共30字节，很复杂）+ 数据部分（不超过2312字节）+ 帧检验序列FCS（4字节）
- IEEE 802.11数据帧有4种子类型，分别是IBSS、From AP、To AP 和 WDS，下面介绍的是中间的两种。注意，接受地址 ≠ 目的地址，发送地址 ≠ 源地址！

去往 AP|来自 AP|地址1|地址2|**地址3**|地址4
:-:|:-:|:-:|:-:|:-:|:-:
0|1|接收地址 = 目的地址|发送地址 = AP地址|**源地址**|~
1|0|接收地址 = AP地址|发送地址=源地址|目的地址|~

#### 本章小结

- 链路(Link) ≠ 数据链路(Data Link)，电路接通 ≠ 数据链路接通
- 数据链路层使用PPP协议或CSMA/CD协议时，既然不保证可靠传输，为什么要对所传输的帧进行差错检验？
    - 如果在接收端不进行差错检测，那么接收端上交给主机的帧就可能包括在传输中出了差错的帧，而这样的帧对接收端主机是没有用处的
    - 数据链路层的可靠传输并不能保证网络层的传输也是可靠的
- 局域网、广域网、因特网：局域网和广域网都是通过**交换机**进行通信，而因特网由大局域网（广域网）和小局域网共同通过**路由器**相连
- 与OSI参考模型不同的是：在IEEE 802局域网参考模型中没有网络层。局域网中，在任意两个结点之间只有唯一的一条链路，不需要进行路由选择和流量控制
- 在IEEE 802.3标准以太网中，为什么说如果有冲突，那么冲突一定发生在冲突窗口内？或者说一个帧如果在冲突窗口内没有发生冲突，那么该帧就不会再发生冲突？
    - 一个数据帧在从结点A向**最远的结点**传输的过程中，如果有其他结点也正在发送数据，那么此时就会发生冲突，冲突后的信号需要经过冲突窗口时间后传回结点A，**结点A会检测到冲突**，所以说如果有冲突，那么一定发生在冲突窗口内
- 一个网段就是一个冲突域，一个局域网就是一个广播域
- 与传统共享式局域网相比，使用局域网交换机的交换式局域网为什么能改善网络的性能和服务质量？
    - 传统共享式局域网的核心设备是**集线器**，而交换式局域网的核心是**以太网交换机**。在使用共享式集线器的传统局域网中，在任何时刻只能有一个结点能够通过共享通信信道发送数据；在使用交换机的交换式局域网中，**交换机可以在它的多个端口之间建立多个并发连接，从而实现结点之间数据的并发传输**，有效地改善网络性能和服务质量
- 中继器、集线器、网桥和交换机这四种网络互联设备的区别与联系。
    - 中继器工作在物理层，用来连接两个速率相同且数据链路层协议也相同的网段
    - 集线器也工作在物理层，相当于一个多接口的中继器，**它可将多个结点连接成一个共享式的局域网，但任何时刻都只能有一个结点通过公共信道发送数据**
    - 网桥工作在数据链路层，可以互联不同的物理层、不同的MAC子层及不同速率的以太网。网桥具有过滤帧及存储转发帧的功能
    - 交换机工作在数据链路层，相当于一个多端口的网桥，**是交换式局域网的核心设备**。它允许端口之间建立多个并发连接，实现多个结点之间的并发传输。因此，交换机的每个端口结点所占用的带宽不会因为端口结点数目的增加而减少，且整个交换机的总带宽会随着端口结点的增加而增加

### <a name="20">（四）网络层</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

#### (1)网络层提供的数据报和虚电路服务

分组交换根据通信子网向端点系统提供的服务，分为数据报方式和虚电路方式：
特点|数据报服务|虚电路服务
-|-|-
连接的建立|不需要建立网络层连接|必须建立**网络层**连接
携带信息|每个分组在传输过程中都要携带源地址和目的地址|分组**只需要携带虚电路标识**
目的地址|每个分组都有完整的目的地址|**仅在建立连接阶段使用**，之后每个分组使用长度较短的虚电路号
路由选择|每个分组独立地进行路由选择和转发|属于同一条虚电路的分组按照同一路由转发
分组顺序|不保证分组的有序到达|保证分组的有序到达
可靠性|不保证可靠通信，**可靠通信应当由用户主机来保证**|**可靠通信应当由网络来保证**
对网络故障的适用性|出故障的节点丢失分组，其他分组路径选择发生变化时可正常传输|**所有经过故障节点的虚电路均不能正常工作**
差错处理和流量控制|由用户主机进行流量控制，不保证数据报的可靠性|**可由分组交换网负责，也可由用户主机负责**

网络层的主要功能：
- 异构网络互联	
    - 异构网络：数据链路层和物理层均不同的网络
    - 网络层的任务之一就是使异构网络实现互联
    - 网络互联通常是指用路由器进行网络互联和路由选择
- 路由选择与分组转发（路由器的两个功能）
    - 路由选择【确定哪一条路径】
    - 分组转发【当一个分组到达时所采取的动作】
- 拥塞控制
    - 拥塞：在通信子网中，因出现过量的分组而引起网络性能下降的现象。此时所有节点都来不及接受分组，而要丢弃大量分组
    - 判断是否拥塞的方法
        - 观察网络吞吐量与网络负载的关系
        - 随着通信子网负载的增加，吞吐量反而降低，即可能发生拥塞
        - 轻度拥塞--->拥塞---->死锁（吞吐量为0）
    - 拥塞控制的方法
        - 开环控制【静态】：事先考虑可能发生拥塞的情况，一旦系统启动，就不修改
        - 闭环控制【动态】：采用检测网络监视哪里发生了拥塞，动态调整网络系统运行
    - 流量控制和拥塞控制的区别：
        - 流量控制往往是指在发送端和接收端之间的点对点通信量的控制。流量控制所要做的是抑制发送端发送数据的速率，以便使接收端来得及接收
        - 拥塞控制必须确保通信子网能够传送待传送的数据，**是一个全局性的问题**，涉及网络中所有的主机、路由器及导致网络传输能力下降的所有因素

**王道习题：**

一轮标记题：

二轮重做：

大题：

错题总结：

#### (2)IP协议及ARP协议

IP地址的定义：
- IPV4地址由 32 位正整数来表示，IP 地址在计算机是以二进制的方式处理的
- IP地址最大值 = 2^32 = 43亿左右	
- MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输
- 源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化
- **IP 地址并不是根据主机台数来配置的，而是以网卡**。像服务器、路由器等设备，都是有 2 个以上的网卡，因此：
    - 一台主机至少可以设置 1 个以上的IP
    - 一台路由器可以设置 2 个以上IP
    - 一块网卡也可以设置 2 个以上的IP

IPv4分组的格式：**4-1-8**
- 版本：占4比特，表示IP协议的版本。通信双方使用的IP协议的版本必须一致。目前广泛使用的IP协议版本号为4（即IPv4）
- **首部长度**：占4比特，表示IP数据报首部的长度。该字段的取值**以4字节为单位**
    - 最小十进制取值为5，表示IP数据报首部只有20字节固定部分
    - 最大十进制取值为15，表示IP数据报首部包含20字节固定部分和最大40字节可变部分。可选字段长度从1个字节到40个字节不等。用来支持排错、测量及安全等措施
- 区分服务：占8比特，用来获得更好的服务。一般情况下都不使用该字段
- **总长度**：占16比特，表示IP数据报的总长度（首部 + 数据载荷）。最大取值为十进制检验和的65535，**以1字节为单位**。但其实不能超过链路层的MTU值（例如以太网的1500B）
- 标识（Identification）：占16比特，**属于同一个数据报的各分片数据报应该具有相同的标识**。IP软件维持一个计数器，每产生一个数据报，**计数器值加1，并将此值赋给标识**，但它并不是序号（因为IP是无连接服务）
- 标志（Flags）：占3比特，各比特含义如下：
    - 最高位是保留位，必须为0
    - 中间的一位是DF，**只有当DF = 0时才允许分片**
    - 标志字段的最低位为 MF，**MF = 1表示后面还有分片，MF = 0表示最后**
- 片偏移：占13比特，指出分片数据报的数据载荷部分偏移其在原数据报的位置有多少个单位。片偏移**以8个字节为单位**
- 生存时间（TTL）：占8比特，表示IP数据报的生存时间
    - 最初以秒为单位，最大生存周期为255秒。路由器转发IP数据报时，将IP数据报首部中的该字段的值减去IP数据报在本路由器上所耗费的时间，若不为0就转发，否则就丢弃
    - 现在以“跳数”为单位，路由器转发IP数据报时，将IP数据报首部中的该字段的值减1、若不为0就转发，否则就丢弃
    - 因此，**IP数据报每经过一个路由器，路由器都要重新计算首部检验和**，因为某些字段（生存时间、标志、片偏移等）的取值可能发生变化
- 协议：占8比特，指明IPv4数据报的数据部分是何种协议数据单元。常用的一些协议和相应的协议字段值如下。

协议名称|ICMP|IGMP|**TCP**|**UDP**|IPv6|OSPF
-|-|-|-|-|-|-
协议字段值|1|2|**6**|**17**|41|89

- 首部检验和：占16比特，用来检测首部在传输过程中是否出现差错。比CRC检验码简单，称为因特网检验和
    - 由于IP层本身并不提供可靠传输的服务，并且计算首部校验和是一项耗时的操作，因此在IPv6中，路由器不再计算首部校验和
- 源IP地址和目的IP地址：各占32比特
- 可选字段：增加了IP数据报的功能，但这同时也使得IP数据报的首部长度成为可变的。这就增加了每一个路由器处理IP数据报的开销。实际上可选字段很少被使用
- 填充字段：确保首部长度为4字节的整数倍。使用全0进行填充

IPv4分片：
- 以太网MTU【最大传输单元】不超过1500
- DF=1时，分组的长度又超过MTU时，丢弃该分组，**并用ICMP差错报文向源主机报告**
- MF=1，表示接收到的分片不是最后一个分片
- 所有片中的**有效数据荷载都是8的倍数**【偏移值的单位是8B】
- 在目的主机中对分片后的数据报重组

**分类编制的IPV4地址：**
- 分类：
    - A类（1 ~ 126）（0）：1 + 7（网络号） + 24（主机号）
    - B类（128 ~ 191）（10）：2 + 14（网络号） + 16（主机号）
    - C类（192 ~ 223）（110）：3 + 21（网络号） + 8（主机号）
    - D类（224 ~ 239）（1110）：4 + 多播地址
    - E类（240 ~ 255）（1111）：4 + 保留为今后使用
- 网络前缀 = 类别位 + 网络号
- 特殊IP地址：见背60
- IP分类的优点
	- 简单明了、选路（基于网络地址）简单
- IP分类的缺点
	- 同一网络下没有地址层次，缺少地址层次的灵活性
	- C类地址254个太少了，B类地址65534个又太多了，不能很好的与显示网络匹配
	- 上述两个缺点都可用【CIDR】解决

**ARP协议**【IP地址到MAC地址的映射】：
- ARP主要内容
    - ARP广播只在子网中传播
    - MAC地址只具有本地意义，每当路由器将IP数据报转发到一个具体的网络时，都需要重新封装源MAC地址和目的MAC地址
    - 路由器在收到分组后，剥离该分组的数据链路层协议头，然后在分组被转发之前，给分组加上一个新的链路层协议头
    - **ARP请求**是**广播发送**【由于不知道目标设备在哪里】
    - **ARP响应**是**单播发送**
- ARP过程	
    - 目的主机在本局域网
        - 先在ARP高速缓存中查看有无目的IP地址与MAC地址的映射
        - 有，则把MAC地址写入MAC帧，然后通过局域网把该MAC帧发往此MAC地址
        - 无，则通过广播ARP请求分组，在获得目的主句的ARP响应分组后，将目的主机的IP地址与MAC地址写入ARP告诉缓存
    - 目的主机不在本局域网
        - 将IP分组发送给本局域网的路由器，**先通过上述方式**获得**路由器**的IP地址和MAC地址的映射关系

#### (3)划分子网和构造超网

**划分子网的IPV4地址：**
- 为什么要划分子网？
	- 两级IP地址分类的地址空间流动率有时很低，用子网划分的方法来改善这个问题
- 划分子网的好处
	- 增加子网的数量--->减少广播域的大小--->减少了主机的数量--->提高了IP地址的利用率
	- 不增加网络的数量
- 什么是子网划分？
	- 将主机地址分为两个部分【子网网络地址和子网主机地址】的过程
	- 未做子网划分的 ip 地址：网络地址＋主机地址
	- 做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）
- 如何得到网络地址？
	- 将子网掩码和 IP 地址按位计算 AND，就可得到网络号
- 默认子网掩码
	- A类：255.0.0.0
	- B类：255.255.0.0
	- C类：255.255.255.0
- 怎么进行子网划分？
	- 假设对 C 类地址进行子网划分
	- 网络地址 218.75.230.0，使用子网掩码 255.255.255.192 对其进行子网划分
	- C 类地址中前 24 位是网络号，最后 8 位是主机号
	- 根据子网掩码可知从 8 位主机号中借用 2 位作为子网号
	- 由于子网网络地址被划分成 2 位，那么子网地址就有 4 个，分别是 00、01、10、11

无分类编制的IPV4地址【CIDR】：
- 为什么引入CIDR
	- CIDR消除了**传统的A类，B类和C类地址，以及划分子网**的概念
- CIDR的作用？
	- CIDR是一种**归并技术**，可以把小的网络汇聚成大的**超网**
	- CIDR可以更加有效地分配IPV4的地址空间，并且可以在新的IPV6使用之前允许因特网的规模继续增长
CIDR的细节？
    - CIDR的**表示形式**，最小地址，最大地址，地址数量，聚合网络数量，地址掩码
    - 举例：128.14.35.7/20（表示形式）
        - 最小地址：128.14.32.0
        - 最大地址：128.14.47.255
        - 地址数量：2^(32-20)
        - 聚合C类网的数量：2^(32-20) ÷ 2^8
        - 地址掩码：255.255.240.0
- 路由聚合（构造超网）
	- 为了减小路由表的消耗，用路由聚合来聚合网络地址
	- 网络前缀越长，地址快越小，路由越具体
    - 最长前缀匹配：有多条路由可选的时候，**选择网络前缀最长的那条**

IPV4地址的应用规划：
- 定长的子网掩码
    - 使用同一个子网掩码来划分子网
    - 子网划分方式不灵活，只能划分出 2^n 个子网
    - 每个子网所分配的IP地址数量相同，容易造成IP地址浪费
- 变长的子网掩码
    - 使用不同的子网掩码来划分子网
    - 子网划分方式灵活：可以按需分配
    - 每个子网所分配的IP地址数量可以不同，尽可能减少对IP地址的浪费

#### (4)ICMP协议

**ICMP【互联网控制报文协议】：**
- 为了提高IP数据报交付成功的机会，在网络层使用了**网际控制报文协议**（ICMP）来让主机或路由器报告差错和异常情况。ICMP报文作为**IP层数据报的数据**，加上数据报的首部，组成IP数据报发送出去（即ICMP是IP层协议）
- ICMP报文的种类有两种，即ICMP差错报告报文和ICMP询问报文：
    - ICMP差错报告报文用于目标主机或到目标主机路径上的路由器向源主机报告差错和异常情况。共有以下5种类型：
        1. **终点不可达。**当路由器或主机不能交付数据报时，就向源点发送终点不可达报文
        2. **源点抑制。**当路由器或主机由于**拥塞**而丢弃数据报时，就向源点发送源点抑制报文，使源点知道应当把数据报的发送速率放慢
        3. **时间超过。**当路由器收到生存时间（TTL）为零的数据报时，除丢弃该数据报外，还要向源点发送时间超过报文。当终点在预先规定的时间内不能收到一个数据报的全部数据报片时，就把已收到的数据报片都丢弃，并向源点发送时间超过报文
        4. **参数问题。**当路由器或目的主机收到的数据报的首部中有的字段的值不正确时，就丢弃该数据报，并向源点发送参数问题报文
        5. **改变路由**（重定向）。路由器把改变路由报文发送给主机，让主机知道下次应将数据报发送给另外的路由器（可通过更好的路由）
    - 不应发送ICMP差错报告报文的几种情况如下:
        1. 对ICMP差错报告报文不再发送ICMP差错报告报文
        2. **对第一个分片的数据报片的所有后续数据报片都不发送ICMP差错报告报文**
        3. 对**具有组播地址**的数据报都不发送ICMP差错报告报文。
        4. 对具有特殊地址（如127.0.0.0或0.0.0.0）的数据报不发送ICMP差错报告报文 
    - ICMP询问报文有4种类型：**回送请求和回答**报文、**时间戳请求和回答**报文、地址掩码请求和回答报文、路由器询问和通告报文，最常用的是前两类
        1. ICMP回送请求报文是由主机或路由器向一个特定的目的主机发出的询问。收到此报文的主机必须给源主机或路由器发送ICMP回送回答报文。这种询问报文用来测试目的站**是否可达及了解其有关状态**
        2. ICMP时间戳请求报文是请某个主机或路由器回答当前的日期和时间。在ICMP时间戳回答报文中有一个32位的字段，其中写入的整数代表从1900年1月1日起到当前时刻一共有多少秒。这种询问报文用来进行**时钟同步和测量时间**
- ICMP的两个常见应用是分组网间探测PING（**用来测试两台主机之间的连通性**）和Traceroute（UNIX中的名字，在Windows中是Tracert，可以**用来跟踪分组经过的路由**）。其中**PING使用了ICMP回送请求和回答报文**，**Traceroute（Tracert）使用了ICMP时间超过报文**
    - 注意：**PING工作在应用层**，它直接使用网络层的ICMP，而未使用传输层的TCP或UDP；Traceroute/Tracert工作在网络层。

**王道习题：**

一轮标记题：

二轮重做：

大题：

错题总结：

#### (5)路由算法及协议，包括路由表及路由转发、路由算法分类、距离向量路由算法及RIP协议、链路状态路由算法及OSPF协议、BGP基本原理；

**路由器的组成和功能：**
- 路由器是一种具有多个输入/输出端口的**专用计算机**
- 路由器主要实现物理层，数据链路层，网络层的功能
- 路由器是网络层设备
- 路由器的任务：**连接异构网络**并完成**路由转发**
- 路由器的功能
    - 分组转发：处理通过路由器的数据流
    - 路由计算：通过和其他路由器进行路由协议的交互，完成路由表的计算
- 路由器的组成
    - 路由选择部分
        - 三个组成部分：**路由选择处理机 + 路由选择协议 + 路由表**
        - 也叫控制部分，核心是路由选择处理机
        - 任务是根据所选定的路由选择协议构造出路由表
        - 同时不断更新路由信息和维护路由表
    - 分组转发部分
        - 三个组成部分：交换结构（本身就是一个网络）+ 一组输入端口 + 一组输出端口
        - 三种交换方式
            - 通过存储器进行交换
            - 通过总线进行交互
            - 通过互联网络进行交互
- 路由表与路由转发
	- 路由表是根据路由选择算法得出的，主要用途是路由选择
	- *路由表的组成 = 目的网络的IP地址 + 子网掩码 + 下一跳IP地址 + 接口*
	- **路由表总是用软件实现**，**转发表可以用软件也可以用硬件实现**
	- 路由表不等于转发表，**分组的实际转发是靠直接查找转发表**，而不是直接查找路由表
    - 路由表中默认路由的目的地址和子网掩码都是0.0.0.0

路由算法分类：
- 按照能否随网络的通信量或拓扑自适应地进行调整变化来划分：
    - 静态路由选择
        - 由人工配置的网络路由、默认路由、特定主机路由、黑洞路由等都属于静态路由
        - 这种人工配置方式简单、开销小，但不能及时适应网络状态（流量、拓扑等）的变化
        - 一般只在小规模网络中采用
    - 动态路由选择
        - 路由器通过路由选择协议自动获取路由信息
        - 比较复杂、开销比较大，但能较好地适应网络状态的变化
        - 适用于大规模网络
        - 常用的有**距离-向量路由算法**和**链路状态路由算法**
- 按层次划分：
    - 自治系统（AS）内部：内部网关协议（IGP）
    - 自治系统外部：外部网关协议（EGP）

IP数据报的发送和转发过程：
- 主机发送IP数据报
	- 判断目的主机是否与自己在同一个网络
		- 若在同一个网络，**直接交付**
		- 若不在同一个网络，数据**间接交付**，传输给主机所在网络的默认网关（路由器），由默认网关帮忙转发
- 路由器转发IP数据报
	- 检查IP数据报首部是否出错
		- 若出错，则直接丢弃该IP数据报并通告源主机
		- 若没有出错，则进行转发
	- 根据IP数据报的目的地址在路由表中查找匹配的条目
		- 若找到匹配的条目，则转发给条目中指示的下一跳
		- 若找不到，则丢弃该IP数据报并通告源主机
- 静态路由配置及其可能产生的路由环路问题：
    - 配置错误导致路由环路：在IP数据报首部设生存时间TTL字段
    - 聚合不存在的网络而导致的路由环路：用黑洞路由条目配置解决
    - 网络故障而导致的路由环路：用黑洞路由条目配置解决

**距离向量路由算法及RIP协议：**
- 基本概念：
    - RIP使用**跳数**(Hop Count)作为度量(Metric)来衡量到达目的网络的距离。
    - **路由器到直连网络的距离定义为1，到非直连网络的距离定义为所经过的路由器数加1**
    - 允许一条路径最多只能包含15个路由器。**距离等于16时相当于不可达**。因此,RIP只适用于小型互联网
    - RIP是***应用层协议***，端口为520
- 距离-向量算法
    1. 修改邻居路由器发过来的路由表：距离字段加1（原因显然）
    2. 利用邻居路由表，更新自己的路由表
    3. 如果180秒还没有收到邻居路由表，就把邻居设为不可达路由器，距离设置为16
- RIP协议的特点
    1. 仅和**相邻路由器**交换信息（Who）
    2. 路由器交换的信息是当前路由器所知道的**全部信息**，即自己的路由表（What）
    3. 按**固定的时间间隔**交换路由信息，如每隔30秒（When）
- RIP协议的优点：实现简单、开销小、收敛过程较快
- RIP协议的缺点：“坏消息传得慢”

链路状态路由算法及OSPF协议：
- 基本概念、特点：
    - 使用了Dijkstra提出的最短路径算法SPF
    - OSPF是基于**链路状态**的，而不像RIP那样是基于距离向量的（What，区别1）
    - OSPF采用SPF算法计算路由，从**算法上保证了不会产生路由环路**（区别2）
    - OSPF**不限制网络规模**，更新效率高，收敛速度快（区别3）
    - 链路状态是指本路由器都和哪些路由器相邻，以及相应链路的“代价”(cost)。“代价”用来表示费用、距离、时延、带宽，等等，这些都由网络管理人员来决定
    - **只有当链路状态发生变化时**，路由器才用**洪泛法**向所有路由器发送此信息，且没有“坏消息传得慢”的问题（When，Who，区别4、区别5）
    - OSPF有以下五种分组类型
        - 问候(Hello)分组
        - 数据库描述(Database Description)分组
        - 链路状态请求(Link State Request)分组
        - 链路状态更新(Link State Update)分组
        - 链路状态确认(Link State Acknowledgment)分组
    - 为了使OSPF能够用于规模很大的网络，OSPF把一个自治系统再划分为若干个更小的范围，叫做区域(Area)
- 链路状态路由算法(Dijkstra算法)
    1. dist[1] = 0, dist[i] = +∞
    2. for i : 1 ~ n
        - s: 一个点的集合，1号点到该集合的点的最短路径暂时确定
        - t: **离这个集合距离最近的点**
        - 反复加入新的t，并更新可能发生变化的最短路径

BGP基本原理：
- 基本概念
    - 自治系统之间的路由选择必须考虑相关策略（政治，经济，安全等），BGP只能是力求寻找一条能够到达目的网络且比较好的路由（不能兜圈子），**而并非要寻找一条最佳路由**
    - 网络可达性信息：要到达某个网络所要结果的一系列自治系统/路径
    - 在配置BGP时，每个自治系统的管理员要选择至少一个路由器作为该自治系统的“BGP发言人”。BGP发言人要交换网络可达性信息，并根据所采用的策略从收到的路由信息中找出到达各自治系统的较好的路由
    - BGP是基于TCP的**应用层协议**
    - BGP-4有以下四种报文
        - OPEN（打开）报文：用来与相邻的另一个BGP发言人建立关系，使通信初始化
        - UPDATE（更新）报文：用来通告某一路由的信息，以及列出要撤销的多条路由
        - KEEPALIVE（保活）报文：用来周期性地证实邻站的连通性
        - NOTIFICATION（通知）报文：用来发送检测到的差错

三种路由协议的比较：
协议|RIP|OSPF|BGP
-|-|-|-
类型|内部|内部|外部
路由算法|距离-向量|链路状态|路径-向量
传递协议|UDP|IP|TCP
路径选择|跳数最少|代价最低|较好，非最佳
交换节点|和本节点相邻的路由器|网络中的所有路由器|和本节点相邻的路由器
交换内容|当前本路由器知道的全部信息，即自己的路由表。RIP不知道全网的拓扑结构|本路由器和相邻所有路由器的链路状态。任何一个路由器都知道自己所在**区域**的拓扑结构|首次：邻居的整个路由表；非首次：有变化的部分

**王道习题：**

一轮标记题：

二轮重做：

大题：

错题总结：

#### (6)IP组播基本原理、特点及用途

IP组播基本原理、特点及用途：
- 基本概念：
    - 也叫多播，多点广播或群播
    - 一定仅应用于UDP
    - 主机使用IGMP加入组播组，能运行组播协议的路由器称为组播路由器
    - 组播数据报和一般的IP数据报的区别是，前者使用D类IP地址作为目的地址（注意，**组播地址只能用于目的地址**），并且首部中的协议字段值是2，表明使用IGMP
- 转发过程：
    - 一个组播地址可以标识一组地址，源主机只需将**一份数据**发给组播地址，之后网络会将**这个分组的副本**投递给该组中的每台主机
    - 在IPv4中，组播地址在D类地址空间中分配，IPv6中也有一部分地址空间保留给组播组
    - 对于IPv4，32位组播地址里**只有后23位**会被映射到48位的硬件组播地址，IANA（internet assigned number authority）规定，IPv4组播MAC地址的高24位为0x01005E，第25位为0，后23位就是前文提到的映射内容
    - 因此，组播IP地址与以太网硬件地址的**映射关系不是唯一**的，收到组播数据报的主机，还要在IP层利用软件进行过滤，把不是本主机要接收的数据报丢弃
- IGMP与组播路由算法
    - IGMP让连接到本地局域网上的组播路由器知道本局域网上是否有主机参加或退出了某个组播组，IGMP应视为网际协议IP的一个组成部分，其工作可分为两个阶段：
        1. 当某台主机加入新的组播组时，该主机应向组播组的组播地址发送一个IGMP报文，声明自己要成为该组的成员。本地的组播路由器收到IGMP报文后，将组成员关系转发给因特网上的其他组播路由器
        2. 本地组播路由器要**周期性地探询**本地局域网上的主机，以便知道这些主机是否仍继续是组的成员
    - 组播路由选择实际上就是要找出以源主机为根结点的组播转发树，其中每个分组**在每条链路上只传送一次**
    - 在许多由路由器互联的支持硬件多点传送的网络上实现因特网组播时，主要有三种路由算法：
        1. 基于链路状态的路由选择
        2. 基于距离-向量的路由选择
        3. 可以建立在任何路由器协议之上，因此称为**协议无关的组播**（PIM）

**王道习题：**

一轮标记题：

二轮重做：

大题：

错题总结：

#### (7)网络地址转换NAT原理

私有地址（专用地址）：
- 1个A类：10.0.0.0 ~ 10.255.255.255
- 16个B类：172.16.0.0 ~ 172.31.255.255
- 256个C类：192.168.0.0 ~ 192.168.255.255

网络地址转换NAT原理：
- 一句话解释NAT：**不同专用地址**对应**同一公有地址**，对应**不同端口**（从底层实现上讲, NAT至少是工作在网络层）
- 这种将端口号和IP地址一起进行转换的技术叫作网络地址与端口号转换NAPT(Network Address and Port Translation)
- NAPT转换表在NAT路由器上自动生成。例如，在TCP的情况下，建立TCP连接首次握手时的SYN包一经发出，就会生成这个表，后又随着收到关闭连接时发出FIN包的确认应答（第四次挥手）而被删除

#### (8)IPv6基本知识，包括：IPv6特点、地址、包结构等

IPV6基本知识：
- IPv6 地址的标识方法
	- IPv6 地址长度是 128 位，是以每 16 位作为一组
	- 每组用冒号 「:」 隔开。
	- 如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开
    - 但是，一个 IP 地址中只允许出现一次两个连续的冒号
- IPv6 地址的结构
	- 单播地址，用于一对一的通信
	- 组播地址，用于一对多的通信
	- **任播地址，用于通信最近的节点**，最近的节点是由路由协议决定
- IPv6 的亮点
	- IPv6 可自动配置【即插即用】
	- IPv6 首部长度采用固定的值 40 字节，去掉了校验和
	- IPv6安全性提高了
- IPv6 相比 IPv4 的首部改进
	- 取消了首部校验和字段
		- 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验
	- 取消了分片/重新组装相关字段
		- 分片与重组是耗时的过程，IPv6 不允许在**中间路由器**进行分片与重组（这种操作只能在源与目标主机，这将大大提高了路由器转发的速度）
	- 取消选项字段
		- 选项字段不再是标准 IP 首部的一部分了。但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上
		- 删除该选项字段使的 IPv6 的首部成为**固定长度的 40 字节**
        - 📈![img](https://bkimg.cdn.bcebos.com/pic/b17eca8065380cd733642891a944ad3459828150?x-bce-process)
- IPv4 到 IPv6 的过渡
    - 双协议栈
    - 隧道技术

**王道习题：**

一轮标记题：

二轮重做：

大题：

错题总结：

#### (9)其他

SDN的基本概念：
- 软件定义网络SDN采用**集中式的控制层面**和**分布式的数据层面**来控制网络
- 北向接口：SDN提供的编程接口
- 南向接口：SDN控制器和转发设备建立双向会话的接口（使用南向接口协议，如openflow）
- 东西向接口：SDN控制器集群内部控制器之间的通信接口

DHCP协议【动态主机配置协议】（基于**UDP的应用层协议**）：
- 客户：DHCP发现！（广播）
- 服务器：DHCP提供！（广播）（使用ARP确保所选IP地址未被网络中其他主机占用）
- 客户：DHCP请求！（广播）
- 服务器：DHCP确认！（广播）
    - 使用ARP检测所分配到的IP地址是否已被网络中其他主机占用：
        - 若被占用：给DHCP服务器发送“DHCP拒绝”报文撤销IP地址租约,并重新发送“DHCP发现”报文
        - 若未被占用：可以使用租约中的IP地址与网络中其他主机通信
- 特点：IP动态分配，即插即用

移动IP：
- 接收：本地代理/归属代理 → 转交地址/辅地址 → 移动结点/主地址（通俗易懂的解释：就好比你搬家了，你原来的邻居为你代收邮件，然后转寄给你）
- 移动结点 → 外埠代理/外部代理

虚拟专用网VPN：
- **利用公用的因特网作为本机构各专用网之间的通信载体**，这样的专用网又称为虚拟专用网
- 同一机构内不同部门的内部网络所构成的虚拟专用网VPN又称为**内联网VPN**
- VPN要保证传输数据的安全性，会将原始的内部数据报进行**加密**，然后再将其封装成为在因特网上发送到的外部数据
- 有时一个机构的VPN需要有某些外部机构（通常就是合作伙伴）参加进来。这样的VPN就称为**外联网VPN**
- 在外地工作的员工需要访问公司内部的专用网络时，只要在任何地点接入到因特网，运行驻留在员工PC中的VPN软件，在员工的PC和公司的主机之间建立VPN隧道，即可访问专用网络中的资源。这种VPN称为**远程接入VPN**

**王道习题：**

一轮标记题：

二轮重做：

大题：

错题总结：

#### 本章小结

- 解决“IP地址耗尽”问题的措施有哪几种？
    1. 采用无类别编址CIDR，使IP地址的分配更加合理
    2. 采用网络地址转换NAT方法以节省全球IP地址
    3. 采用具有更大地址空间的新版本的IPv6（从根本上解决了IP地址的耗尽问题）
- “尽最大努力交付”有哪些含义?
    1. 不保证源主机发送的IP数据报**一定无差错**地交付到目的主机
    2. 不保证源主机发送的IP数据报都在**某一规定的时间内**交付到目的主机
    3. 不保证源主机发送的IP数据报**一定按发送时的顺序**交付到目的主机
    4. 不保证源主机发送的IP数据报**不会重复**交付给目的主机。
    5. 不**故意**丢弃IP数据报。
    6. **凡向上交付的IP数据报，都是IP首部没有差错的，或没有检测出差错的**
- IP有分片的功能，但**广域网中的分组**则不必分片，这是为什么?
    - IP数据报可能要经过多个局域网，而源结点事先并不知道数据报后面要经过的这些网络**所能通过的分组的最大长度**是多少。等到IP数据报转发到某个网络时，中间结点可能才发现数据报太长了，因此在这时就必须进行分片
    - 而*广域网能够通过的分组的最大长度是该广域网中所有结点都事先知道的*，源结点不可能发送网络不支持的过长分组。因此广域网没有必要将已经发送出的分组再进行分片
- 数据链路层广播和IP广播有何区别?
    - 数据链路层广播是用数据链路层协议（第二层）在一个以太网上实现的对该局域网上的所有主机进行广播MAC帧
    - IP广播则是用IP通过因特网实现的对一个网络（即目的网络）上的所有主机进行广播IP数据报
- 主机在接收一个广播帧或组播帧时，其**CPU**所要做的事情有何区别？
    - 在接收广播帧时，主机通过其网卡(NIC)接收每个广播帧，然后将其传递给操作系统。**CPU执行协议软件**，并界定是否接受和处理该帧
    - 在接受组播帧时，NIC根据特定的组播地址表来接收帧。凡与此**组播地址表**不匹配的帧都将被NIC丢弃。因此在组播的情况下，是适配器NIC而不是CPU决定是否接收一个帧

## <a name="23">附录：各种名词缩写及含义</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

**计算机组成原理：**

英文|缩写|补充说明
:-:|:-:|-
Central Processing Unit|CPU|略
Memory Address Register|MAR|地址寄存器
Memory Data Register|MAR|数据寄存器
Clock cycle Per Instruction|CPI|执行每条指令所需的平均时钟周期数
Million Instructions Per Second|MIPS|每秒执行多少百万条指令数量
Mega Floating-Point Operations Per Second|MFLOPS|每秒执行多少百万条指令数量
Arithmetic Logic Unit|ALU|算术逻辑单元
Solid State Drives|SSD|固态硬盘
Read-Only Memory|ROM|只读存储器
Static Random Access Memory|SRAM|静态随机存取存储器
Dynamic Random Access Memory|DRAM|动态随机存取存储器
Row Address Strobe|RAS|行选通信号，低电平有效
Column Address Strobe|CAS|列选通信号，低电平有效
~|WE|读**写**控制信号，读周期为高电平
~|CS|片选信号，低电平有效
write-through|~|全写法/写直通法
write-back|~|回写法
write-allocate|~|写分配法
not-write-allocate|~|非写分配法
First In First Out|FIFO|先进先出算法
Least Recently Used|LRU|最近最久未使用算法
Least Frequently Used|LFU|最近最少使用算法

**操作系统：**

英文|缩写|补充说明
:-:|:-:|-
Basic Input Output System|BIOS|一组固化到计算机内主板上一个ROM芯片上的程序，保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序
Process Control Block|PCB|使参与并发执行的每个程序（含数据）能够独立运行的专门的数据结构
Thread Control Block|TCB|线程控制块
User-Level Thread|ULT|用户级线程
Kernel-Level Thread|KLT|内核级线程
First Come First Serve|FCFS|先来先服务
Shortest Job First|SJF|短进程优先
Round-Robin|RR|轮询调度
Memory Manage Unit|MMU|内存管理部件
Page Table Register|PTR|页表寄存器
Translation Lookaside Buffer|TLB|快表，转址旁路缓存，MMU用来完成地址转换和TLb的访问与交互
Virtual Page Number|VPN|页号
Physical Page Number|PPN|物理页号/页框号
Page Table Entry|PTE|页表项

**计算机网络：**

英文|缩写|补充说明
:-:|:-:|-
~|Repeater|中继器/转发器/放大器
~|Hub|集线器
~|Bridge|网桥
~|Switch|交换机
~|Routers|路由器
~|Gateway|网关/协议转换器
~|Brouter|桥接路由器，可以工作在数据链路层和网络层
Network Interface Card|NIC|网卡，工作在数据链路层和物理层，进行数据的串并转换
Wide Area Network|WAN|广域网
Metropolitan Area Network|MAN|城域网
Local Area Network|LAN|局域网
Personal Area Network|PAN|个人区域网
Internet Service Provider|ISP|网络业务提供商
Round-Trip Time|RTT|往返时延
Service Data Unit|SDU|服务数据单元，物理层的服务数据单元就是1-SDU
Protocol Control Information|PCI|控制协议操作的信息，链路层的协议控制信息就是2-PCI
Protocol Data Unit|PDU|对等层次之间传送的数据单位称为该层的PDU，物理层的PDU称为比特流，数据链路层的称为帧，网络层为分组/IP数据报，传输层为报文段
Service Access Point|SAP|逻辑接口，是一个层次系统的上下层之间进行通信的接口，和硬件接口有所不同
International Standardization Organization|ISO|国际标准化组织
Open System Interconnection reference model|OSI/RM|开放系统互连参考模型
Return to zero|RZ|归零编码
Non return to zero|NRZ|非归零编码
Non return to zero, inverted|NRZI|反向非归零编码
Amplitude Shift Keying|ASK|幅移键控
Frequency Shift Keying|FSK|频移键控
Phase Shift Keying|PSK|相移键控
Quadrature Amplitude Modulation|QAM|正交振幅调制
Shielded Twisted Pair|STP|屏蔽双绞线
Unshielded Twisted Pair|UTP|无屏蔽双绞线
Pulse-Code Modulation|PCM|脉冲编码调制
Asymmetric Digital Subscriber Line|ADSL|非对称数字用户线
Hybrid Fiber Coax|HFC|光纤同轴混合网
fiber to the...|FTTx|光纤到……
Maximum Transmission Unit|MTU|最大传送单元
Cyclic Redundancy Check|CRC|循环冗余校验
Automatic Repeat reQuest|ARQ|自动重传请求
Stop-and-Wait|SW|停止-等待协议
Go-back-N|GBN|后退N帧协议
Selective Repeat|SR|选择重传协议
Medium Access Control|MAC|介质访问控制/媒体接入控制/介质接入控制/媒体访问控制，当然，媒体还能替换成媒介，总之翻译方式极多
Logical Link Control|LLC|逻辑链路控制
Point-to-Point Protocol|PPP|点对点协议
Link Control Protocol|LCP|链路控制协议
Network Control Protocol|NCP|网络控制协议
Password Authentication Protocol|PAP|口令鉴别协议
Challenge-Handshake Authentication Protocol|CHAP|口令握手鉴别协议
Frequency-Division Multiplexing|FDM|频分多路复用
Time-Division Multiplexing|TDM|时分多路复用
Statistical Time-Division Multiplexing|STDM|异步时分多路复用
Wave-Division Multiplexing|WDM|波分多路复用
Code-Division Multiplexing|CDM|码分多路复用
Code Division Multiple Access|CDMA|码分多址，注意与CSMA做区分
Additive Link On-line HAwaii system|ALOHA|ALOHA协议
Carrier Sense Multiple Access|CSMA|载波侦听多点访问协议
Carrier Sense Multiple Access with Collision Detection|CSMA/CD|载波侦听多点访问/碰撞检测协议
Carrier Sense Multiple Access with Collision Avoidance|CSMA/CA|载波侦听多点访问/碰撞避免协议
InterFrame Space|IFS|帧间间隔
Short InterFrame Space|SIFS|短IFS，用来分隔属于一次对话的各帧
PCF interframe space|PIFS|点协调IFS，中等长度的IFS，在PCF操作中使用
DCF interframe space|DIFS|分布式协调IFS，最长的IFS，用于异步帧竞争访问的时延
Access Point|AP|接入点
Basic Service Set|BSS|基本服务集
Basic Service Area|BSA|基本服务区
Distribution System|DS|分配系统
Extended Service Set|ESS|扩展服务集
Service Set IDentifier|SSID|服务集标识符
Request To Send|RTS|请求发送
Clear To Send|CTS|允许发送
Software Defined Networking|SDN|软件定义网络
Don't Fragment|DF|不要分片（也就是说，DF = 0就是可以）
More Fragments|MF|更多分片（也就是说，MF = 1就是后面还有）
Address Resolution Protocol|ARP|地址解析协议
Classless Inter-Domain Routing|CIDR|无分类域间路由选择
Dynamic Host Configuration Protocol|DHCP|动态主机配置协议
Internet Control Message Protocol|ICMP|网际控制报文协议
Autonomous System|AS|自治系统
Interior Gateway Protocol|IGP|内部网关协议
Exterior Gateway Protocol|EGP|外部网关协议
Routing Information Protocol|RIP|路由信息协议
Open Shortest Path First|OSPF|开放（开源）最短路径优先
Border Gateway Protocol|BGP|边界网关协议
Internet Group Management Protocol|IGMP|因特网组管理协议
Virtual Private Network|VPN|虚拟专用网络
Network Address Translation|NAT|网络地址转换